---
title: "Main analysis code, process and outputs"
author: "Robert Heirene"
output:
  html_document: default
---
## Lay introduction
This html document is the direct output of computer code from the statistical programming software R Studio. It presents the original code used to undertake the analyses in the below-titled study:

<br>
<center>
 **"A randomised control trial to evaluate messages that promote limit setting and the impact of limits on online gambling behaviour**
</center>
<br>

Alongside the analysis code are the outcomes from the code, which are produced by R Studio directly from the underlying code and therefore are not editable by the research team, leading to the transparent presentation of all findings from the study. 

The analysis code that underlies this document can be accessed on this project's Open Science Framework (OSF) page:

- https://osf.io/6dpkw/

## Technical introduction
This document presents the analysis code used to pre-process (e.g., combine datasets, organise data, rename variables and values) and analyse data for the above-titled study. The code is annotated and the resulting outputs are included (although outputs for code that would present customer ids from appearing have been preventing from appearing [wherever possible the need to prevent outcomes appearing has been avoided]).
<br>

This document does not include the pre-processing of the original datasets provided by each operator. Four analysis scripts (one for each operators' data) were developed and used for the pre-processing of the original datasets. These can all be accessed on this project's OSF page and have the following titles:

- "Analysis_script_Operator1_preprocessing.R"
- "Analysis_script_Operator2_preprocessing.R"
- "Analysis_script_Operator3_preprocessing.R"
- "Analysis_script_Operator4_preprocessing.R"

# --------------------------------------------------------------------------------
## Load packages & fonts
Create function to check to see if packages are installed and install them if they are not, and then load them into the R session. From:

- https://gist.github.com/stevenworthington/3178163#file-ipak-r-L1

```{r message=FALSE, results = FALSE}
# Create function:
ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

# Name relevant packages:
packages <- c("MOTE",
              "plyr",
              "dplyr",
              "knitr",
              "Rmisc", 
              "beepr",
              "extrafont",
              "extrafontdb",
              "ggplot2",
              "forcats",
              "sjmisc",
              "data.table",
              "tidyr",
              "lubridate",
              "cowplot",
              "readr",
              "car",
              "fmsb",
              "purrr",
              "scales",
              "patchwork",
              "multicon",
              "ggridges",
              "broom",
              # "broom.mixed",
              "ggstatsplot",
              "ggsci",
              "showtext",
              "aod",
              "ggpubr",
              "rstatix",
              "WRS2",
              "lsr",
              "BayesFactor",
              "epitools",
              "mosaic",
              "kableExtra",
              "table1",
              "english",
              "apa",
              "WebPower",
              "kableExtra",
              "gtsummary",
              "Gmisc",
              "glue",
              "htmlTable",
              "grid",
              "magrittr",
              "BFpack")
              # "psych") # Used for "phi" function

# Load packages:
ipak(packages)

# Had to load separately for an unknown reason:
library("DescTools")
# Had to run the following code to install "ggstatsplot" when using a laptop:

# remotes::install_github(
#   repo = "IndrajeetPatil/ggstatsplot", # package path on GitHub
#   dependencies = TRUE, # installs packages which ggstatsplot depends on
#   upgrade_dependencies = TRUE # updates any out of date dependencies
# )

# If encountering bugs with packages this code will remove them all and then you can reinstall:
# ip <- installed.packages()
# pkgs.to.remove <- ip[!(ip[,"Priority"] %in% c("base", "recommended")), 1]
# sapply(pkgs.to.remove, remove.packages)

```

Remove all objects from work space before starting:
```{r}
# rm(list = ls())
```

Load relevant fonts for figures:
```{r message = FALSE, results = FALSE}

font_add_google("Poppins")
font_add_google("Cormorant Garamond")

showtext_auto()
```

# --------------------------------------------------------------------------------
## Load & name all datasets
### Operator 1

``` {r message = FALSE, results = FALSE, warnings = FALSE}
operator1 <- read.csv("./Analysis data/Operator 1/Final_dataset_Operator1.csv")

head(operator1) %>% 
  as_tibble()
```
View variable names to check these are consistent between operators:
```{r}
operator1names<- names(as.list(operator1)) %>%
  print()
```

### Operator 2
``` {r message = FALSE, results = FALSE, warnings = FALSE}
operator2 <- read.csv("Analysis data/Operator 2/Final_dataset_Operator2.csv") %>%
  as_tibble() %>%
  # dplyr::rename(customer_id = customerid,
  #        post_code = postcode) %>%
  mutate(customerid = as.factor(customerid),
         postcode = as.double(postcode)) %>% 
  #dplyr::select(-customer_id,
  #        -post_code) %>%
    print()

head(operator2) %>% 
  as_tibble()
```
View variable names to check these are consistent between operators:
```{r}
operator2names<- names(as.list(operator2)) %>%
  print()
```
  
### Operator 3
``` {r message = FALSE, results = FALSE, warnings = FALSE}
operator3 <- read.csv("Analysis data/Operator 3/Final_dataset_Operator3.csv") %>%
  # dplyr::rename(customer_id = customerid,
  #        timeout.duration.pre = timeout_duration_pre,
  #        timeout.duration.post = timeout_duration_post) %>%
  mutate(customerid = as.factor(customerid),
         timeout_duration_pre = as.double(timeout_duration_pre),
         timeout_duration_post = as.double(timeout_duration_post),
         ) %>% 
  #dplyr::select(-customer_id,
  #        -timeout.duration.pre,
  #        -timeout.duration.post) %>%
  as_tibble() %>%
  print()
```
View variable names to check these are consistent between operators:
```{r}
operator3names<- names(as.list(operator3)) %>%
  print()
```

### Operator 4
``` {r message = FALSE, results = FALSE, warnings = FALSE}
operator4 <- read.csv("Analysis data/Operator 4/Final_dataset_Operator4.csv") %>%
# dplyr::rename(customer_id = customerid) %>%
  mutate(customerid = as.factor(customerid)) %>% 
  #dplyr::select(-customer_id) %>%
  as_tibble() %>%
  print()
```
View variable names to check these are consistent between operators:
```{r}
operator4names<- names(as.list(operator4)) %>%
  print()
```
<br><br>

# Join all datasets together
Join all datasets together from each operator and make a final, usable dataset:
``` {r message = FALSE, results = FALSE, warnings = FALSE}
all.operators.data<- bind_rows(operator1,
          operator2,
          operator3,
          operator4) %>% # Combined datasets
dplyr::select(-limit_date, 
       -bonusbet_amount_wagered_pre,
       -regular_payout_pre,
       -bonusbet_payout_pre,
       # -regular_amount_wagered_pre,
       -bonusbet_amount_wagered_pre,
       -regular_payout_pre,
       -bonusbet_payout_pre,
       -X) %>% # Remove irrelevant rows
  as_tibble() %>%
  print()

# Take a look at the new dataset and check for any irregularities:
all.operators.data %>%
 dplyr::select(1:8)

# Convert all date columns to date format----
all.operators.data$date_account_opened<- as.Date(all.operators.data$date_account_opened, format = "%Y-%m-%d") # date_account_opened
all.operators.data$date_account_closed<- as.Date(all.operators.data$date_account_closed, format = "%Y-%m-%d") # date_account_closed
all.operators.data$window_limit_date<- as.Date(all.operators.data$window_limit_date, format = "%Y-%m-%d") # window_limit_date
all.operators.data$limit_date_pre<- as.Date(all.operators.data$limit_date_pre, format = "%Y-%m-%d") # limit_date_pre
all.operators.data$limit_date_post<- as.Date(all.operators.data$limit_date_post, format = "%Y-%m-%d") # limit_date_post
all.operators.data$timeout_start_date_pre<- as.Date(all.operators.data$timeout_start_date_pre, format = "%Y-%m-%d") # timeout_start_date_pre
all.operators.data$timeout_finish_date_pre<- as.Date(all.operators.data$timeout_finish_date_pre, format = "%Y-%m-%d") # timeout_finish_date_pre
all.operators.data$timeout_start_date_post<- as.Date(all.operators.data$timeout_start_date_post, format = "%Y-%m-%d") # timeout_start_date_post
all.operators.data$timeout_finish_date_post<- as.Date(all.operators.data$timeout_finish_date_post, format = "%Y-%m-%d") # timeout_finish_date_post
all.operators.data$self_exclusion_start_date<- as.Date(all.operators.data$self_exclusion_start_date, format = "%Y-%m-%d") # self_exclusion_start_date
all.operators.data$self_exclusion_finish_date<- as.Date(all.operators.data$self_exclusion_finish_date, format = "%Y-%m-%d") # self_exclusion_finish_date 

# Check all columns have converted properly:
head(all.operators.data)

all.operators.data  %>%
 dplyr::select(date_account_opened, 
         date_account_closed,
         window_limit_date,
         limit_date_pre,
         limit_date_post,
         timeout_start_date_pre,
         timeout_finish_date_pre,
         timeout_start_date_post,
         timeout_finish_date_post,
         self_exclusion_start_date,
         self_exclusion_finish_date)
```
<br><br>

## Overall data summaries
Compute summaries of the entire dataset (pre-cleaning/filtering):
``` {r message = FALSE, result = 'asis'}
# How many consumers are there in total:
nrow(all.operators.data)

# How many window limit setters are there in total:
all.operators.data %>%
  filter(window_limit_setter == "LimitSetter") %>%
  nrow()

# How many customers are there per operator:
kable(all.operators.data %>%
  group_by(operator) %>%
  dplyr::summarise(
    n = n()
    ),
  caption = "Number of consumers per operator")  %>%
    kable_classic(full_width = F, html_font = "Cambria")

# How many customers are there per Condition:
kable(all.operators.data %>%
  group_by(condition) %>%
  dplyr::summarise(
   n = n()
   ), caption = "Number of consumers per condition") %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br><br>

# Clean the data according to eligibility criteria

Preregistered eligibility criteria:

-	Placed bets on a minimum of five days in the 30 days preceding messaging
-	Held a wagering account for at least 90 days
-	Not currently on a time-out of any duration
-	No current deposit limit set (Note: this was checked when processing the data at the individual operator level)


Let's first see how many don't meet each criterion:

### Criterion 1: Placed bets on a minimum of five days in the 30 days preceding messaging:
``` {r message = FALSE}
too.few.betting.days<- all.operators.data %>%
  filter(last30_betting_days_frequency < 5) 

nrow(too.few.betting.days)
```

Let's see whether these all come from the same operator or a mix:
``` {r message = FALSE}
too.few.betting.days %>%
  group_by(operator) %>%
  dplyr::summarise(
    n = n()
  )
```
This is almost the entire sample for Operator 4 (89%), 18% for Operator 2, and 4% of operator 3.

Does this remove any of our window limit letters?
``` {r message = FALSE}
table(too.few.betting.days$window_limit_setter)
```
Yes, 2. Double check using another method:
``` {r message = FALSE}
too.few.betting.days %>%
  filter(window_limit_setter == "LimitSetter") %>%
 dplyr::select(1:10,
         -customerid,
         -postcode)
```
Both limit setters in this cohort were from Operator 4.

### Criterion 2: Held a wagering account for at least 90 days:
``` {r message = FALSE}
late.registration.date<- all.operators.data %>%
  anti_join(too.few.betting.days) %>% # let's filter them out sequentially so our numbers tally nicely in our flowchart
  filter(date_account_opened > as.Date("2019-07-16"))

nrow(late.registration.date)
```
This would exclude 1,757 participants in total, but 1564 will be removed after already removing those with too few betting days.

Let's see whether these all come from the same operator or a mix:
``` {r message = FALSE}
late.registration.date %>%
  group_by(operator) %>%
  dplyr::summarise(
    n = n()
  )
```
This even more of the sample for Operator 4 (although there may be some overlap between this sample and the one above) and a considerable proportion for Operator 3 (~15%).

Does this remove any of our window limit letters?
``` {r message = FALSE}
late.registration.date %>%
  filter(window_limit_setter == "LimitSetter") %>%
 dplyr::select(1:10,
         -customerid,
         -postcode)
```
Yes, this removes one limit setting participant from Operator 4.

### Criterion 3: Not currently on a time-out of any duration:
``` {r message = FALSE}
# First, how long are the timeouts in the data:
table(all.operators.data$timeout_duration_pre)

# Option to take a look at the timeout data and manually search for any concerns:
all.operators.data %>%
  filter(timeout_pre != "None" |
         timeout_post != "None") %>%
 dplyr::select(timeout_duration_pre, 
       timeout_start_date_pre,
       timeout_finish_date_pre,
       timeout_pre,
       timeout_duration_post,
       timeout_start_date_post,
       timeout_finish_date_post,
       timeout_post)
```

Identify anyone on timeouts using code:

-(StartMessagePeriod < EndTimeoutPeriod) and (EndMessagePeriod > StartTimeoutPeriod).

``` {r message = FALSE}
all.operators.data %>%
  filter(as.Date("2019-10-14") < timeout_finish_date_pre &
  as.Date("2019-10-23") >  timeout_start_date_pre) %>%
 dplyr::select(timeout_duration_pre, 
         timeout_start_date_pre,
         timeout_finish_date_pre,
         timeout_pre,
         operator,
         window_limit_setter)

# Check if anyone was on a timeout for the entire window:
timeout_for_entire_window<- all.operators.data %>%
  filter(timeout_start_date_pre < as.Date("2019-10-14") &
  timeout_finish_date_pre > as.Date("2019-10-23")) %>%
 dplyr::select(timeout_duration_pre, 
         timeout_start_date_pre,
         timeout_finish_date_pre,
         timeout_start_date_post,
        timeout_finish_date_post,
         timeout_pre,
         operator,
         window_limit_setter) %>%
  print(n=50)

```
Only one person was on timeout and they were from Operator 4. The timeout started on 11/10/2019 and ended on 18/10/2019 and so they would've received one of messages. Based on a reviewer suggestion, we will leave this person in although we had originally excluded them. 

### Additional elgibility criteria
We need to check that no one self-excluded during the messaging period:
``` {r message = FALSE, results = FALSE}
self.excluders.during<- all.operators.data %>%
  filter(self_exclusion_start_date >=  as.Date("2019-10-14") &
         self_exclusion_start_date <=  as.Date("2019-10-23")) %>%
 dplyr::select(self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         customerid,
         operator,
         window_limit_setter) 

nrow(self.excluders.during)
# Nine people self excluded during this window. Two of these were limit setters 

# But was anyone self-exclusion for the entire duration of the messaging period?
self.excluders.all<- all.operators.data %>%
  filter(self_exclusion_start_date <=  as.Date("2019-10-14") &
         self_exclusion_finish_date >=  as.Date("2019-10-23") &
           window_limit_setter == "None") %>%
 dplyr::select(operator,
                self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         customerid,
         operator,
         window_limit_setter) 

nrow(self.excluders.all)
# No one
```
We also need to check that no one closed their account during the messaging period:
``` {r message = FALSE, results = FALSE}
account.closers<- all.operators.data %>%
  anti_join(too.few.betting.days) %>% 
  anti_join(late.registration.date) %>% 
  filter(date_account_closed <  as.Date("2019-10-14")) %>%
 dplyr::select(operator,
                date_account_closed,
         self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         customerid,
         operator,
         window_limit_setter)

nrow(account.closers)
# 5 people closed their account prior to the messaging window. Five of these were limit setters in response to messages and so we need to retain these for hypothesis testing
``` 

# --------------------------------------------------------------------------------

## Create a final dataset for hypothesis testing analyses
Add all filters for eligibility criteria and create a final dataset for hypothesis testing analyses:
``` {r message = FALSE, results = FALSE}
hypothesis.test.data<- all.operators.data %>%
  filter(last30_betting_days_frequency >= 5) %>% # Remove those with too few betting days
  filter(date_account_opened <= as.Date("2019-07-16"))  %>% # Remove those opened their account too recently
  anti_join(account.closers) %>% # Remove those who closed their account before messages could be sent
  print()

# Randomly check for customerids for those who self excluded or closed their accounts to check the anti-joins worked (removed for anonymity):
hypothesis.test.data %>%
  filter(customerid == "***" | 
           customerid =="***") # Removed for anonymity
```
<br><br>

## Summarise characteristics of sample used in hypothesis tests

Let's provide some descriptive details for this sample:
``` {r message = FALSE, warning = FALSE}
# First, how many are there?
nrow(hypothesis.test.data) 

# Number of participants per operator:
kable(hypothesis.test.data %>% 
  group_by(operator) %>% 
  dplyr::summarise(
  n =  n()
  ), caption = "Number of participants per operator") %>%
    kable_classic(full_width = F, html_font = "Cambria")
  
# Number of participants per condition:
kable(hypothesis.test.data %>% 
  group_by(condition) %>% 
  dplyr::summarise(
   n =  n()
  ), caption = "Number of participants per condition") %>%
    kable_classic(full_width = F, html_font = "Cambria")

# Gender distribution:
kable(hypothesis.test.data %>% 
  # distinct(customerid, .keep_all = TRUE) %>% # This was added to check their are no duplicates in the sample
  group_by(gender) %>%
  dplyr::summarise(
    n = n()
    ) %>% 
  # group_by(n) %>% 
  mutate(percentage = n/sum(n)*100), caption = "Gender distribution") %>%
    kable_classic(full_width = F, html_font = "Cambria")

# Age summaries:
kable(hypothesis.test.data %>% 
  dplyr::summarise(
    age.mean = mean(age),
    age.median = median(age),
    age.min = min(age),
    age.max = max(age),
    age.sd = sd (age),
    n = n()
  ), caption = "Age summary for total sample",
      digits = 2,
      col.names = c("Mean age", "Median age", "Min age", "Max age", "SD of age", "n")) %>%
    kable_classic(full_width = F, html_font = "Cambria")

# Demographic breakdown by condition and gender:
kable(hypothesis.test.data %>% 
  group_by(condition, 
           gender) %>% 
  dplyr::summarise(
    age.mean = mean(age),
    age.median = median(age),
    age.min = min(age),
    age.max = max(age),
    age.sd = sd (age),
    n = n()
  ), caption = "Age summary by condition & gender",
      digits = 2,
      col.names = c("Condition", "Gender","Mean age", "Median age", "Min age", "Max age", "SD of age", "n")) %>%
    kable_classic(full_width = F, html_font = "Cambria")

# Percentage of males and females in each condition:
kable(hypothesis.test.data %>%
  group_by(condition,
           gender) %>% 
  dplyr::summarise(
    total = n()
  ) %>% 
  group_by(condition) %>% 
  mutate(percentage = total/sum(total)*100), caption = "Gender distribution by condition",
      digits = 2,
      col.names = c("Condition", "Gender","n", "Percentage")) %>%
    kable_classic(full_width = F, html_font = "Cambria")

# Demographic breakdown by condition only:
kable(hypothesis.test.data %>% 
  group_by(condition) %>% 
  dplyr::summarise(
    "Mean age" = mean(age),
    "Median age" = median(age),
    "Min age" = min(age),
    "Max age" = max(age),
    "SD of age" = sd (age),
    n = n()
  ), caption = "Age summary by condition", digits = 2)  %>%
    kable_classic(full_width = F, html_font = "Cambria") 
```

## Limit setting summaries
Total number of limit setters:
```{r message=FALSE, warning=FALSE}
kable(hypothesis.test.data %>%
  group_by(window_limit_setter) %>%
  dplyr::summarise( 
    n = n()), caption = "Limit setting (in window of interest) summary", col.names = c("Group","n")) %>%
    kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Total number of limit setters excluding controls (with %):
```{r message=FALSE, warning=FALSE}

intervention.limits.sans.controls<- hypothesis.test.data %>%
  group_by(window_limit_setter) %>%
  filter(condition != "1") %>%
  dplyr::summarise( 
    n = n()
    ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100) 

kable(intervention.limits.sans.controls, caption = "Total number of limit setters excl. controls",
  digits = 3) %>%
    kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Number of limit setters by operator:
```{r message=FALSE, warning=FALSE}
kable(hypothesis.test.data %>%
  group_by(operator, 
           window_limit_setter) %>%
  dplyr::summarise( 
    n()), caption = "Number of limit setters by operator",
  col.names = c("Operator", "Group","n")) %>%
    kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Number of limit setters by condition:
```{r message=FALSE, warning=FALSE}
colour <- as.factor(c("Controls", "Email", "In-account", "Email", "In-account", "Email", "In-account"))  # Create a character vector to identify the main groups
Message <- as.factor(c("Controls", "Informative", "Informative", "Social", "Social", "Personal", "Personal"))  # Create a character vector to identify the main groups

limit.summary<- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise( 
             n = n()
             ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100) %>%
  bind_cols(colour, Message) %>%
  dplyr::rename(Delivery= ...6,
         Message = ...7)  %>%
  as.data.frame()

kable(limit.summary, caption = "Number of limit setters by condition",
      digits = 2,
      col.names = c("Condition", "Limit setters (n)","Non-limit setters (n)", "Total sample (n)", "Percentage of condition", "Delivery method", "Message content")) %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br>

## Plot the primary outcome in a bar chart:
``` {r}

grob <- grobTree(textGrob("(values = n)", x=0.073,  y=0.2, hjust=0,
  gp=gpar(col="black", fontsize=6, fontface="italic", family = "Poppins")))
# Plot

Figure2 <- ggplot(limit.summary, aes(x=Message, y=Percentage, fill=Delivery)) + 
  geom_bar(stat = "identity", position = position_dodge2(width = 2), alpha = 1, color="black")+
  geom_text(aes(label=LimitSetter), position=position_dodge(width=0.9), vjust=-.25, family = "Poppins",size = 2, color="black")+ # add n labels for each bar
  annotation_custom(grob) +
  theme(axis.text = element_text(color = "black", size = 8.5, face = "plain", family = "Poppins"))+
  theme(axis.title.x = element_text(color="black", size=10, face="plain", vjust=-2.3, family = "Poppins"))+
  theme(axis.title.y = element_text(color="black", size=10, face="plain", vjust = 2.5, family = "Poppins"))+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  scale_x_discrete(name = "Message content") +
  scale_y_continuous(name = "% of consumers who set limits") +
  theme(plot.margin = unit(c(.5,.2,.5,.5), "cm"))+
  scale_fill_manual(values=c("gray92", "#E69F00", "#56B4E9")) +
  theme(legend.position = "top",
    # legend.position = c(.19, .85),
        legend.text = element_text( color="black", size=7, face="plain", family = "Poppins"),
        legend.title.align = .5,
        legend.title=element_text(size=9, family = "Poppins")) +
   labs(color = "Delivery:")     
```

``` {r results = FALSE, fig.align = 'center'}
# View new plot:
print(Figure2) 

# Save Plot:
ggsave("Figures/Figure2.pdf",
  width = 90,
  height = 90,
  units = c("mm"),
  dpi = 300
  )
```

Compute the number of limit setters by IV (delivery method & message content)
``` {r warnings = FALSE, message = FALSE}
# 1) Informative message limit summary:
hypothesis.test.data %>%
  filter(condition == "2" | condition == "3") %>%
  group_by(window_limit_setter) %>%
  dplyr::summarise( 
    n = n()
  ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100)

# 2) Socially referenced message limit summary:
hypothesis.test.data %>%
  filter(condition == "4" | condition == "5") %>%
  group_by(window_limit_setter) %>%
  dplyr::summarise( 
    n = n()
  ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100)

# 3) Personal message limit summary:
hypothesis.test.data %>%
  filter(condition == "6" | condition == "7") %>%
  group_by(window_limit_setter) %>%
  dplyr::summarise( 
    n = n()
  ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100)

# 4) Email message limit summary:
hypothesis.test.data %>%
  filter(condition == "2" | condition == "4" | condition == "6") %>%
  group_by(window_limit_setter) %>%
  dplyr::summarise( 
    n = n()
  ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100)

# 5) In-account message limit summary:
hypothesis.test.data %>%
  filter(condition == "3" | condition == "5" | condition == "7") %>%
  group_by(window_limit_setter) %>%
  dplyr::summarise( 
    n = n()
  ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100)

# 6) Controls  limit summary:
control.limit.summary <- hypothesis.test.data %>%
  filter(condition == "1") %>%
  group_by(window_limit_setter) %>%
  dplyr::summarise( 
    n = n()
  ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100) %>% 
  print()
```

### Limit setting rates adjusted for message opening rates:

Load summary tables and make them consistent:
```{r warnings = FALSE, message = FALSE, results = FALSE}

Operator2.opening.summary<- read.csv("Analysis data/opening_rate_summary_Operator2.csv")
Operator3.opening.summary<- read.csv("Analysis data/opening_rate_summary_Operator3.csv")

# Need to create this for Operator 4 from raw data:
# Load data sets:
group2mes1.4<- read.csv("Analysis data/Operator 4/Messaging Trial Open Rates/group2mes1.csv")
group4mes1.4<- read.csv("Analysis data/Operator 4/Messaging Trial Open Rates/group4mes1.csv")
group6mes1.4<- read.csv("Analysis data/Operator 4/Messaging Trial Open Rates/group6mes1.csv")
group2mes2.4<- read.csv("Analysis data/Operator 4/Messaging Trial Open Rates/group2mes2.csv")
group4mes2.4<- read.csv("Analysis data/Operator 4/Messaging Trial Open Rates/group4mes2.csv")
group6mes2.4<- read.csv("Analysis data/Operator 4/Messaging Trial Open Rates/group6mes2.csv")

# Take a look at datasets and make them tibbles:
group2mes1.4<- as_tibble(group2mes1.4) %>%
  print()
group4mes1.4<- as_tibble(group4mes1.4) %>%
  print()
group6mes1.4<- as_tibble(group6mes1.4) %>%
  print()
group2mes2.4<- as_tibble(group2mes2.4) %>%
  print()
group4mes2.4<- as_tibble(group4mes2.4) %>%
  print()
group6mes2.4<- as_tibble(group6mes2.4) %>%
  print()

# Merge datasets:
opening.rates.4 <- bind_rows(group2mes1.4,
          group4mes1.4,
          group6mes1.4,
          group2mes2.4,
          group4mes2.4,
          group6mes2.4)

# Compute summary:
opening.rates.summarytable.4 <- opening.rates.4 %>% group_by(MESSAGE_DATE, 
                             MSG_GROUP,
                             OPENED_YN) %>%
  dplyr::summarise(
    n = n()
  ) %>%
  pivot_wider(names_from = OPENED_YN, values_from = n) %>%
  mutate(Percentage = Y/(N+Y)*100) %>%
  print()

write.csv(opening.rates.summarytable.4, file = "Analysis data/opening_rate_summary_Operator4.csv")

Operator4.opening.summary<- read.csv("Analysis data/opening_rate_summary_Operator4.csv") %>% dplyr::rename(PercentageOpen = Percentage,
        Condition = MSG_GROUP)

operator<- as.factor(rep(c("2", "3", "4"), each = 6)) # Create a character vector to identify this message response
```
Now join these summary tables together and identify the highest opening rate for each condition of the two messages (that is the % opening rate for either Message 1 or 2, depending on which was higher). Also make a summary table of the number of participants by condition and operator within the hypothesis testing data to allow for the calculation of the **estimated** message opening rates within the sample used for hypothesis tests:
```{r warnings = FALSE, message = FALSE}
opening.summary.combined <- bind_rows(Operator2.opening.summary,
          Operator3.opening.summary,
          Operator4.opening.summary) %>% 
  bind_cols(operator) %>%
  dplyr::rename(operator = ...10,
         condition = Condition) %>%
 dplyr::select(condition, Message, MESSAGE_DATE, operator, PercentageOpen) %>%
  group_by(condition, operator) %>% 
  top_n(1, PercentageOpen) %>%
  print()

# summarise the full data set:
opening.rate.summary <- bind_rows(Operator2.opening.summary,
          Operator3.opening.summary,
          Operator4.opening.summary) %>% 
  bind_cols(operator) %>%
  dplyr::rename(operator = ...10,
         condition = Condition) %>%
 dplyr::select(condition, Message, MESSAGE_DATE, operator, PercentageOpen) %>%
  group_by(condition, operator) %>%
  ungroup() %>%
  dplyr::summarise(
    min.open = min(PercentageOpen),
    max.open = max(PercentageOpen),
    mean.open = mean(PercentageOpen)
  ) %>%
  print()

# Number of consumers by operator and condition, excluding Operator 1 as we don't have opening rate data from them:
consumer.numbers<- hypothesis.test.data %>% 
  group_by(operator,
           condition) %>% 
  dplyr::summarise(
   n =  n()
  ) %>%
  filter(condition == "2"|
          condition == "4"|
           condition == "6") %>%
  filter(operator != "1") %>%
  print()
```

Merge the two datasets and then times the number of participants in each "condition by operator" group by the proportion of those who opened messages in the total sample to estimate the number who opened messages in this sample, then sum this total across operators to arrive at a total number for these 3 operators combined for each condition:
```{r warnings = FALSE, message = FALSE}
consumer.numbers$operator<- as.factor(consumer.numbers$operator)

estimated.open.rates.os234<- opening.summary.combined %>%
  bind_cols(consumer.numbers) %>%
  mutate(ProportionOpen = PercentageOpen/100) %>%
  mutate(estimate.openers.n = n*ProportionOpen) %>%
  group_by(condition...1) %>%
  dplyr::summarise(
    number.opened1 = sum(estimate.openers.n)
  ) %>%
  print()
```
Now calculate the mean percentage for each condition across the 3 operators where opening rate data are available, which can then be used to estimate the opening rates for messages sent by Operator 1 (for which we have no data):
```{r warnings = FALSE, message = FALSE}
mean.openingrates<- opening.summary.combined %>%
  bind_cols(consumer.numbers) %>%
  group_by(condition...1) %>%
  dplyr::summarise(
    mean.opening.rate = mean(PercentageOpen)
  ) %>%
  print()

# How many consumers are in each of these conditions for Operator 1? Calculate this and combine with the above data table, then calculate the estimate number of consumers for this operator who opened messages based on mean rates from other operators:
estimated.open.rates.os1<- hypothesis.test.data %>%
  filter(operator == "1") %>%
  filter(condition == "2"|
           condition == "4"|
           condition == "6") %>%
  group_by(condition) %>%
  dplyr::summarise(
   n = n()
  ) %>%
  bind_cols(mean.openingrates) %>%
  mutate(ProportionOpen = mean.opening.rate/100) %>%
  mutate(number.opened2 = n*ProportionOpen) %>%
  print()
```
Now join the estimated opening rates data tables for operators 2-4 and operator 1 and calculated the total estimated number of consumers per condition who opened emails:
```{r warnings = FALSE, message = FALSE}
estimated.open.rates.total <- estimated.open.rates.os234 %>%
  bind_cols(estimated.open.rates.os1) %>%
  mutate(total.estimated.opened = number.opened1+number.opened2) %>%
  dplyr::rename(condition = condition...1) %>%
dplyr::select(condition, 
        number.opened1,
        mean.opening.rate,
        number.opened2,
        total.estimated.opened) %>%
  print()
```
Now compute the total number of limits setters in each email condition and then work out what percentage they make up of the total estimated samples who opened emails:
```{r warnings = FALSE, message = FALSE}
hypothesis.test.data %>%
  filter(condition == "2"|
           condition == "4"|
           condition == "6") %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise( 
             n = n()
             ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  full_join(estimated.open.rates.total) %>%
  mutate(Percentage = (LimitSetter/total.estimated.opened)*100) 

# There are a total of 66 limit setters in these groups (23+25+18). Calculate the total estimated number of email openers across all conditions and then work out the overall percentage of limit setting within email conditions when only including the estimated no. of email openers:
email.open.rates.adjusted<- hypothesis.test.data %>%
  filter(condition == "2"|
           condition == "4"|
           condition == "6") %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise( 
             n = n()
             ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  full_join(estimated.open.rates.total) %>%
  ungroup() %>%
  dplyr::summarise(
    totaln = sum(total.estimated.opened)
  ) %>%
  mutate(percentagetotal= (66/totaln)*100) %>%
  print()

# What was the percentage without accounting for opening rates:
email.open.rates<- hypothesis.test.data %>%
  filter(condition == "2"|
           condition == "4"|
           condition == "6") %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise( 
             n = n()
             ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  ungroup() %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100) %>% # Cut off here to see breakdown by condition
  dplyr::summarise(
    totaln = sum(Total)
  ) %>%
  mutate(percentagetotal= (66/totaln)*100) %>%
  print()

```
Finally, calculate the total n and percentage and no. of limit setters among the in-account message conditions, then add these together to compute an overall adjusted limit setting percentage for the entire sample that accounts for the opening rate among those sent email messages:
```{r warnings = FALSE, message = FALSE}
hypothesis.test.data %>%
  group_by(window_limit_setter) %>%
  filter(condition != "1" & 
  condition != "2" &
  condition != "4" &
  condition != "6") %>%
  dplyr::summarise( 
    n = n()
    ) %>%
  pivot_wider(names_from = window_limit_setter, 
              values_from = n) %>%
  mutate(Total = LimitSetter + None) %>%
  mutate(Percentage = (LimitSetter/Total)*100)

# total sample size:
3299 + 10927

# total no. limit setters:
66+95

# Total limit setting percentage:
final.adjusted.limit.rate<- (161/14226)*100
```
### Characteristics of the the deposit limits set
```{r warnings = FALSE, message = FALSE}
# First recode and reorder factor levels for presentation in plot:
Figure3data <- hypothesis.test.data %>%
  mutate(Limit_window = fct_recode(limit_window_setters,
                             "Yearly" = "DepositLimitYear",
                             "Monthly" = "DepositLimitMonth",
                             "Weekly" = "DepositLimitWeek",
                             "Daily" = "DepositLimitDay")) %>%
  filter(window_limit_setter == "LimitSetter") 
  
Figure3data$Limit_window <- factor(Figure3data$Limit_window,
                                         c("Yearly",
                             "Monthly",
                             "Weekly",
                            "Daily")) # Re-order factor levels

# How many people set limits of each duration? What limit amounts (in dollars) were set?
kable(Figure3data %>%
  group_by(Limit_window) %>%
  filter(condition != "1") %>%
  dplyr::summarise(
    n =  n(),
    meanlimit = mean(window_limit_amount),
    medianlimit = median(window_limit_amount),
    SDlimit = sd(window_limit_amount)), caption = "Limit summary by duration",
      digits = 2,
      col.names = c("Limit duration", "n","Mean limit", "Median limit", "SD of limit")) %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br>

Plot limit amount ($) across limit durations:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
Figure3 <- Figure3data %>%
  ggplot(aes(x=window_limit_amount , y=Limit_window, fill = factor(stat(quantile)))) +
  stat_density_ridges(
    geom = "density_ridges_gradient", calc_ecdf = TRUE,
    quantiles = 4, quantile_lines = TRUE,
    scale = .9,
    position = position_nudge(x = .6, y = -.17)
  ) +
  # scale_fill_viridis_d(name = "Quartiles") +
  annotate("text", x = 530, y = 4.2, # Add in mean difference scores and their confidence intervals
           label = "n = 61",
           size = 2.5) +
  annotate("text", x = 530, y = 3.2, # Add in mean difference scores and their confidence intervals
           label = "n = 71",
           size = 2.5) +
  annotate("text", x = 530, y = 2.2, # Add in mean difference scores and their confidence intervals
           label = "n = 19",
           size = 2.5) +
  annotate("text", x = 530, y = 1.3, # Add in mean difference scores and their confidence intervals
           label = "n = 4",
           size = 2.5) +
  scale_fill_manual(values=c("gray92", "#E69F00", "#56B4E9", "navyblue"), name = "Quartiles") +
  scale_y_discrete(name = "Limit duration") +
  scale_x_continuous(name = "Limit amount ($AUD)", limits = c(-100, 2300), breaks = c(0, 500, 1000, 1500, 2000)) +
  theme(axis.text = element_text(color = "black", size = 7, face = "plain"))+
  theme(axis.title.x = element_text(color="black", size=8, face="plain", vjust=-2))+
  theme(axis.title.y = element_text(color="black", size=8, face="plain", vjust=2.5))+
  theme(legend.text = element_text(color = "black", size = 7, face = "plain"),
        legend.title.align = .5,
        legend.title=element_text(size=8)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  theme(plot.margin = unit(c(.2,.1,.25,.25), "cm")) +
  theme(legend.key.size = unit(.8,"line"))

# View new plot:
Figure3
```
<br>

Warning, the above figure is capped at \$2,300 cutting out three outliers: One person with the weekly deposit limit of approximately \$6000, one person with a daily deposit limit of \$5000, and another of $20,000
<br>

Save plot:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
ggsave("Figures/Figure3.jpeg",
       width = 80,
       height = 85,
       units = c("mm"),
       dpi = 600
)
```

Plot the same for pre limits setters for comparison:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
hypothesis.test.data %>%
  mutate(Limit_window = fct_recode(limit_window_pre,
                                   "Yearly" = "DepositLimitYear",
                                   "Monthly" = "DepositLimitMonth",
                                   "Weekly" = "DepositLimitWeek",
                                   "Daily" = "DepositLimitDay")) %>%
  filter(limit_setter_pre == "PreLimitSetter") %>%
  ggplot(aes(x=limit_amount_pre , y=Limit_window, fill = factor(stat(quantile)))) +
  stat_density_ridges(
    geom = "density_ridges_gradient", calc_ecdf = TRUE,
    quantiles = 4, quantile_lines = TRUE,
    scale = .9,
    position = position_nudge(x = .6, y = -.17)
  ) +
  # scale_fill_viridis_d(name = "Quartiles") +
  # annotate("text", x = 1450, y = 3.9, # Add in mean difference scores and their confidence intervals
  #          label = "n = 61",
  #          size = 2.5) +
  # annotate("text", x = 1450, y = 2.9, # Add in mean difference scores and their confidence intervals
  #          label = "n = 71",
  #          size = 2.5) +
  # annotate("text", x = 1450, y = 1.9, # Add in mean difference scores and their confidence intervals
  #          label = "n = 19",
  #          size = 2.5) +
  # annotate("text", x = 1450, y = .9, # Add in mean difference scores and their confidence intervals
  #          label = "n = 4",
  #          size = 2.5) +
  scale_fill_manual(values=c("gray92", "#E69F00", "#56B4E9", "navyblue"), name = "Quartiles") +
  scale_y_discrete(name = "Limit duration") +
  scale_x_continuous(name = "Limit amount ($AUD)", limits = c(-100, 2300), breaks = c(0, 250, 500, 750, 1000, 1250, 1500,1750, 2000, 2250)) +
  theme(axis.text = element_text(color = "black", size = 7, face = "plain"))+
          theme(axis.title.x = element_text(color="black", size=8, face="plain", vjust=-2))+
          theme(axis.title.y = element_text(color="black", size=8, face="plain", vjust=2.5))+
          theme(legend.text = element_text(color = "black", size = 7, face = "plain"),
                legend.title.align = .5,
                legend.title=element_text(size=8)) +
          theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                panel.background = element_blank(), axis.line = element_line(colour = "black"))+
          theme(plot.margin = unit(c(.5,.1,.5,.5), "cm"))
```
<br>

Further characterise the deposit limits set prior to be messages: 
```{r message=FALSE, warning=FALSE}
# How many pre limits setters were there of each duration?
kable(hypothesis.test.data %>%
  group_by(limit_window_pre) %>%
  filter(condition != "1") %>%
  dplyr::summarise(
    n() 
  ), caption = "Summary of limits set pre-messages") %>%
    kable_classic(full_width = F, html_font = "Cambria")

```
<br><br>

## Compare the characteristics of limits setters vs non-setters
Note: Most of these simple comparisons are for inclusion in a report to the funder.
Some comparisons are redundant scientifically as below we carry out a logistic regression comparing limit setters vs. non-setters to evaluate the predictive validity of these variables. That said, we do calculate summary figures here for each group on each of the variables, which may be useful for interpreting the findings of this study.

<br>

First, exclude all controls from these comparisons:
```{r message=FALSE, warning=FALSE}
hypothesis.test.data.sanscontrols <- hypothesis.test.data %>%
  filter(condition != "1")
```

### Age comparison
```{r message=FALSE, warning=FALSE, fig.align = 'center'}
# Summary figures for age:
kable(hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter) %>%
  dplyr::summarise(
    age.mean = mean(age),
    age.median = median(age),
    age.min = min(age),
    age.max = max(age),
    age.sd = sd (age),
    n() 
  ), caption = "Age summary for each group",
      digits = 2,
     col.names = c("Group", "Mean age", "Median age", "Min age", "Max age", "SD of age", "n")) %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br>
```{r message=FALSE, warning=FALSE, fig.align = 'center'}
# Plot distribution of age for both groups to see whether this is normally distributed across groups:
hist.age<- ggplot(hypothesis.test.data.sanscontrols, 
                  aes(age, fill = window_limit_setter)) +
  geom_histogram(bins = 60) 

hist.age 
```
<br>

Age is clearly positively skewed across both groups. Now check for outliers:
```{r message=FALSE, warning=FALSE}
age.outliers<- hypothesis.test.data.sanscontrols %>%
  mutate(age_zscore = (age - mean(age))/ sd(age)) %>%
  filter(age_zscore >= 3.29 |
           age_zscore <= -3.29)
nrow(age.outliers)
```

Given the distribution of the data and the presence of outliers, let's perform both a normal t-test and a Mann-Whitney U:
```{r message=FALSE, warning=FALSE}
age.ttest <-t.test(formula = age ~ window_limit_setter,
       data = hypothesis.test.data.sanscontrols,
       paired = FALSE,
       alternative = "two.sided")
age.ttest

wilcox.test(age ~ window_limit_setter,
            data = hypothesis.test.data.sanscontrols) 
```

### Gender comparison
```{r message=FALSE, warning=FALSE}
# Percentage of males and females in each group:
kable(hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter, 
           gender) %>%
  dplyr::summarise(
    total = n()
  ) %>% 
  group_by(window_limit_setter) %>% 
  mutate(percentage = total/sum(total)*100), caption = "Gender distribution across groups",
      digits = 2,
     col.names = c("Group", "Gender", "n", "Percentage of group")) %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br>

Test whether the proportion of males who set limits significantly greater than the proportion of females:
```{r message=FALSE, warning=FALSE}
gender.table<- hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter, 
           gender) %>%
  dplyr::summarise(
    total = n()
  )  %>% 
  as.data.frame() %>% 
  pivot_wider(names_from = gender, values_from = total) %>%
 dplyr::select("F",
         "M") %>%
  as.matrix() %>%
  print()
```
Run Chi-square test:
```{r message=FALSE, warning=FALSE}
chisq.test(gender.table)
```
Print APA output:
```{r message=FALSE, warning=FALSE}
chisq_apa(chisq.test(gender.table), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```
### Operator comparison
```{r message=FALSE, warning=FALSE}
# Summary figures:
kable(hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter, 
           operator) %>%
  dplyr::summarise(
    total = n()
  ) %>% 
  group_by(window_limit_setter) %>% 
  mutate(percentage = total/sum(total)*100), # Percentage across operators
     caption = "Operator distribution across groups",
     digits = 2,
     col.names = c("Group", "Operator", "n", "Percentage of group")) %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br>

Test whether the proportion of limits set associated with the operator from which consumers are registered:
```{r message=FALSE, warning=FALSE}
operator.table<- hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter, 
           operator) %>%
  dplyr::summarise(
    total = n()
  )  %>% 
  as.data.frame() %>% 
  pivot_wider(names_from = operator, values_from = total) %>%
 dplyr::select("1",
         "2",
         "3",
         "4") %>%
  print()

operator.table[is.na(operator.table)] <- 0
```
Run Chi-square test:
```{r message=FALSE, warning=FALSE}
chisq.test(operator.table)
```

### Limit setting prior to study comparison
```{r message=FALSE, warning=FALSE}
# Summary figures:
kable(hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter, 
           limit_setter_pre) %>%
  dplyr::summarise(
    total = n()
  ) %>% 
  group_by(window_limit_setter) %>% 
  mutate(percentage = total/sum(total)*100), caption = "Previous limit use across groups",
      digits = 2,
     col.names = c("Group", "Previous use", "n", "Percentage of group")) %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br>

Test whether the proportion of window_limit_setters who have previously set limits significantly greater than the proportion of non_window_limit_setters?
```{r message=FALSE, warning=FALSE}
prelimit.table<- hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter, 
           limit_setter_pre) %>%
  dplyr::summarise(
    total = n()
  )  %>% 
  as.data.frame() %>% 
  pivot_wider(names_from = limit_setter_pre, values_from = total) %>%
 dplyr::select(PreLimitSetter,
         None) %>%
  as.data.frame() %>%
  print()
```
Run Chi-square test:
```{r message=FALSE, warning=FALSE}
chisq.test(prelimit.table)
```
Produce APA output:
```{r message=FALSE, warning=FALSE}
chisq_apa(chisq.test(prelimit.table), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```

### Timeout prior to study comparison
```{r message=FALSE, warning=FALSE}
# Summary figures:
kable(hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter, 
           timeout_pre) %>%
  dplyr::summarise(
    total = n()
  ) %>% 
  group_by(window_limit_setter) %>% 
  mutate(percentage = total/sum(total)*100), caption = "Previous timeout use across groups",
      digits = 2,
     col.names = c("Group", "Previous use", "n", "Percentage of group")) %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br>

Test whether the proportion of window_limit_setters who have previously used timeouts significantly greater tham the proportion of non_window_limit_setters:
```{r message=FALSE, warning=FALSE}
pretimeout.table<- hypothesis.test.data.sanscontrols %>%
  group_by(window_limit_setter, 
           timeout_pre) %>%
  dplyr::summarise(
    total = n()
  )  %>% 
  as.data.frame() %>% 
  pivot_wider(names_from = timeout_pre, values_from = total) %>%
 dplyr::select(TimeOutPre,
         None) %>%
  print()
```
Run Chi-square test:
```{r message=FALSE, warning=FALSE}
chisq.test(pretimeout.table)
```
Produce APA output:
```{r message=FALSE, warning=FALSE}
chisq_apa(chisq.test(pretimeout.table), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```


# --------------------------------------------------------------------------------

<center>
# Confirmatory Chi-square analyses
</center>

 Original condition names:
 
- 1: Control group           
- 2: Informative; email       
- 3: Informative; in-account 
- 4: Social; email            
- 5: Social; in-account      
- 6: Personal; email          
- 7: Personal; in-account    

First, compare differences in limit setting frequency across all conditions (no specific hypothesis, but pre-registered as a confirmatory test as it tests the overall effect of group):
``` {r warnings = FALSE, message = FALSE}
primary.outcome.table<- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% 
  pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  as.data.frame() %>%
 dplyr::select(LimitSetter,
         None) %>%
  print()
```

Run Chi-square analysis:
```{r warnings = FALSE, message = FALSE}
hyp.chi<- chisq.test(primary.outcome.table)
```
Get the results in APA format:
```{r warnings = FALSE, message = FALSE}
chisq_apa(chisq.test(primary.outcome.table), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```
Calculate the effect size and confidence intervals:
```{r warnings = FALSE, message = FALSE}
Phi(primary.outcome.table)
hyp.cramer<- CramerV(primary.outcome.table, conf.level = 0.95) %>% 
  as.matrix() %>% 
  print()
```
Bayesien test equivalent:
```{r warnings = FALSE, message = FALSE}
primary.outcome.table<- as.matrix(primary.outcome.table)
hyp.bayes<- contingencyTableBF(primary.outcome.table, sampleType = "jointMulti") %>%
  as.data.frame() %>% 
  print()
```

## Test Hypothesis 1
Compare differences in limit setting frequency between controls and all messaging conditions combined:
``` {r warnings = FALSE, message = FALSE}
# Isolate the messaging conditions and conflate their outcomes:
messagecondition.limit.summary<- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition != "1") %>%
  as.data.frame() %>%
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>%
 dplyr::select(NoLimit,
         LimitSetter) %>%
  print() 

# Isolate outcomes from controls:
controlcondition.limit.summary<- hypothesis.test.data %>%
  distinct(customerid, .keep_all = TRUE) %>%
  group_by(condition,
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter, 
          None) %>%
  filter(condition == "1") %>%
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>%
  as.data.frame() %>%
 dplyr::select(NoLimit,
         LimitSetter) %>%
  print() 

# Merge the two datasets created here:
# NOTE: when joining, for ORs to properly compute: "This is where the orientation of the contingency table is critical, i.e., with the unexposed (reference) group in the first row and the subjects without the outcome in the first column."
# See OR function page: https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module8-CategoricalData/PH717-Module8-CategoricalData6.html

primary.outcome.table1<- bind_rows(controlcondition.limit.summary,
                                   messagecondition.limit.summary) %>%
  as.matrix() %>%
  print() 

```
Run Chi-square analysis:
```{r}
hyp1.chi <- chisq.test(primary.outcome.table1)
```
Get the results in APA format:
```{r}
chisq_apa(chisq.test(primary.outcome.table1), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```
Calculate the effect size and confidence intervals (write computation for objects for each to guide later insertion of these into the paper):
```{r warnings = FALSE, message = FALSE}
hyp1.ORframe <- oddsratio.wald(primary.outcome.table1) %>% 
  print()

# OR:
hyp1.ORframe$measure[2, 1]
# Lower CI:
hyp1.ORframe$measure[2, 2]
# UpperCI:
hyp1.ORframe$measure[2, 3]
```

#### Bayesian test of Hypothesis 1
``` {r}
hyp1.bayes<- contingencyTableBF(primary.outcome.table1, sampleType = "jointMulti" ) %>%
  as.data.frame() %>% 
  print()
```
Further info on the Bayesian test of association used: https://learningstatisticswithr.com/book/bayes.html#bayescontingency

#### Relative difference in proportions for Hypothesis 1
``` {r}
# Calculate proportion of limit setters in each group and the difference between the two:
# Messaging groups:
messageconditions.hyp1.relative<- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition != "1") %>%
  as.data.frame() %>%
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>%
  mutate(proportion_message_groups = LimitSetter/(LimitSetter + NoLimit)*100) %>%
 dplyr::select(proportion_message_groups) %>%
  print() 

# Controls:
controls.hyp1.relative<- hypothesis.test.data %>%
  distinct(customerid, .keep_all = TRUE) %>%
  group_by(condition,
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter, 
          None) %>%
  filter(condition == "1") %>%
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>%
 mutate(proportion_controls = LimitSetter/(LimitSetter + NoLimit)*100) %>%
dplyr::select(proportion_controls) %>%
 print() 
  
controls.hyp1.relative %>%
  bind_cols(messageconditions.hyp1.relative) %>%
  mutate(proportional_difference = proportion_message_groups - proportion_controls)
```
The proportion of limit setters was greater by 0.631 in the message groups compared to the control group. 

## Test Hypothesis 2
Compare differences in limit setting frequency between messages with different content (I.e., Informative, social, and personal messages):

``` {r warnings = FALSE, message = FALSE}
# First, provide some tables for the each of 3 pairs of conditions in which participants are sent the same form of message content
# Informative message conditions:
informative.conditions.summary <- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition == "2" |
           condition == "3") %>%
  as.data.frame() %>% 
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>% 
 dplyr::select(NoLimit,
         LimitSetter) %>%
  print() # Isolate the Informative messaging conditions and conflate their outcomes

# Social message conditions:
social.conditions.summary <- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition == "4" |
           condition == "5") %>%
  as.data.frame() %>% 
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>% 
 dplyr::select(NoLimit,
         LimitSetter) %>%
  print() # Isolate the social messaging conditions and conflate their outcomes

# Personal message conditions:
personal.conditions.summary <- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition == "6" |
           condition == "7") %>%
  as.data.frame() %>% 
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>% 
 dplyr::select(NoLimit,
         LimitSetter) %>%
  print() # Isolate the personal messaging conditions and conflate their outcomes
```

### Hypothesis 2.1
First content comparison analysis: Social messages (i.e., conditions  4 & 5) vs. Informative messages (i.e, conditions 2 & 3):
```{r warnings = FALSE, message = FALSE}
#  Remember, it needs to be laid out with "the unexposed (reference) group in the first row and the subjects without the outcome in the first column."
primary.outcome.table2<- bind_rows(informative.conditions.summary,
                                   social.conditions.summary) %>%
  as.matrix() %>%
  print()
```
Run Chi-square analysis:
```{r warnings = FALSE, message = FALSE}
hyp2.1chi <- chisq.test(primary.outcome.table2)
```
Get the results in APA format:
```{r warnings = FALSE, message = FALSE}
chisq_apa(chisq.test(primary.outcome.table2), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```
Calculate the effect size and confidence intervals:
```{r warnings = FALSE, message = FALSE}
hyp2.1ORframe <- oddsratio.wald(primary.outcome.table2) %>%
  print()
```

#### Bayesian test of Hypothesis 2.1
```{r warnings = FALSE, message = FALSE}
hyp2.1bayes<- contingencyTableBF(primary.outcome.table2, sampleType = "jointMulti" ) %>%
  as.data.frame() %>% 
  print()
```

#### Relative difference in proportions for Hypothesis 2.1
``` {r}
# Calculate proportion of limit setters in each group and the difference between the two:
# Social:
social.hyp2.relative<- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition == "4" |
           condition == "5") %>%
  as.data.frame() %>% 
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>% 
  mutate(proportion_social = LimitSetter/(LimitSetter + NoLimit)*100) %>%
 dplyr::select(proportion_social) %>%
  print() 

# Informative:
informative.hyp2.relative<-  hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition == "2" |
           condition == "3") %>%
  as.data.frame() %>% 
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>% 
 mutate(proportion_informative = LimitSetter/(LimitSetter + NoLimit)*100) %>%
dplyr::select(proportion_informative) %>%
 print() 
  
social.hyp2.relative %>%
  bind_cols(informative.hyp2.relative) %>%
  mutate(proportional_difference = proportion_social - proportion_informative)
```
The proportion of limit setters was greater by 0.087 in the social message groups compared to the informative message groups. 

### Hypothesis 2.2
Second content comparison analysis: Personal messages (i.e., conditions  6 & 7) versus Informative messages (i.e, conditions 2 & 3):
```{r warnings = FALSE, message = FALSE}
#  Remember, it needs to be laid out with "the unexposed (reference) group in the first row and the subjects without the outcome in the first column."
primary.outcome.table3<- bind_rows(informative.conditions.summary,
                                   personal.conditions.summary)%>%
  as.matrix() %>%
  print()
```
Run Chi-square analysis:
```{r warnings = FALSE, message = FALSE}
hyp2.2chi <- chisq.test(primary.outcome.table3)
```
Get the results in APA format:
```{r warnings = FALSE, message = FALSE}
chisq_apa(chisq.test(primary.outcome.table3), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```
Calculate the effect size and confidence intervals:
```{r warnings = FALSE, message = FALSE}
hyp2.2ORframe <- oddsratio.wald(primary.outcome.table3) %>%
  print()
```

#### Bayesian test of hypothesis 2.2
```{r warnings = FALSE, message = FALSE}
hyp2.2bayes<- contingencyTableBF(primary.outcome.table3, sampleType = "jointMulti" ) %>%
  as.data.frame() %>% 
  print()
```             

#### Relative difference in proportions for Hypothesis 2.2
``` {r}
# Calculate proportion of limit setters in each group and the difference between the two:
# Personal:
personal.hyp2.relative<- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition == "6" |
           condition == "7") %>%
  as.data.frame() %>% 
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>% 
  mutate(proportion_personal = LimitSetter/(LimitSetter + NoLimit)*100) %>%
 dplyr::select(proportion_personal) %>%
  print() 

# Informative:
informative.hyp2.relative
  
personal.hyp2.relative %>%
  bind_cols(informative.hyp2.relative) %>%
  mutate(proportional_difference = proportion_personal - proportion_informative)
```
The proportion of limit setters was smaller by -0.139 in the personal message groups compared to the informative message groups. 

### Hypothesis 2.3
Third content comparison analysis: Social messages (i.e., conditions  4 & 5) versus Personal messages (i.e., conditions  6 & 7):
```{r warnings = FALSE, message = FALSE}
primary.outcome.table4<- bind_rows(personal.conditions.summary,
                                   social.conditions.summary) %>%
  as.matrix() %>%
  print()
```
Run Chi-square analysis:
```{r warnings = FALSE, message = FALSE}
hyp2.3chi <- chisq.test(primary.outcome.table4)
```
Get the results in APA format:
```{r warnings = FALSE, message = FALSE}
chisq_apa(chisq.test(primary.outcome.table4), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```
Calculate the effect size and confidence intervals:
```{r warnings = FALSE, message = FALSE}
hyp2.3ORframe <- oddsratio.wald(primary.outcome.table4) %>%
  print()
```

#### Bayesian test of hypothesis 2.3
```{r warnings = FALSE, message = FALSE}
hyp2.3bayes<- contingencyTableBF(primary.outcome.table4, sampleType = "jointMulti" ) %>%
  as.data.frame() %>% 
  print()
```

#### Relative difference in proportions for Hypothesis 2.3
``` {r}
# Calculate proportion of limit setters in each group and the difference between the two:
# Social:
social.hyp2.relative
# Personal:
personal.hyp2.relative
  
personal.hyp2.relative %>%
  bind_cols(social.hyp2.relative) %>%
  mutate(proportional_difference = proportion_social - proportion_personal)
```
The proportion of limit setters was greater by 0.227 in the social message groups compared to the personal message groups. 

## Test hypothesis 3
Compare differences in limit setting frequency between in-account (i.e., conditions 2, 4, & 6) versus email (i.e., conditions 3, 5, & 7) messaging conditions combined
```{r warnings = FALSE, message = FALSE}
# Isolate the EMAIL messaging conditions and conflate their outcomes:
email.conditions.summary<- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition != "1" & 
           condition != "3" & 
           condition != "5" & 
           condition != "7") %>%
  as.data.frame() %>% 
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>% 
 dplyr::select(NoLimit,
         LimitSetter) %>%
  print() 

# Isolate the IN-ACCOUNT messaging conditions and conflate their outcomes:
inaccount.conditions.summary<- hypothesis.test.data %>%
  group_by(condition, window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  filter(condition != "1" & 
           condition != "2" & 
           condition != "4" & 
           condition != "6") %>%
  as.data.frame() %>%
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>%
 dplyr::select(NoLimit,
         LimitSetter) %>%
  print() 

# Merge:
primary.outcome.table5<- bind_rows(email.conditions.summary,
                                     inaccount.conditions.summary) %>%
  as.matrix() %>%
  print()
```
Run Chi-square analysis:
```{r warnings = FALSE, message = FALSE}
hyp3.chi <- chisq.test(primary.outcome.table5)
```
Get the results in APA format:
```{r warnings = FALSE, message = FALSE}
chisq_apa(chisq.test(primary.outcome.table5), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```
Calculate the effect size and confidence intervals:
```{r warnings = FALSE, message = FALSE}
hyp3.ORframe <- oddsratio.wald(primary.outcome.table5) %>%
  print()
```

### Bayesian test of hypothesis 3
```{r warnings = FALSE, message = FALSE}
hyp3.bayes<- contingencyTableBF(primary.outcome.table5, sampleType = "jointMulti" ) %>%
  as.data.frame() %>% 
  print()
```
<br><br>

#### Relative difference in proportions for Hypothesis 3
``` {r}
# Calculate proportion of limit setters in each group and the difference between the two:
# EMAIL:
email.hyp3.relative<- hypothesis.test.data %>%
  group_by(condition, 
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  ungroup(LimitSetter,
          None) %>%
  filter(condition != "1" & 
           condition != "3" & 
           condition != "5" & 
           condition != "7") %>%
  as.data.frame() %>% 
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>% 
  mutate(proportion_email = LimitSetter/(LimitSetter + NoLimit)*100) %>%
 dplyr::select(proportion_email) %>%
  print() 

# IN-ACCOUNT:
inaccount.hyp3.relative<- hypothesis.test.data %>%
  group_by(condition, window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  filter(condition != "1" & 
           condition != "2" & 
           condition != "4" & 
           condition != "6") %>%
  as.data.frame() %>%
  dplyr::summarise(
    LimitSetter = sum(LimitSetter),
    NoLimit = sum(None)
  ) %>%
  mutate(proportion_inaccount = LimitSetter/(LimitSetter + NoLimit)*100) %>%
 dplyr::select(proportion_inaccount) %>%
  print() 

inaccount.hyp3.relative %>%
  bind_cols(email.hyp3.relative) %>%
  mutate(proportional_difference = proportion_inaccount - proportion_email)
```
The proportion of limit setters was greater by 0.309 in the in-account message groups compared to the email message groups. 

# --------------------------------------------------------------------------------

<center>
# Exploratory analyses
</center>

## Additional limit setting comparison
Compare differences in limit setting frequency between all messaging conditions only:
```{r warnings = FALSE, message = FALSE}
primary.outcome.table6<- hypothesis.test.data %>%
  filter(condition != "1") %>%
  group_by(condition,
           window_limit_setter) %>%
  dplyr::summarise(
    n = n()
  ) %>% pivot_wider(names_from = window_limit_setter, values_from = n) %>%
  as.data.frame() %>%
 dplyr::select(LimitSetter, 
         None) %>%
  print()
```
Run Chi-square analysis:
```{r warnings = FALSE, message = FALSE}
chisq.test(primary.outcome.table6)
```
Get the results in APA format:
```{r warnings = FALSE, message = FALSE}

chisq_apa(chisq.test(primary.outcome.table6), 
          print_n = TRUE,
          format = "html",
          info = FALSE,
          print = TRUE)
```
Calculate the effect size and confidence intervals:
```{r warnings = FALSE, message = FALSE}
Phi(primary.outcome.table6)
CramerV(primary.outcome.table6, conf.level = 0.95)
```

Bayesien test equivalent:
```{r warnings = FALSE, message = FALSE}
primary.outcome.table6<- as.matrix(primary.outcome.table6)
contingencyTableBF(primary.outcome.table6, sampleType = "jointMulti")
```
<br><br>

# Logistic regression: Predictors of limit setting

Details specified in preregistration:

- "For logistic regressions (i.e., analyses relating to outcome 1 & 2), if multicollinearity between predictor variables exists (variable inflation factors will be reported and those >5  will be considered as indicators of multicollinearity) then this will be reported but no variables will be removed from the analysis. If outliers are detected (defined as cases with standardised residuals >±2 in case-wise diagnostics) analyses will be completed and reported with and without their inclusion.  If the relationship between a continuous predictor variable is not linearly related to the logit of the dependent variable (Box-Tidwell approach; a Bonferroni correction will be applied, dividing alpha by the total number of terms in the model to determine an appropriate threshold for detecting non-linearity; Tabachnick & Fidell, 2014), the predictor variable will be transformed. The variable will be transformed using a power transformation  to raise the variable to the power of lambda (λ), the specific value of which will be calculated using the below formula λ=1+(B/γ). For logistic regressions, the enter method will be used to input variables into the model. No interaction terms will be entered into the models. The Omnibus tests of model coefficients significance value will be used to estimate the overall fit of models. Wald’s test will be used to determine the statistical significance of individual predictor variables. B coefficients and unadjusted standard errors will be reported. Odds ratios and Nagelkerke pseudo R2 will be also reported for logistic regressions."

<br>
 
There have since been some changes to the pre-registered plan for this analysis which can be found in our "Transparent changes document": https://osf.io/6dpkw/
<br>

Make the data workable for the regression model:
```{r warnings = FALSE, message = FALSE}
predictors.limitsetting.data<- hypothesis.test.data %>%
  dplyr::select(window_limit_setter,
         limit_setter_pre,
         operator,
         age,
         gender,
         betting_days_frequency_pre,
         average_daily_wager_pre,
         betting_intensity_pre,
         net_loss_pre,
         lost_last_bet,
         daily_wager_SD_pre) %>%
  filter(operator != "4") 
# Remove those from operator 4 as nobody set a limit within this group and including this group will result in the following error when running the regression model as it perfectly splits the group:
# "glm.fit: fitted probabilities numerically 0 or 1 occurred"
# For categorical variables, see which level is the reference group and which is the predicted/ compared with group:
# contrasts(predictors.limitsetting.data$limit_setter_pre) # Being a previous limits setter is the predicted group
# contrasts(predictors.limitsetting.data$gender) 
# contrasts(predictors.limitsetting.data$operator) 
predictors.limitsetting.data$window_limit_setter <-  as.factor(predictors.limitsetting.data$window_limit_setter) # Make the outcome variable a factor
predictors.limitsetting.data$window_limit_setter <-  relevel(predictors.limitsetting.data$window_limit_setter, ref = "None") # Put the reference group as those who don't set limits so we can predict who does
```
### Run model exactly as preregistered
Logistic regression:
```{r warnings = FALSE, message = FALSE}
LG.predictors.limitsetting <- glm(window_limit_setter ~ age +
                                    gender + 
                                    operator +
                                    betting_days_frequency_pre +
                                    average_daily_wager_pre +
                                    betting_intensity_pre +
                                    net_loss_pre +
                                    lost_last_bet +
                                    daily_wager_SD_pre +
                                    limit_setter_pre, data = predictors.limitsetting.data, family = "binomial") 
# View summary of outcomes:
summary(LG.predictors.limitsetting) 
```

Check variable inflation factors for evidence of multicollinearity:
```{r warnings = FALSE, message = FALSE}
vif(LG.predictors.limitsetting) 
```
High VIFs for average_daily_wager_pre & daily_wager_SD_pre, unsurprisingly.
<br>

Let's remove one of the above variables from the model and lost_last_bet as this variable is unreliable as the date given for wagers is for when the bet was placed and not the outcome was determined.

### Run updated model without high VIF & unreliable variables
Logistic regression:
```{r warnings = FALSE, message = FALSE}
LG.predictors.limitsetting.2 <- glm(window_limit_setter ~ age +
                                    gender + 
                                    operator +
                                    betting_days_frequency_pre +
                                    average_daily_wager_pre +
                                    betting_intensity_pre +
                                    net_loss_pre +
                                    # lost_last_bet + #Remove this variable 
                                    # daily_wager_SD_pre + # Remove this variable
                                    limit_setter_pre,
                                    data = predictors.limitsetting.data, family = "binomial") 
 # View summary of outcomes:
summary(LG.predictors.limitsetting.2)
```

Check variable inflation factors for evidence of multicollinearity:
```{r warnings = FALSE, message = FALSE}
vif(LG.predictors.limitsetting.2)
```
Calculate standardised residuals to identify and remove outliers:
```{r warnings = FALSE, message = FALSE}
# Calculate residuals and other model data:
model.data <- augment(LG.predictors.limitsetting.2) %>% 
  mutate(index = 1:n()) 
# See how many outliers they are in the data:
model.data %>% 
  filter(abs(.std.resid) > 3 |
           abs(.std.resid) < -3 ) %>%
  nrow()
```

#### Use the boxTidwell approach to test whether the continuous predictor variables are linearly related to the logit of the dependent variable:
```{r message=FALSE, warning=TRUE, results = FALSE}
# boxTidwell(window_limit_setter ~ age +
#              # gender + Omit as a categorical variable
#              # operator + Omit as a categorical variable
#              betting_days_frequency_pre +
#              # average_daily_wager_pre +
#              betting_intensity_pre +
#              # net_loss_pre + Omit as this contains negative values and this approach does not work with these
#              # lost_last_bet + Omit
#              daily_wager_SD_pre + # Omit
#              limit_setter_pre, data = predictors.limitsetting.data)
```
Getting an error messages when running the above Boxtidwell analysis. Run diagnostics:
```{r warnings = FALSE, message = FALSE}
# First check there are no NAs in the data:
anyNA(predictors.limitsetting.data) # Nope
# Additional solutions identified: convert the data to a data frame, remove values == 0, and convert the outcome variable to numeric:
predictors.limitsetting.data.temp<- predictors.limitsetting.data %>%
  filter(betting_days_frequency_pre >= 1,
  average_daily_wager_pre >= 1,
  betting_intensity_pre >= 1,
  net_loss_pre >= 1,
  daily_wager_SD_pre >= 1) %>% 
  mutate(window_limit_setter_binary = fct_recode(window_limit_setter,
                                        "1" = "LimitSetter",
                                        "2" = "None")) %>% 
  as.data.frame()
predictors.limitsetting.data.temp$window_limit_setter_binary<- as.numeric(predictors.limitsetting.data.temp$window_limit_setter_binary)
```
Now try and re-run boxTidwell analysis:
```{r warnings = FALSE, message = FALSE}
# boxTidwell(window_limit_setter_binary ~ age +
#               betting_days_frequency_pre +
#               average_daily_wager_pre +
#               betting_intensity_pre, 
#               other.x= ~window_limit_setter + gender + operator + limit_setter_pre + net_loss_pre + lost_last_bet + daily_wager_SD_pre, # variables to omit
#               data = predictors.limitsetting.data.temp)
```
The variable "average_daily_wager_pre" is not linearly relaed to the logit of the DV. Let's take a look at the distribution of this variable:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
hist(predictors.limitsetting.data.temp$average_daily_wager_pre)
```
<br>

It highly skewed (positively). Let's transform this variable using the square root transformation which is suitable for positively skewed data:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
average_daily_wager_pre_sqrt = sqrt(predictors.limitsetting.data.temp$average_daily_wager_pre)
# Now plot the distribution of this variable again to see if it has changed:
hist(average_daily_wager_pre_sqrt) 
```
<br>

The data is still very heavily skewed. Let's try a stronger transformation. Cubed transformation:
```{r warnings = FALSE, message = FALSE, fig.align = 'center',}
average_daily_wager_pre_cubed = sign(predictors.limitsetting.data.temp$average_daily_wager_pre)* abs(predictors.limitsetting.data.temp$average_daily_wager_pre)^(1/3) 
# Again, plot the distribution of this variable again to see if it has changed:
hist(average_daily_wager_pre_cubed)
```
<br>

This seems much better. Isolate this variable and the outcome variables so that we can check it's relation with the logit of the DV (i.e. Box Tidwell):
```{r warnings = FALSE, message = FALSE}
predictors.limitsetting.data.temp2 <- predictors.limitsetting.data.temp %>%
  mutate(average_daily_wager_pre_cuberoot = average_daily_wager_pre^(1/3)) %>%
  dplyr::select(window_limit_setter_binary,
         average_daily_wager_pre_cuberoot)
predictors.limitsetting.data.temp2$window_limit_setter_binary<- as.numeric(predictors.limitsetting.data.temp2$window_limit_setter_binary)
# Rerun Box Tidwell analysis for the newly transformed variable:
boxTidwell(window_limit_setter_binary ~
           average_daily_wager_pre_cuberoot,
           other.x= NULL, 
           data = predictors.limitsetting.data.temp2)
```
The relationship between this variable and the DV is no longer an issue with our Bonferroni adjusted alpha level (as we stated in our preregistration we would divide it by the number of terms to be included in the model: 0.05/7 = 0.007142857).

### Final regression analysis with no outliers & transformed variable
Prepare the data:
```{r warnings = FALSE, message = FALSE}
# Create subsetted, usable dataframe (without outliers):
updated_model_data <- model.data %>% 
  filter(abs(.std.resid) < 3) %>%
  mutate(average_daily_wager_pre_cuberoot = average_daily_wager_pre^(1/3))  
# ensure variables are in correct format:
updated_model_data$operator<- as.factor(updated_model_data$operator)
# Put the reference group as those who don't set limits so we can predict who does:
updated_model_data$window_limit_setter <-  as.factor(updated_model_data$window_limit_setter) 
updated_model_data$window_limit_setter <-  relevel(updated_model_data$window_limit_setter, ref = "None") 
updated_model_data$limit_setter_pre <- as.factor(updated_model_data$limit_setter_pre)
contrasts(updated_model_data$limit_setter_pre) # Being a previous limits setter is the predicted group
```
Run final model:
```{r warnings = FALSE, message = FALSE}
LG.predictors.limitsetting.final <- glm(window_limit_setter ~ 
                                      operator +
                                      betting_days_frequency_pre +
                                      average_daily_wager_pre_cuberoot +
                                      age +
                                      betting_intensity_pre +
                                      # net_loss_pre+ # Retaining this variable in the model results in the following warning message:
                                      # "glm.fit: fitted probabilities numerically 0 or 1 occurred". Hence, it is removed from the model. 
                                      # However, this is strange as this morning message usually occurs when a variable perfectly discriminates between the outcomes and the coefficient isn't very large: -8.194e-06.
                                      # Still, removing it seems to reduce the coeffients of other variables, indicating that it was leading to inflated values.
                                      # lost_last_bet, # Remove this variable (Unreliable data)
                                      # daily_wager_SD_pre + # Remove this variable (High VIF)
                                      gender + 
                                      limit_setter_pre,
                                      data = updated_model_data, family = "binomial") 
```
Calculate various summary figures for the model:
```{r warnings = FALSE, message = FALSE, result = 'asis'}
# View summary of outcomes:
summary(LG.predictors.limitsetting.final) 
# Check variable inflation factors for evidence of multicollinearity:
vif(LG.predictors.limitsetting.final)
# View confidence intervals for the coefficient estimates:
sumarisedCIs<- confint(LG.predictors.limitsetting.final) 
kable(sumarisedCIs %>% 
     as.data.frame(), caption = "Rounded 95% CIs for regression coefficients",
     digits = 2,
     col.names = c("Lower CI: 2.5%", "Upper CI: 97.5%")) %>%
    kable_classic(full_width = F, html_font = "Cambria") # View rounded CI values
```
<br>
```{r warnings = FALSE, message = FALSE, result = 'asis'}
# Exponentiate coefficients and interpret them as odds-ratios:
sumarisedORs<- exp(cbind(OR = coef(LG.predictors.limitsetting.final), confint(LG.predictors.limitsetting.final))) 
kable(sumarisedORs %>% 
  as.data.frame(),
     caption = "Rounded 95% CIs for regression coefficients",
     digits = 2,
     col.names = c("OR", "Lower CI: 2.5%", "Upper CI: 97.5%")) %>%
    kable_classic(full_width = F, html_font = "Cambria") # View rounded OR values
```
<br>
```{r warnings = FALSE, message = FALSE}
# Calculate Nagelkerke's R squared for the model
NagelkerkeR2<- NagelkerkeR2(LG.predictors.limitsetting.final) %>% 
  as.data.frame() %>%
  print()
# N = The number of observations in which the model were fitted
# R2 = Nagelkerke's R squared value
# NOTE: R2 is calculate as a proportion here and so in the paper we have multiplied it by 100 to form a percentage value
# Calculate overall p-value for model by comparing it with a null model:
lgr.model<- anova(LG.predictors.limitsetting.final, 
      update(LG.predictors.limitsetting.final, ~1), # update here produces null model for comparison 
      test="Chisq")
lgr.model
lgr.model.ps<- lgr.model$`Pr(>Chi)` %>% as.matrix()
lgr.model.p <- lgr.model.ps[2,]
if(lgr.model.p <.001){print(".001")} else{print(lgr.model.p)}
lgr.model.n <- nrow(updated_model_data)
# Analysis of variance for individual terms (Wald's test):
Anova(LG.predictors.limitsetting.final, type="II", test="Wald")
# Test overall effect of gender:
wald.test(b = coef(LG.predictors.limitsetting.final), Sigma = vcov(LG.predictors.limitsetting.final), Terms = 3:4)
# Test overall effect of operator:
wald.test(b = coef(LG.predictors.limitsetting.final), Sigma = vcov(LG.predictors.limitsetting.final), Terms = 5:6)
```
#### Plot Logistic regression output
```{r warnings = FALSE, message = FALSE, fig.align = 'center', fig.height = 8, fig.width = 3.5}
# Set seed so that labels are consistent in the plot:
set.seed(200)
Regressionplot <- ggstatsplot::ggcoefstats(LG.predictors.limitsetting.final,
                         vline.args = list(size = 1, color = "#56B4E9"),
                         ggstatsplot.layer = FALSE,
                          exclude.intercept = TRUE, # hide the intercept
                         stats.label.args = list(size = 1.8, direction = "y"),) +
  scale_x_continuous(name = "Regression coefficient", limits = c(-3.2, 10), breaks = c(0, 5, 10, 15, 20, 25, 30)) +
  scale_y_discrete(name = "", labels = c("Operator 3",
                                         "Operator 2",
                                         "Betting 
                                          frequency",
                                         "Average 
                                          daily wager",
                                         "Age",
                                         "Betting 
                                          intensity",
                                         "Male 
                                            gender",
                                         "Unknown 
                                         gender",
                                         "Previous 
                                          limit set")) +
  theme(panel.grid.minor = element_blank(),
        axis.line = element_blank()) +
  # theme(axis.text = element_text(color = "black", size = 7, face = "plain"))+
  theme_light(base_family = "Poppins") +
  theme(plot.margin = unit(c(.1,.1,.3,-3), "cm")) +
  theme(axis.text.y = element_text(color="black", size=8, face="plain", family = "Poppins")) +
  theme(axis.title.x = element_text(color="black", size=10, face ="plain", vjust = -1, family = "Poppins")) 

# View new plot:
Regressionplot
# Save Plot:
ggsave("Figures/Regressionplot.pdf",
       width = 80,
       height = 150,
       units = c("mm")
)
```
<br><br>

## Comparisons of pre & post wagering activity between limit setters and non-limit setters

Pre-registered definition of groups:

- "When comparing the gambling behaviour of those who set a limit with those who do not  the former group are defined as those who set a limit within 5 days of receiving a message (Time 1 or 2,  depending on whether they set a limit at the former) and the latter group those who do not set a limit (regardless of whether they open messages sent to them). To prevent group sizes from being substantially uneven (only a small proportion of customers are expected to set limits), we will randomly dselect the same number of customers who set limits (n?) from the non-limit setting group. This will be achieved using the procedure described in Section 2.3.3 to randomly order participants, selecting the first n? customers. To ensure consistency between groups in relation to the length of time-periods in which behavioural data  are collected, for limit setters this period will be 90 days pre and post the day they set a limit and for non-limit setters this period will be 90 days pre and post the Time 1 message"

#### Prepare data
We can start with the data used for hypothesis testing as anyone excluded from those analyses will also be ineligible for inclusion in exploratory analyses. But we need to clean the data according to the additional specific eligibility criteria for this study. First we need to remove anyone self excluded or closed their account before two weeks post-message 1 (non-setters) and two weeks post-limit date (for limit setters). This will ensure there is sufficient wagering activity to perform analyses.
<br>

Double check what 14 days post-message 1 is for all non-limit setters:
```{r warnings = FALSE, message = FALSE}
as.Date("2019-10-14") + 14
```

We need to split filters for eligibility by limit-setter/non-setter as they have different date periods of interest. Start with **non-limit setters**
<br>

Identify all **non-limit setters** who **closed their account** within two weeks of receiving message one:
```{r warnings = FALSE, message = FALSE}
post.message.account.closers.nonsetters<- hypothesis.test.data %>%
  filter(date_account_closed >=  as.Date("2019-10-14")  &
           date_account_closed <=  as.Date("2019-10-28") &
           window_limit_setter == "None") %>%
 dplyr::select(date_account_closed,
         self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         customerid,
         operator,
         window_limit_setter)

nrow(post.message.account.closers.nonsetters)
```
11 people closed their account during this window (several account closers from the early part of this window were already excluded above for hypothesis tests)
<br>

Identify all **non-limit setters** who **self-excluded** within two weeks of receiving message one:
```{r warnings = FALSE, message = FALSE}
post.message.self.excluders.nonsetters<- hypothesis.test.data %>%
  filter(self_exclusion_start_date >=  as.Date("2019-10-14") &
           self_exclusion_start_date <=  as.Date("2019-10-28") &
           window_limit_setter == "None") %>%
 dplyr::select(self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         customerid,
         operator,
         window_limit_setter) 

nrow(post.message.self.excluders.nonsetters)
```
1 person self excluded during this window (several self-exlcuders from the early part of this window were already excluded above for hypothesis tests)
<br>

Next we need to exclude any **non-limit setters** who used **an extended timeout** during the 90 days post-message one that will have resulted in them having less than two weeks of wagering activity. For this to occur, the person will have needed to take a timeout on any date during the first 14 days post-message one for a duration that is equal to or longer than 76 days (i.e., 90-14).
```{r warnings = FALSE, message = FALSE}
post.message.extended.time.out.nonsetters<- hypothesis.test.data %>%
  filter(timeout_start_date_post >=  as.Date("2019-10-14")  &
           timeout_start_date_post <=  as.Date("2019-10-28") &
           timeout_duration_post >= 76 &
           window_limit_setter == "None") %>%
 dplyr::select(timeout_duration_post,
         timeout_start_date_post,
         timeout_finish_date_post,
         timeout_post,
         customerid,
         operator,
         window_limit_setter)

nrow(post.message.extended.time.out.nonsetters)
```
12 people went on extended timeouts during this window (ranging in duration from 63 days [i.e ~3 months] to 1,828 days [i.e ~5 years])
<br>

Now let's do the same for **limit setters**:
<br>

Identify all **limit setters** who **closed their account** within two weeks of setting a limit:
```{r warnings = FALSE, message = FALSE}
post.message.account.closers.setters<- hypothesis.test.data %>%
  mutate(post.limit.date = window_limit_date + days(14)) %>%
  filter(date_account_closed >=  window_limit_date  &
           date_account_closed <=  post.limit.date &
           window_limit_setter == "LimitSetter") %>%
 dplyr::select(date_account_closed,
         self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         customerid,
         operator,
         window_limit_setter)
nrow(post.message.account.closers.setters)
```
6 people closed their accounts within two weeks of setting their limit
<br>

Identify all **limit setters** who **self-excluded** within two weeks of setting a limit:
```{r warnings = FALSE, message = FALSE}
post.message.self.excluders.setters<- hypothesis.test.data %>%
  mutate(post.limit.date = window_limit_date + days(14)) %>%
  filter(self_exclusion_start_date >=  window_limit_date  &
           self_exclusion_start_date <=  post.limit.date &
           window_limit_setter == "LimitSetter") %>%
 dplyr::select(self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         customerid,
         operator,
         window_limit_setter)

nrow(post.message.self.excluders.setters)
```
2 people closed their accounts during this window (both were self–excluders included in the above group).
<br>

Next we need to exclude any **limit setters** who used **an extended timeout** during the 90 days post-limit one that will have resulted in them having less than two weeks of wagering activity. For this to occur, the person will have needed to take a timeout on any date during the first 14 days post-limit one for a duration that is equal to or longer than 76 days (i.e., 90-14):
```{r warnings = FALSE, message = FALSE}
post.message.extended.time.out.setters<- hypothesis.test.data %>%
  mutate(post.limit.date = window_limit_date + days(14)) %>%
  filter(timeout_start_date_post >=  window_limit_date  &
           timeout_start_date_post <=  post.limit.date &
           window_limit_setter == "LimitSetter") %>%
  filter(timeout_duration_post >= 76) %>%
 dplyr::select(timeout_duration_post,
         timeout_start_date_post,
         timeout_finish_date_post,
         timeout_post,
         operator,
         customerid,
         window_limit_setter)

nrow(post.message.extended.time.out.setters)
```
2 people went on extended timeouts during this window (ranging in duration from 93 days to 183 days [i.e ~6 months])
<br>

How many people set a limit after the messaging window: 
```{r warnings = FALSE, message = FALSE}
hypothesis.test.data %>% filter(limit_setter_post != "None") %>% 
  nrow()
```
344, roughly twice the number to set limits in just 10 days post-messages

#### Filter dataset for pre-post wagering comparisons
Now filter out all of the people do not meet the eligibility criteria for inclusion in these analyses and make a final dataset for use.
```{r warnings = FALSE, message = FALSE}
exploratory.wagering.analysis.data<- hypothesis.test.data %>%
  anti_join(post.message.account.closers.nonsetters, by = "customerid") %>%
  anti_join(post.message.self.excluders.nonsetters, by = "customerid") %>%
  anti_join(post.message.extended.time.out.nonsetters, by = "customerid") %>% 
  anti_join(post.message.extended.time.out.setters, by = "customerid") %>%
  anti_join(post.message.account.closers.setters, by = "customerid") %>%
  anti_join(post.message.self.excluders.setters, by = "customerid") %>%
  anti_join(post.message.extended.time.out.setters, by = "customerid") %>%
  filter(limit_setter_post == "None") %>% # Remove all those non-setters who set a limit in the 90 days post message 1 (this doesn't remove any limit setters from our key group)
  filter(condition != "1") # Remove all those from condition 1, including any limit setters [n = 3] (we only want to compare within those who received messages)
  
nrow(exploratory.wagering.analysis.data)

# Randomly check for customerids of those who self excluded or closed their accounts to check the anti-joins worked:
# exploratory.wagering.analysis.data %>%
#   filter(customerid == "******" | 
#            customerid == "******") # Removed for anonymity 
```

#### Randomly select cohort from non-limit setters

First, how many limits setters do we have after removing ineligible participants?
```{r warnings = FALSE, message = FALSE}
table(exploratory.wagering.analysis.data$window_limit_setter)
```
How are these divided across the conditions?
```{r warnings = FALSE, message = FALSE}
exploratory.wagering.analysis.data %>% 
  group_by(condition,
           window_limit_setter) %>%
  dplyr::summarise( n())
```
How are these is divided across operators?
```{r warnings = FALSE, message = FALSE}
exploratory.wagering.analysis.data %>% 
  group_by(operator,
           window_limit_setter) %>%
  dplyr::summarise( n())
```

#### Randomly select non-limit setters
Randomly select the equivalent number of non-limits setters to limit setters for each specific operator:
```{r warnings = FALSE, message = FALSE}
set.seed(50)

random.sample.controls<-exploratory.wagering.analysis.data %>%
  filter(operator != "4"  & # Remove all those from operator 4 as no one from this operator set a limit
           window_limit_setter == "None") %>% # Select only those didn't set a limit for comparison
  group_by(operator) %>% 
  nest() %>%
  ungroup() %>% 
  mutate(n = c(100, 18, 35)) %>% # the number of limit setters from operator 1, 2 and 3 respectively.
  mutate(samp = map2(data, n, sample_n)) %>% 
 dplyr::select(-data) %>%
  unnest(samp)
```
Check this has randomly sampled the correct number of non-setters per operator:
```{r warnings = FALSE, message = FALSE}
random.sample.controls %>% 
  group_by(operator) %>%
  dplyr::summarise( n())
```
Merge the two datasets:
```{r warnings = FALSE, message = FALSE}
wager.comaprison.data<- exploratory.wagering.analysis.data %>%
  filter(window_limit_setter == "LimitSetter") %>% 
  bind_rows(random.sample.controls)
  
# Check this has joined correctly and there are an equal number in each group: 
wager.comaprison.data %>% 
  group_by(window_limit_setter) %>%
  dplyr::summarise( n())

# Make the primary grouping variable a factor for the following analyses:
wager.comaprison.data$window_limit_setter <- as.factor(wager.comaprison.data$window_limit_setter)
```
<br><br>

## Comparisons of pre & post average daily wager

First create a workable dataset for this comparison, including the creation of z scores to identify and remove outliers: 
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison<- wager.comaprison.data %>%
  mutate(average_daily_wager_differencescore = average_daily_wager_pre - average_daily_wager_post) %>%
  pivot_longer(c("average_daily_wager_pre",
                 "average_daily_wager_post"), 
               names_to = "Period",
               values_to = "Average_daily_wager") %>%
 dplyr::select(customerid, 
         window_limit_setter, 
         average_daily_wager_differencescore,
         Period, 
         Average_daily_wager,
         self_exclusion) %>%
  group_by(window_limit_setter,
           Period) %>%
  mutate(ave_daily_wager_zscore = (Average_daily_wager - mean(Average_daily_wager))/ sd(Average_daily_wager))
```
Identify outliers using pre-registered method and see how many cases this would remove: 
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison.outliers<- ave.daily.wager.comparison %>%
  filter(ave_daily_wager_zscore >= 3.29 |
           ave_daily_wager_zscore <= -3.29) %>%
 dplyr::select(customerid, 
         Period,
         ave_daily_wager_zscore) %>%
  ungroup() %>%
  distinct(customerid, .keep_all = TRUE)

nrow(ave.daily.wager.comparison.outliers)
```
10 participants in total, 6 limit setters and 4 non-limit setters.
<br>

Create a dataset that excludes these outliers and make all of the common column names and value names tidy for future plots:
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison$Period<- as.factor(ave.daily.wager.comparison$Period) # Make variable in factor in order to change the level names below

ave.daily.wager.comparison.sansoutliers<- ave.daily.wager.comparison %>%
  anti_join(ave.daily.wager.comparison.outliers, by = "customerid") %>% 
  ungroup() %>%
  mutate(Period = fct_recode(Period,
                                 "Pre-message" = "average_daily_wager_pre",
                                 "Post-message" = "average_daily_wager_post")) %>%
  mutate(Group = fct_recode(window_limit_setter,
                                 "Limit
                            setters" = "LimitSetter",
                                 "No limit" = "None")) %>%
  arrange(desc(Group))
```
Now that we have the final sample, let's create some summary data for this comparison.
<br>

Difference scores with CIs:
```{r warnings = FALSE, message = FALSE}
sumdat.ave.daily.wager.differencescore <- ave.daily.wager.comparison.sansoutliers %>%
  distinct(customerid, .keep_all = TRUE) %>%
  summarySE(measurevar = "average_daily_wager_differencescore",
            groupvars=c("Group")) %>%
  mutate(lowerCI = average_daily_wager_differencescore - ci,
         upperrCI = average_daily_wager_differencescore + ci)

kable(sumdat.ave.daily.wager.differencescore, caption = "Pre-post difference score with 95% CIs: Average daily wager",
      digits = 2,
      col.names = c("Group", "n", "Difference sore", "SD", "SE", "95% CI", "Lower CI: 2.5%", "Upper CI: 97.5%")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Group means, SDs, and medians pre and post-message:
```{r warnings = FALSE, message = FALSE}
kable(ave.daily.wager.comparison.sansoutliers %>%
  group_by(Period,
           window_limit_setter) %>%
  dplyr::summarise(
    n(),
    mean = mean(Average_daily_wager),
    sd = sd(Average_daily_wager),
    median = median(Average_daily_wager)),
    caption = "Pre-post summary scores: Average daily wager",
      digits = 2,
      col.names = c("Period", "Group", "n", "Mean", "SD", "Median")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Next calculate Effect sizes (dz) for the within comparison (pre-post) of scores:

- We need a t value first to include in the calculation from the MOTE Package and this needs to be done separately for each group

Create a dataset just to compare **limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison.limitsetters<- 
  anti_join(ave.daily.wager.comparison, 
            ave.daily.wager.comparison.outliers, by = "customerid") %>%
  filter(window_limit_setter == "LimitSetter")

t.test(formula = Average_daily_wager ~ Period,
       data = ave.daily.wager.comparison.limitsetters,
       paired = TRUE,
       alternative = "two.sided")

# Now calculate the effect size (limit setters):
d.dep.t.diff.t(t = -7.6916, 145, a = 0.05)
```

Create a dataset just to compare **non-limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison.nonlimitsetters<- 
  anti_join(ave.daily.wager.comparison, 
            ave.daily.wager.comparison.outliers, by = "customerid") %>%
  filter(window_limit_setter == "None") %>%
  print() 

t.test(formula = Average_daily_wager ~ Period,
       data = ave.daily.wager.comparison.nonlimitsetters,
       paired = TRUE,
       alternative = "two.sided")

# Now calculate the effect size (non-limit setters):
d.dep.t.diff.t(t = -1.4975, 150, a = 0.05)
```
 
#### ANCOVA: Average daily wager
Now run an ANCOVA to see the effect of limit setting on scores, with the difference score as the outcome and baseline scores and age as the covariates.

- Useful guide: https://www.datanovia.com/en/lessons/ancova-in-r/
- Note: we're sitll using the data sans outliers here

First filter out the "post-message" scores as we don't need these for the analysis and including these rows would result in a duplicated "average_daily_wager_differencescore" for each consumer due to the current setup of the data:
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison.sansoutliers.ANCOVA<- ave.daily.wager.comparison.sansoutliers %>%
  filter(Period == "Pre-message")

# Check there are 296 consumers remaining: 
ave.daily.wager.comparison.sansoutliers.ANCOVA %>% 
  dplyr::summarise(n_distinct(customerid)) 
```
Next, check the statical assumptions are met
<br>

Normally distributed outcome variables across groups is not required but check distribution anyway:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
# Plot distribution of variable for both groups to see whether this is normally distributed across groups:
hist_average_daily_wager_pre<-  ggplot(ave.daily.wager.comparison.sansoutliers.ANCOVA, 
                                      aes(average_daily_wager_differencescore, fill = window_limit_setter)) +
  geom_histogram(bins = 60) 

hist_average_daily_wager_pre
```
<br>

This variable is relatively centered distributed around 0 for both groups, although it is leptokurtic (kurtosis).

##### Asumption 1: No influential outliers:
Outliers have already been removed: 8 participants in total, 6 limit setters and 2 non-limit setters.

##### Asumption 2: The covariate should be linearly related to the dependent variable at each level of the independent variable:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
ggscatter(
  ave.daily.wager.comparison.sansoutliers.ANCOVA, x = "Average_daily_wager", y = "average_daily_wager_differencescore",
  color = "window_limit_setter", add = "reg.line"
)+
  stat_regline_equation(
    aes(label =  paste(..eq.label.., ..rr.label.., sep = "~~~~"), color = window_limit_setter)
  )
```
<br>

ASSUMPTION 2 MET: the covariate is linearly related to the dependent variable at each level of the independent variable, although minimally for the non-setter group.

##### Assumption 3: homogeneity of regression slope (No sig. interaction between covariate and grouping variable):
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison.sansoutliers.ANCOVA %>% anova_test(average_daily_wager_differencescore ~ window_limit_setter*Average_daily_wager)
```
ASSUMPTION 3 NOT MET: Interaction term significant.

##### Assumption 4: normality of within-group residuals:
```{r warnings = FALSE, message = FALSE}
# Compute model to calculate residuals:
norm.model1<- lm(average_daily_wager_differencescore ~ Average_daily_wager + window_limit_setter, data = ave.daily.wager.comparison.sansoutliers.ANCOVA)

# Make residuals available:
norm.model1.metrics <- augment(norm.model1) 

# Run Shapiro Wilk's test on residuals:
shapiro_test(norm.model1.metrics$.resid)
```
ASSUMPTION 4 NOT MET: non-normality of residuals

##### Assumption 5: homogeneity of variance:
```{r warnings = FALSE, message = FALSE}
leveneTest(.resid~window_limit_setter, center = mean, data = norm.model1.metrics)
```
ASSUMPTION 5 MET: homogeneity of residuals, non-sig. Levene's test
<br>

Most parametric have been violated so need to use another approach. Use Robust ANCOVA instead. Here's a useful link for info on this technique that was used to guide the ROBUST ANCOVA analysis performed here:

- https://cran.r-project.org/web/packages/WRS2/vignettes/WRS2.jpeg


#### ROBUST ANCOVA: Average daily wager
No need to remove outliers here so lets make the orginal dataset suitable for this analysis:
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison.ANCOVA<- ave.daily.wager.comparison %>%
  filter(Period == "average_daily_wager_pre")
# %>% arrange(desc(window_limit_setter))

ave.daily.wager.comparison.ANCOVA$window_limit_setter <- as.factor(ave.daily.wager.comparison.ANCOVA$window_limit_setter)
```
Run ROBUST ANCOVA (use standard parameters: tr = .2, fr1 & fr2 = 1):
```{r warnings = FALSE, message = FALSE, , result = 'asis'}
set.seed(99)
Robust.ANCOVA.averwager <- ancova(average_daily_wager_differencescore ~ Average_daily_wager + window_limit_setter,
                                  data = ave.daily.wager.comparison.ANCOVA)

Robust.ANCOVA.averwager

# How to select parts out this output for R Markdown manuscript:
avwager.evalupts <- as.matrix(Robust.ANCOVA.averwager$evalpts) %>% as.data.frame()
# then:
avwager.evalupts[1,]
avwager.evalupts[2,]

# Make all parts of the output accessible for manuscript:
avwager.n1 <- as.matrix(Robust.ANCOVA.averwager$n1) %>% as.data.frame()

avwager.n2 <- as.matrix(Robust.ANCOVA.averwager$n2) %>% as.data.frame()

avwager.diff <- as.matrix(Robust.ANCOVA.averwager$trDiff) %>% as.data.frame()

avwager.se <- as.matrix(Robust.ANCOVA.averwager$se) %>% as.data.frame()

avwager.lowerci <- as.matrix(Robust.ANCOVA.averwager$ci.low) %>% as.data.frame()

avwager.upperci <- as.matrix(Robust.ANCOVA.averwager$ci.hi) %>% as.data.frame()

avwager.stat <- as.matrix(Robust.ANCOVA.averwager$test) %>% as.data.frame()

avwager.pvalue <- as.matrix(Robust.ANCOVA.averwager$p.vals) %>% as.data.frame()
# As the first 3 p-values here are very small these will need to be put into the manuscript as conditional statements that print "p<0.001" if that statement is true. Otherwise, simply printing these values will result in "p = 0"
avwager.pvalue1 <- avwager.pvalue[1,]
avwager.pvalue2 <- avwager.pvalue[2,]
avwager.pvalue3 <- avwager.pvalue[3,]

```
It is clear from the above output that n1 is the limit setting group and n2 is non-setters, given the lower number of ps in the upper design points (see mean/median (above), and distribution of scores in figures below). Let's check this:

```{r}
# Confirm factor levels:
Robust.ANCOVA.averwager$faclevels
```
Yes, n1 are limit setters.

#### Plot average daily wager comparison
Before developing raincloud plots we have to run the following code taken from the below sources:

- https://wellcomeopenresearch.org/articles/4-63
- https://github.com/RainCloudPlots/RainCloudPlots/blob/master/tutorial_R/R_rainclouds.R
- Note: the below code modifies the existing github page by removing a parenthesis in line 50

```{r warnings = FALSE, message = FALSE}
# Defining the geom_flat_violin function:
"%||%" <- function(a, b) {
  if (!is.null(a)) a else b
}

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = "ydensity",
                             position = "dodge", trim = TRUE, scale = "area",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}

#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
GeomFlatViolin <-
  ggproto("GeomFlatViolin", Geom,
          setup_data = function(data, params) {
            data$width <- data$width %||%
              params$width %||% (resolution(data$x, FALSE) * 0.9)
            
            # ymin, ymax, xmin, and xmax define the bounding rectangle for each group
            data %>%
              group_by(group) %>%
              mutate(
                ymin = min(y),
                ymax = max(y),
                xmin = x,
                xmax = x + width / 2
              )
          },
          
          draw_group = function(data, panel_scales, coord) {
            # Find the points for the line to go all the way around
            data <- transform(data,
                              xminv = x,
                              xmaxv = x + violinwidth * (xmax - x)
            )
            
            # Make sure it's sorted properly to draw the outline
            newdata <- rbind(
              plyr::arrange(transform(data, x = xminv), y),
              plyr::arrange(transform(data, x = xmaxv), -y)
            )
            
            # Close the polygon: set first and last point the same
            # Needed for coord_polar and such
            newdata <- rbind(newdata, newdata[1, ])
            
            ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
          },
          
          draw_key = draw_key_polygon,
          
          default_aes = aes(
            weight = 1, colour = "grey20", fill = "white", size = 0.5,
            alpha = NA, linetype = "solid"
          ),
          
          required_aes = c("x", "y")
  )
```

Plot only limit setters pre- and post limit for pilot test:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
ave.daily.wager.comparison.limitsetters$Period<- as.factor(ave.daily.wager.comparison.limitsetters$Period) # Convert variable to factor to allow recoding

Plot.ave.daily.wager.comparison.limitsetters<- ave.daily.wager.comparison.limitsetters %>% 
  mutate(Period_new = fct_recode(Period,
                                              "Pre-limit" = "average_daily_wager_pre",
                                              "Post-limit" = "average_daily_wager_post")) %>%
  ggplot(aes(x = Period_new,
             y = Average_daily_wager, fill = Period))+
  geom_flat_violin(position = position_nudge(x = .2, y = 0),adjust = .2)+
  geom_point(position = position_jitter(width = .15), size = .25)+
  
  ylab('Average daily wager ($AUD)')+xlab('')+coord_flip()+theme_cowplot()+guides(fill = FALSE) + 
  ggtitle('')

# View plot:
Plot.ave.daily.wager.comparison.limitsetters
```
<br>

Now plot full outcomes with between and within comparisons:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
 ggplot(ave.daily.wager.comparison.sansoutliers, 
                                         aes(x = Period, y = Average_daily_wager, fill = Group)) +
  geom_flat_violin(aes(fill = Group),position = position_nudge(x = .07, y = 0), adjust = .7, trim = TRUE, alpha = .6, colour = "black")+
  geom_point(aes(x = as.numeric(Period)-.15, y = Average_daily_wager, colour = Group), position = position_jitter(width = .07), size = .5, shape = 20)+
  geom_boxplot(aes(x = Period, y = Average_daily_wager, fill = Group), outlier.shape = NA, alpha = .6, width = .09, colour = "black")+
  ylab('Average daily wager ($AUD)')+
  scale_y_continuous(name = "Average daily wager ($AUD)") +
  xlab('')+
  # ggtitle("Figure 2: Average daily wager 90 days before and after messages") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
         panel.background = element_blank(), axis.line = element_line(colour = "black"))+
   theme(plot.margin = unit(c(.5,.5,1,.5), "cm"))+
   # theme(plot.title = element_text(family = "Arial Black", color="black", size=14, face="bold", vjust =2)) +
   theme(axis.title.x = element_text(color="black", size=12, face="plain", vjust=-1.7))+
   scale_x_discrete(labels = c("Post-message", "Pre-message"), expand = c(0.3, 0))+
   theme(axis.text = element_text(color="black", size=11, face="plain"))+
   theme(legend.position = c(0.3, 0.8), 
         legend.text = element_text(color="black", size=9, face="plain"),
         legend.title.align = .5)
```
<br>
Let's try flipping the variables for this plot to see whether that helps with visualisation.
<br>

Create plot (Figure4a)
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
# Recode factor order:
 ave.daily.wager.comparison.sansoutliers$Period <- factor(ave.daily.wager.comparison.sansoutliers$Period,
                                                            c("Pre-message", "Post-message"))
 
 Figure4.a<- ggplot(ave.daily.wager.comparison.sansoutliers, aes(x = Group, y = Average_daily_wager, fill = Period)) +
   geom_flat_violin(aes(fill = Period),
                    position = position_nudge(x = .1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
   geom_point(aes(x = as.numeric(Group)-.17, y = Average_daily_wager, colour = Period),
              position = position_jitter(width = .07), size = .4, shape = 20)+
   scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
   scale_color_manual(values=c("#E69F00", "#56B4E9")) +
   # OTHER COLOUR OPTIONS:
   # scale_fill_viridis_d(name = "Quartiles") +
   # scale_color_viridis_d(name = "Quartiles") +
   # Nice green colour HEX: #00846b; RED Hex: #FF2400 
   geom_boxplot(aes(x = Group, y = Average_daily_wager, fill = Period),  
                position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
   # OPTIONAL ADD INS:
   # geom_line(data = sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.1, y = Average_daily_wager, group = Period, colour = Period), linetype = 3)+
   # geom_point(data = sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.1, y = Average_daily_wager, group = Period, colour = Period), shape = 18) +
   # geom_errorbar(data = sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.1, y = Average_daily_wager, group = Period, colour = Period,
                                    # ymin = Average_daily_wager-se, ymax = Average_daily_wager+se), width = .05)+
   theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
   theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1, family = "Poppins"))+
   theme(legend.position = c(0.85, 0.9), 
         legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
         legend.title.align = .5, 
         legend.title=element_text(size=10)) +
   # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
         panel.background = element_blank(), axis.line = element_line(colour = "black"))+
   theme(plot.margin = unit(c(.1,.2,1.5,-2.2), "cm"))+ 
   scale_x_discrete(expand = c(0.3, 0))+
   theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
   # annotate("text", x = 1.26:2.26, y = 1500, # Add in mean difference scores and their confidence intervals
   #          label = c("Mean difference between periods = $-211.5
   #                    [95% CI: -157.1, -265.8], dz = 0.64 [0.46, 0.81]                      ",
   #                    "Mean difference between periods = $-14.1
   #                    [95% CI: -32.8, -4.5], dz = 0.12 [-0.04, 0.28]                      "),
   #          size = 2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
   scale_y_continuous(name = "Average daily wager ($)",
                      breaks = c(0, 250, 500, 750, 1000, 1250, 1500,1750, 2000, 2250)) +
   xlab('')+
   coord_flip()

# View new plot:
Figure4.a
```
<br>

Save plot:
```{r warnings = FALSE, message = FALSE}
ggsave("Figures/Figure4.a.jpeg",
       width = 170,
       height = 130,
       units = c("mm"),
       dpi = 600
)
```
Create a truncated version that makes visualisation and interpretation easier:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
Figure4truncated.a<- ggplot(ave.daily.wager.comparison.sansoutliers, aes(x = Group, y = Average_daily_wager, fill = Period)) +
  geom_flat_violin(aes(fill = Period),
                   position = position_nudge(x = .1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
  geom_point(aes(x = as.numeric(Group)-.17, y = Average_daily_wager, colour = Period),
             position = position_jitter(width = .07), size = .4, shape = 20)+
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
  scale_color_manual(values=c("#E69F00", "#56B4E9")) +
  # OTHER COLOUR OPTIONS:
  # scale_fill_viridis_d(name = "Quartiles") +
  # scale_color_viridis_d(name = "Quartiles") +
  # Nice green colour HEX: #00846b; RED Hex: #FF2400 
  geom_boxplot(aes(x = Group, y = Average_daily_wager, fill = Period),  
               position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
  # OPTIONAL ADD INS:
  # geom_line(data = sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.1, y = Average_daily_wager, group = Period, colour = Period), linetype = 3)+
  # geom_point(data = sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.1, y = Average_daily_wager, group = Period, colour = Period), shape = 18) +
  # geom_errorbar(data = sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.1, y = Average_daily_wager, group = Period, colour = Period,
  # ymin = Average_daily_wager-se, ymax = Average_daily_wager+se), width = .05)+
  theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
  theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1, family = "Poppins"))+
  theme(legend.position = c(0.85, 0.9), 
        legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
        legend.title.align = .5, 
        legend.title=element_text(size=10)) +
  # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  theme(plot.margin = unit(c(.1,.2,1.5,-2.2), "cm"))+ 
  scale_x_discrete(expand = c(0.3, 0))+
  theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
  # annotate("text", x = 1.26:2.26, y = 1500, # Add in mean difference scores and their confidence intervals
  #          label = c("Mean difference between periods = $-211.5
  #                    [95% CI: -157.1, -265.8], dz = 0.64 [0.46, 0.81]                      ",
  #                    "Mean difference between periods = $-14.1
  #                    [95% CI: -32.8, -4.5], dz = 0.12 [-0.04, 0.28]                      "),
  #          size = 2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
  scale_y_continuous(name = "Average daily wager ($)", 
                     limits = c(0, 1500), 
                     breaks = c(0, 250, 500, 750, 1000, 1250, 1500)) +
  xlab('')+
  coord_flip()

# View new plot:
Figure4truncated.a
```
<br>

Save plot:
```{r warnings = FALSE, message = FALSE}
ggsave("Figures/Figure4truncated.a.jpeg",
       width = 170,
       height = 130,
       units = c("mm"),
       dpi = 600
)
```
<br>

Create a difference plot for the same outcome to compare visualisations:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
Figure4.a2 <-   diffPlot(average_daily_wager_differencescore ~ Group,
          data = ave.daily.wager.comparison.sansoutliers,
          xlab = "", ylab = "Average daily wager ($)", main="Difference between pre-and post average daily 
          wagers per group: Means and 95% CIs            ", 
          grp.names=c("Limit setters", "No limit"))
 
Figure4.a2
```
<br><br>


## Comparisons of pre & post SD of average daily wager
First create a workable dataset for this comparison, including the creation of z scores to identify and remove outliers: 
```{r warnings = FALSE, message = FALSE}
 sd.of.ave.daily.wager.comparison<- wager.comaprison.data %>%
   mutate(sd_av_daily_wager_differencescore = daily_wager_SD_pre - daily_wager_SD_post) %>%
   pivot_longer(c("daily_wager_SD_pre",
                  "daily_wager_SD_post"), 
                names_to = "Period",
                values_to = "SD_of_ave_daily_wager") %>%
  dplyr::select(customerid, 
          window_limit_setter, 
          Period, 
          SD_of_ave_daily_wager,
          sd_av_daily_wager_differencescore) %>%
   group_by(window_limit_setter,
            Period) %>%
   mutate(SD_of_ave_daily_wager_zscore = (SD_of_ave_daily_wager - mean(SD_of_ave_daily_wager))/ sd(SD_of_ave_daily_wager))
```

Identify outliers using pre-registered method and see how many cases this would remove: 
```{r warnings = FALSE, message = FALSE}
sd.of.ave.daily.wager.comparison.outliers<-  sd.of.ave.daily.wager.comparison %>%
   filter(SD_of_ave_daily_wager_zscore >= 3.29 |
            SD_of_ave_daily_wager_zscore <= -3.29) %>%
  dplyr::select(customerid, 
          Period,
          SD_of_ave_daily_wager_zscore,
          SD_of_ave_daily_wager) %>%
   ungroup() %>%
   distinct(customerid, .keep_all = TRUE) 

nrow(sd.of.ave.daily.wager.comparison.outliers)
```
9 participants in total, 4 limit setters and 5 non-limit setters
<br>

Create a dataset that excludes participants who are in eligible for going on timeouts or self excluding and these outliers and then make all of the common column names and value names tidy for future plots:
```{r warnings = FALSE, message = FALSE, fig.align = 'centre'}
 sd.of.ave.daily.wager.comparison.sansoutliers<- sd.of.ave.daily.wager.comparison %>%
   anti_join(sd.of.ave.daily.wager.comparison.outliers, by = "customerid") %>% 
   ungroup() %>%
   mutate(Period = fct_recode(Period,
                              "Pre-message" = "daily_wager_SD_pre",
                              "Post-message" = "daily_wager_SD_post")) %>%
   
   mutate(Group = fct_recode(window_limit_setter,
                             "Limit 
                             setters" = "LimitSetter",
                             "No limit" = "None"))
```
Create some summary data for this comparison. Difference scores with CIs:
```{r warnings = FALSE, message = FALSE}
 sumdat.sd.of.ave.daily.wager.differencescore <- sd.of.ave.daily.wager.comparison.sansoutliers %>%
   distinct(customerid, .keep_all = TRUE) %>%
   summarySE(measurevar = "sd_av_daily_wager_differencescore",
             groupvars=c("Group", "Period")) %>%
   mutate(lowerCI = sd_av_daily_wager_differencescore - ci,
          upperrCI = sd_av_daily_wager_differencescore + ci) # Calculate confidence intervals for the "sd_av_daily_wager_differencescore":

kable(sumdat.sd.of.ave.daily.wager.differencescore, caption = "Pre-post difference score with 95% CIs: SD of average daily wager",
      digits = 2,
      col.names = c("Group", "period", "n", "Difference sore", "SD", "SE", "95% CI", "Lower CI: 2.5%", "Upper CI: 97.5%")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Group means, SDs, and medians pre and post-message:
```{r warnings = FALSE, message = FALSE}
 kable(sd.of.ave.daily.wager.comparison.sansoutliers %>%
   group_by(Period,
            window_limit_setter) %>%
   dplyr::summarise(
     n(),
     mean = mean(SD_of_ave_daily_wager),
     sd = sd(SD_of_ave_daily_wager),
     median = median(SD_of_ave_daily_wager)),
    caption = "Pre-post summary scores: SD of average daily wager",
      digits = 2,
      col.names = c("Period", "Group", "n", "Mean", "SD", "Median")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 
``` 
<br>

Next calculate Effect sizes (dz) for the within comparison (pre-post) of scores:

- We need a t value first to include in the calculation from the MOTE Package and this needs to be done separately for each group

Create a dataset just to compare **limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}
 sd.of.ave.daily.wager.comparison.sansoutliers.limitsetters<- sd.of.ave.daily.wager.comparison.sansoutliers %>%
   filter(window_limit_setter == "LimitSetter")
 
 t.test(formula = SD_of_ave_daily_wager ~ Period,
        data = sd.of.ave.daily.wager.comparison.sansoutliers.limitsetters,
        paired = TRUE,
        alternative = "two.sided")

 # Now calculate the effect Size:
 d.dep.t.diff.t(t = -5.8881, 148, a = 0.05)
``` 
 
Create a dataset just to compare **non-limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}
 sd.of.ave.daily.wager.comparison.sansoutliers.nonlimitsetters<- sd.of.ave.daily.wager.comparison.sansoutliers %>%
   filter(window_limit_setter == "None")
 
 t.test(formula = SD_of_ave_daily_wager ~ Period,
        data = sd.of.ave.daily.wager.comparison.sansoutliers.nonlimitsetters,
        paired = TRUE,
        alternative = "two.sided")
 
 # Now calculate the effect Size:
 d.dep.t.diff.t(t = -1.6257, 149, a = 0.05)
```
 
#### ANCOVA: SD of average daily wager
Now run an ANCOVA to see the effect of limit setting on scores, with the difference score as the outcome and baseline scores and age as the covariates:
 
First filter out the "post-message" scores as we don't need these for the analysis and including these rows would result in a duplicated "average_daily_wager_differencescore" for each consumer due to the current setup of the data:
```{r warnings = FALSE, message = FALSE}
 sd.of.ave.daily.wager.comparison.sansoutliers.ANCOVA<- sd.of.ave.daily.wager.comparison.sansoutliers %>%
   filter(Period == "Pre-message")
``` 
Next check the statical assumptions are met
<br>

Normally distributed outcome variables across groups is not required but check anyway:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
 # Plot distribution of variable for both groups to see whether this is normally distributed across groups:
 hist_sd_average_daily_wager_pre<-  ggplot(sd.of.ave.daily.wager.comparison.sansoutliers.ANCOVA, 
                                        aes(sd_av_daily_wager_differencescore, fill = window_limit_setter)) +
   geom_histogram(bins = 60) 
 
 hist_sd_average_daily_wager_pre 
```  
<br>
Again, this variable is relatively centred distributed around a few dollars for both groups, although it is leptokurtic (kurtosis)
 
##### Asumption 1: No influential outliers:
Outliers have already been removed: 7 participants in total, 4 limit setters and 3 non-limit setters.

##### Asumption 2: The covariate should be linearly related to the dependent variable at each level of the independent variable:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
 ggscatter(
   sd.of.ave.daily.wager.comparison.sansoutliers.ANCOVA, x = "SD_of_ave_daily_wager", y = "sd_av_daily_wager_differencescore",
   color = "window_limit_setter", add = "reg.line"
 )+
   stat_regline_equation(
     aes(label =  paste(..eq.label.., ..rr.label.., sep = "~~~~"), color = window_limit_setter)
   )
```
<br>
ASSUMPTION 2 MET: the covariate is linearly related to the dependent variable at each level of the independent variable, although minimally for the non-setter group
 
##### Assumption 3: homogeneity of regression slope (No sig. interaction between covariate and grouping variable):
```{r warnings = FALSE, message = FALSE}
 sd.of.ave.daily.wager.comparison.sansoutliers.ANCOVA %>% anova_test(sd_av_daily_wager_differencescore ~ window_limit_setter*SD_of_ave_daily_wager)
```
ASSUMPTION 3 NOT MET: Interaction term significant
 
##### Assumption 4: normality of within-group residuals:
```{r warnings = FALSE, message = FALSE}
 # Compute model to calculate residuals:
 norm.model2<- lm(sd_av_daily_wager_differencescore ~ SD_of_ave_daily_wager + window_limit_setter, data = sd.of.ave.daily.wager.comparison.sansoutliers.ANCOVA)
 
# Make residuals available:
 norm.model2.metrics <- augment(norm.model2) 

# Run Shapiro Wilk's test on residuals:
 shapiro_test(norm.model2.metrics$.resid)
```
ASSUMPTION 4 NOT MET: non-normality of residuals
 
##### Assumption 5: homogeneity of variance:
```{r warnings = FALSE, message = FALSE}
leveneTest(.resid~window_limit_setter, center = mean, data = norm.model2.metrics)
```
ASSUMPTION 5 NOT MET: non-homogenity of residuals, sig. Levene's test
 
#### ROBUST ANCOVA: SD of average daily wager
No need to remove outliers here so lets make the orginal dataset suitable for this analysis:
```{r warnings = FALSE, message = FALSE}
 sd.of.ave.daily.wager.comparison.ANCOVA<- sd.of.ave.daily.wager.comparison %>%
   filter(Period == "daily_wager_SD_pre")
```
Run ROBUST ANCOVA:
```{r warnings = FALSE, message = FALSE}
set.seed(101)
Robust.ANCOVA.sd.averwager <- ancova(sd_av_daily_wager_differencescore ~ SD_of_ave_daily_wager + window_limit_setter,
                                   data = sd.of.ave.daily.wager.comparison.ANCOVA)
 
 Robust.ANCOVA.sd.averwager
 
# How to select parts out this output for R Markdown manuscript:
sd.avwager.evalupts <- as.matrix(Robust.ANCOVA.sd.averwager$evalpts) %>% as.data.frame()
# then:
sd.avwager.evalupts[1,]
sd.avwager.evalupts[2,]

# Make all parts of the output accessible for manuscript:
sd.avwager.n1 <- as.matrix(Robust.ANCOVA.sd.averwager$n1) %>% as.data.frame()

sd.avwager.n2 <- as.matrix(Robust.ANCOVA.sd.averwager$n2) %>% as.data.frame()

sd.avwager.diff <- as.matrix(Robust.ANCOVA.sd.averwager$trDiff) %>% as.data.frame()

sd.avwager.se <- as.matrix(Robust.ANCOVA.sd.averwager$se) %>% as.data.frame()

sd.avwager.lowerci <- as.matrix(Robust.ANCOVA.sd.averwager$ci.low) %>% as.data.frame()

sd.avwager.upperci <- as.matrix(Robust.ANCOVA.sd.averwager$ci.hi) %>% as.data.frame()

sd.avwager.stat <- as.matrix(Robust.ANCOVA.sd.averwager$test) %>% as.data.frame()

sd.avwager.pvalue <- as.matrix(Robust.ANCOVA.sd.averwager$p.vals) %>% as.data.frame()
# As the first 3 p-values here are very small these will need to be put into the manuscript as conditional statements that print "p<0.001" if that statement is true. Otherwise, simply printing these values will result in "p = 0"
sd.avwager.pvalue1 <- sd.avwager.pvalue[1,]
sd.avwager.pvalue2 <- sd.avwager.pvalue[2,]
sd.avwager.pvalue3 <- sd.avwager.pvalue[3,]

```
Again, it is clear from the above output that n1 is the limit setting group and n2 is non-setters, given the lower number of ps in the upper design points (see mean/median (above), and distribution of scores in figures below).

#### Plot SD Of the average daily wager comparison
Create plot (Figure4b):
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
# Recode factor order:
 sd.of.ave.daily.wager.comparison.sansoutliers$Period <- factor(sd.of.ave.daily.wager.comparison.sansoutliers$Period,
                                                          c("Pre-message", "Post-message"))
 
 Figure4.b <- ggplot(sd.of.ave.daily.wager.comparison.sansoutliers, aes(x = Group, y = SD_of_ave_daily_wager, fill = Period)) +
   geom_flat_violin(aes(fill = Period),
                    position = position_nudge(x = .1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
   geom_point(aes(x = as.numeric(Group)-.17, y = SD_of_ave_daily_wager, colour = Period),
              position = position_jitter(width = .07), size = .4, shape = 20)+
   scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
   scale_color_manual(values=c("#E69F00", "#56B4E9")) +
   geom_boxplot(aes(x = Group, y = SD_of_ave_daily_wager, fill = Period),  
                position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
   # OPTIONAL ADD INS:
   # geom_line(data = sumdat.sd.of.ave.daily.wager.differencescore, aes(x = as.numeric(Group)+.1, y = SD_of_ave_daily_wager, group = Period, colour = Period), linetype = 3)+
   # geom_point(data = sumdat.sd.of.ave.daily.wager.differencescore, aes(x = as.numeric(Group)+.1, y = SD_of_ave_daily_wager, group = Period, colour = Period), shape = 18) +
   # geom_point(data =sumdat.sd.of.ave.daily.wager.differencescore, aes(x = as.numeric(Group)+.06, y= sd_av_daily_wager_differencescore)) +
   # geom_errorbar(data = sumdat.sd.of.ave.daily.wager.differencescore,
   #               aes(x = as.numeric(Group)+.06, y = sd_av_daily_wager_differencescore, group = Period, colour = Period,
   #                  ymin = sd_av_daily_wager_differencescore - ci, ymax = sd_av_daily_wager_differencescore + ci), width = .05)+
   # annotate("text", x = 1.26:2.26, y = 2000, # Add in mean difference scores and their confidence intervals
   #          label = c("Mean difference between periods = $-250.3663
   #                    [95% CI: -334.4 -166.3], dz = 0.48 [0.31, 0.65]                      ",
   #                    "Mean difference between periods = $-19.8
   #                    [95% CI: -43.9, 4.3], dz = 0.13 [-0.03, 0.29]                      "),
   #          size =2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
 theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
   theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1, family = "Poppins"))+
   theme(legend.position = c(0.85, 0.9), 
         legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
         legend.title.align = .5, 
         legend.title=element_text(size=10)) +
   # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
         panel.background = element_blank(), axis.line = element_line(colour = "black"))+
   theme(plot.margin = unit(c(.1,.2,1,-2.2), "cm"))+ 
   scale_x_discrete(expand = c(0.3, 0))+
   theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
   scale_y_continuous(name = "SD of average daily wager ($)") +
   xlab('')+
   coord_flip()
 
 # View new plot:
 Figure4.b
```
<br>

Save plot:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
 ggsave("Figures/Figure4.b.jpeg",
        width = 170,
        height = 130,
        units = c("mm"),
        dpi = 600
 )
```
Create a truncated version:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
 Figure4truncated.b <- ggplot(sd.of.ave.daily.wager.comparison.sansoutliers, aes(x = Group, y = SD_of_ave_daily_wager, fill = Period)) +
   geom_flat_violin(aes(fill = Period),
                    position = position_nudge(x = .1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
   geom_point(aes(x = as.numeric(Group)-.17, y = SD_of_ave_daily_wager, colour = Period),
              position = position_jitter(width = .07), size = .4, shape = 20)+
   scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
   scale_color_manual(values=c("#E69F00", "#56B4E9")) +
   geom_boxplot(aes(x = Group, y = SD_of_ave_daily_wager, fill = Period),  
                position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
   # OPTIONAL ADD INS:
   # geom_line(data = sumdat.sd.of.ave.daily.wager.differencescore, aes(x = as.numeric(Group)+.1, y = SD_of_ave_daily_wager, group = Period, colour = Period), linetype = 3)+
   # geom_point(data = sumdat.sd.of.ave.daily.wager.differencescore, aes(x = as.numeric(Group)+.1, y = SD_of_ave_daily_wager, group = Period, colour = Period), shape = 18) +
   # geom_point(data =sumdat.sd.of.ave.daily.wager.differencescore, aes(x = as.numeric(Group)+.06, y= sd_av_daily_wager_differencescore)) +
   # geom_errorbar(data = sumdat.sd.of.ave.daily.wager.differencescore,
   #               aes(x = as.numeric(Group)+.06, y = sd_av_daily_wager_differencescore, group = Period, colour = Period,
   #                  ymin = sd_av_daily_wager_differencescore - ci, ymax = sd_av_daily_wager_differencescore + ci), width = .05)+
   # annotate("text", x = 1.26:2.26, y = 2000, # Add in mean difference scores and their confidence intervals
   #          label = c("Mean difference between periods = $-250.3663
   #                    [95% CI: -334.4 -166.3], dz = 0.48 [0.31, 0.65]                      ",
   #                    "Mean difference between periods = $-19.8
 #                    [95% CI: -43.9, 4.3], dz = 0.13 [-0.03, 0.29]                      "),
 #          size =2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
 theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
   theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1, family = "Poppins"))+
   theme(legend.position = c(0.85, 0.9), 
         legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
         legend.title.align = .5, 
         legend.title=element_text(size=10)) +
   # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
         panel.background = element_blank(), axis.line = element_line(colour = "black"))+
   theme(plot.margin = unit(c(.1,.2,1,-2.2), "cm"))+ 
   scale_x_discrete(expand = c(0.3, 0))+
   theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
   scale_y_continuous(name = "SD of average daily wager ($)", limits = c(0, 1500), breaks = c(0, 250, 500, 750, 1000, 1250, 1500,1750, 2000, 2250, 2500)) +
   xlab('')+
   coord_flip()
 
 # View new plot:
 Figure4truncated.b
```
<br>

Save plot:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
 ggsave("Figures/Figure4truncated.b.jpeg",
        width = 170,
        height = 130,
        units = c("mm"),
        dpi = 600
 )
```
<br><br>

## Comparisons of pre & post net loss
First create a workable dataset for this comparison, including the creation of z scores to identify and remove outliers: 
```{r warnings = FALSE, message = FALSE}
net.loss.comparison<- wager.comaprison.data %>%
  mutate(net_loss_differencescore = net_loss_pre - net_loss_post) %>%
  pivot_longer(c("net_loss_pre",
                 "net_loss_post"), 
               names_to = "Period",
               values_to = "net_loss") %>%
 dplyr::select(customerid, 
         window_limit_setter, 
         Period, 
         net_loss,
         net_loss_differencescore,
         self_exclusion,
         self_exclusion_start_date,
         timeout_start_date_pre,
         timeout_finish_date_pre,
         timeout_start_date_post,
         timeout_start_date_post,
         timeout_pre,
         timeout_duration_pre,
         timeout_duration_post,
         timeout_post) %>%
  group_by(window_limit_setter,
           Period) %>%
  mutate(net_loss_zscore = (net_loss - mean(net_loss))/ sd(net_loss))
```

This outcome will also be affected by people using timeouts and self-exclusion and so we need to remove these from sample. Let's remove anyone who went on a time out of more than 2 weeks either side of messages:
```{r warnings = FALSE, message = FALSE}
 as.Date("2020-10-14") + 90
 as.Date("2021-01-12") - 14 
 
 # First, identify this cohort:
net.loss.comparison.ineligible <- net.loss.comparison  %>%
   ungroup() %>%
# The below code would excluded any customers with a break of ≥ 14 days either side of messages due to account closures or CPT use, Wh=wich is originally from these analyses but we changed this in in response to reviewer comments:
   # filter(timeout_pre != "None" & 
   #          timeout_duration_pre >14 &
   #          timeout_start_date_pre >= as.Date("2019-07-16") & 
   #          timeout_start_date_pre <= as.Date("2020-12-29") |
   #          self_exclusion != "None" &
   #          self_exclusion_start_date >= as.Date("2019-07-16") & 
   #          self_exclusion_start_date <= as.Date("2020-12-29") | # This is 14 days prior to the 90 day post message period....
   #          timeout_post  != "None" & #  # (If anyone excluded after this date then it was for less than 2 weeks of the period)
   #          timeout_duration_post >=14 &
   #          timeout_start_date_post >= as.Date("2019-07-16") & 
   #          timeout_start_date_post <= as.Date("2020-12-29")) %>% 
  dplyr::select(customerid, 
          window_limit_setter, 
          self_exclusion_start_date,
          timeout_start_date_pre,
          timeout_finish_date_pre,
          timeout_duration_pre,
          timeout_duration_post,
          timeout_start_date_post,
          timeout_start_date_post,
          timeout_post) %>%
   distinct(customerid, .keep_all = TRUE)

nrow(net.loss.comparison.ineligible)
```  
Interestingly, this will exclude 21 people:

- One had an extended timeout prior to messages and self excluded following.
- Two had an extended timeout prior to messages
- One self excluded following messages
- The other 17 all had extended timeouts following messages

Identify outliers using pre-registered method and see how many cases this would remove: 
```{r warnings = FALSE, message = FALSE}
net.loss.comparison.outliers<-  net.loss.comparison %>%
  filter(net_loss_zscore >= 3.29 |
           net_loss_zscore <= -3.29) %>%
  ungroup() %>%
 dplyr::select(customerid, 
         Period,
         net_loss_zscore,
         net_loss,
         window_limit_setter) %>%
  distinct(customerid, .keep_all = TRUE) 

nrow(net.loss.comparison.outliers)
```
6 participants in total, 2 limit setters and 4 non-limit setters
<br>

Create a dataset that excludes participants who are in eligible for going on timeouts or self excluding and these outliers and then make all of the common column names and value names tidy for future plots:
```{r warnings = FALSE, message = FALSE}
ave.daily.wager.comparison$Period<- as.factor(ave.daily.wager.comparison$Period) # Make a variable in factor to change the level names

net.loss.comparison.sansoutliers<- net.loss.comparison %>%
  # anti_join(net.loss.comparison.ineligible, by = "customerid") %>% 
  anti_join(net.loss.comparison.outliers, by = "customerid") %>% 
  ungroup() %>%
  mutate(Period = fct_recode(Period,
                             "Pre-message" = "net_loss_pre",
                             "Post-message" = "net_loss_post")) %>%
  
  mutate(Group = fct_recode(window_limit_setter,
                            "Limit 
                            setters" = "LimitSetter",
                            "No limit" = "None")) 
```
Create some summary data for this comparison.
<br>

Difference scores with CIs:
```{r warnings = FALSE, message = FALSE}
sumdat.net.loss.differencescore <- net.loss.comparison.sansoutliers %>%
  distinct(customerid, .keep_all = TRUE) %>%
  summarySE(measurevar = "net_loss_differencescore",
            groupvars=c("Group")) %>%
  mutate(lowerCI = net_loss_differencescore - ci,
         upperrCI = net_loss_differencescore + ci)# calculate confidence intervals for "net_loss_differencescore":
 
kable(sumdat.net.loss.differencescore, caption = "Pre-post difference score with 95% CIs: Net loss",
      digits = 2,
      col.names = c("Group", "n", "Difference sore", "SD", "SE", "95% CI", "Lower CI: 2.5%", "Upper CI: 97.5%")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Group means, SDs, and medians pre and post-message:
```{r warnings = FALSE, message = FALSE}
kable(net.loss.comparison.sansoutliers %>%
  group_by(Period,
           window_limit_setter) %>%
  dplyr::summarise(
    n = n(),
    mean = mean(net_loss),
    sd = sd(net_loss),
    median = median(net_loss)),
    caption = "Pre-post summary scores: Net loss",
      digits = 2,
      col.names = c("Period", "Group", "n", "Mean", "SD", "Median")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 
  
```
<br>

Next calculate Effect sizes (dz) for the within comparison (pre-post) of scores:

- We need a t value first to include in the calculation from the MOTE Package and this needs to be done separately for each group

Create a dataset just to compare **limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}
net.loss.comparison.sansoutliers.limitsetters<- net.loss.comparison.sansoutliers %>%
  filter(window_limit_setter == "LimitSetter")

t.test(formula = net_loss ~ Period,
       data = net.loss.comparison.sansoutliers.limitsetters,
       paired = TRUE,
       alternative = "two.sided")

# Now calculate the effect Size:
d.dep.t.diff.t(t = -5.19656, 130, a = 0.05)
```
Create a dataset just to compare **non-limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}

net.loss.comparison.sansoutliers.nonlimitsetters<- net.loss.comparison.sansoutliers %>%
  filter(window_limit_setter == "None")

t.test(formula = net_loss ~ Period,
       data = net.loss.comparison.sansoutliers.nonlimitsetters,
       paired = TRUE,
       alternative = "two.sided")

# Now calculate the effect Size:
d.dep.t.diff.t(t = -0.15203, 148, a = 0.05)
```

#### ANCOVA: Net loss
Now run an ANCOVA to see the effect of limit setting on scores, with the difference score as the outcome and baseline scores and age as the covariates.
<br>

First filter out the "post-message" scores as we do not need these for the analysis and including these rows would result in a duplicated "average_daily_wager_differencescore" for each consumer due to the current setup of the data:
```{r warnings = FALSE, message = FALSE}
net.loss.comparison.sansoutliers.ANCOVA<- net.loss.comparison.sansoutliers %>%
  filter(Period == "Pre-message")
```
Next check the statical assumptions are met.
<br>

Normally distributed outcome variables across groups is not required but check anyway:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
# Plot distribution of variable for both groups to see whether this is normally distributed across groups:
hist_net_loss__pre<-  ggplot(net.loss.comparison.sansoutliers.ANCOVA, 
                                          aes(net_loss_differencescore, fill = window_limit_setter)) +
  geom_histogram(bins = 60) 

hist_net_loss__pre 
```
<br>
Again, this variable is relatively centered distributed around a few dollars for both groups, although it is leptokurtic (kurtosis), esp for the non-setters

##### Asumption 1: No influential outliers:
Outliers have already been removed: 6 participants in total, 2 limit setters and 4 non-limit setters

##### Asumption 2: The covariate should be linearly related to the dependent variable at each level of the independent variable:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
ggscatter(
  net.loss.comparison.sansoutliers.ANCOVA, x = "net_loss", y = "net_loss_differencescore",
  color = "window_limit_setter", add = "reg.line"
)+
  stat_regline_equation(
    aes(label =  paste(..eq.label.., ..rr.label.., sep = "~~~~"), color = window_limit_setter)
  )
```
<br>
ASSUMPTION 2 MET: the covariate is linearly related to the dependent variable at each level of the independent variable, although minimally for the non-setter group

##### Assumption 3: homogeneity of regression slope (No sig. interaction between covariate and grouping variable):
```{r warnings = FALSE, message = FALSE}
net.loss.comparison.sansoutliers.ANCOVA %>% anova_test(net_loss_differencescore ~ window_limit_setter*net_loss)
```
ASSUMPTION 3 MET: Interaction term NOT significant

##### Assumption 4: normality of within-group residuals:
```{r warnings = FALSE, message = FALSE}
# Compute model to calculate residuals:
norm.model3<- lm(net_loss_differencescore ~ net_loss + window_limit_setter, data = net.loss.comparison.sansoutliers.ANCOVA)
# Make residuals available:
norm.model3.metrics <- augment(norm.model3) 
# Run Shaprio wilks test on residuals:
shapiro_test(norm.model3.metrics$.resid)
```
ASSUMPTION 4 NOT MET: non-normality of residuals

##### Assumption 5: homogeneity of variance:
```{r warnings = FALSE, message = FALSE}
leveneTest(.resid~window_limit_setter, center = mean, data = norm.model3.metrics)
```
ASSUMPTION 5 NOT MET: non-homogeneity of residuals, sig. Levene's test

#### ROBUST ANCOVA: Net loss
No need to remove outliers here so lets make the original dataset suitable for this analysis:
```{r warnings = FALSE, message = FALSE}
net.loss.comparison.data.ANCOVA<- net.loss.comparison %>%
  # anti_join(net.loss.comparison.ineligible, by = "customerid") %>% # Remove ineligible consumers
  filter(Period == "net_loss_pre")
```
Run ROBUST ANCOVA:
```{r warnings = FALSE, message = FALSE}
set.seed(102)

Robust.ANCOVA.net.loss <- ancova(net_loss_differencescore ~ net_loss + window_limit_setter, 
data = net.loss.comparison.data.ANCOVA)

Robust.ANCOVA.net.loss

# How to select parts out this output for R Markdown manuscript:
netloss.evalupts <- as.matrix(Robust.ANCOVA.net.loss$evalpts) %>% as.data.frame()
# then:
netloss.evalupts[1,]
netloss.evalupts[2,]

# Make all parts of the output accessible for manuscript:
netloss.n1 <- as.matrix(Robust.ANCOVA.net.loss$n1) %>% as.data.frame()

netloss.n2 <- as.matrix(Robust.ANCOVA.net.loss$n2) %>% as.data.frame()

netloss.diff <- as.matrix(Robust.ANCOVA.net.loss$trDiff) %>% as.data.frame()

netloss.se <- as.matrix(Robust.ANCOVA.net.loss$se) %>% as.data.frame()

netloss.lowerci <- as.matrix(Robust.ANCOVA.net.loss$ci.low) %>% as.data.frame()

netloss.upperci <- as.matrix(Robust.ANCOVA.net.loss$ci.hi) %>% as.data.frame()

netloss.stat <- as.matrix(Robust.ANCOVA.net.loss$test) %>% as.data.frame()

netloss.pvalue <- as.matrix(Robust.ANCOVA.net.loss$p.vals) %>% as.data.frame()
# As the first 3 p-values here are very small these will need to be put into the manuscript as conditional statements that print "p<0.001" if that statement is true. Otherwise, simply printing these values will result in "p = 0"
netloss.pvalue1 <- netloss.pvalue[1,]
netloss.pvalue2 <- netloss.pvalue[2,]
netloss.pvalue3 <- netloss.pvalue[3,]
```
Strangely, n1 in this output is non-setters, given the lower number of ps in the upper design points (see mean/median (above), and distribution of scores in figures below) and n2 is the limit setting group. This could be due the removal of more limit setters before starting these analyses, but the distribution of scores is different for this variable, with non-limit setters have some of the lowest scores of all. Check this assumption:

``` {r}
Robust.ANCOVA.net.loss$faclevels
```
Correct, non-setters are n1 here.

#### Plot net loss comparison
Create plot (Figure4c):
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
net.loss.comparison.sansoutliers$Period <- factor(net.loss.comparison.sansoutliers$Period,
                                                               c("Pre-message", "Post-message"))

Figure4.c <- ggplot(net.loss.comparison.sansoutliers, aes(x = Group, y = net_loss, fill = Period)) +
  geom_flat_violin(aes(fill = Period),
                   position = position_nudge(x = 0.1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
  geom_point(aes(x = as.numeric(Group)-.17, y = net_loss, colour = Period),
             position = position_jitter(width = .07), size = .4, shape = 20)+
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
  scale_color_manual(values=c("#E69F00", "#56B4E9")) +
  geom_boxplot(aes(x = Group, y = net_loss, fill = Period),  
               position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
  # OPTIONAL ADD INS:
  # geom_line(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = net_loss, group = Period, colour = Period), linetype = 3)+
  # geom_point(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = net_loss, group = Period, colour = Period), shape = 18) +
  # # geom_errorbar(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = net_loss, group = Period, colour = Period,
  # # ymin = net_loss-se, ymax = net_loss+se), width = .05)+
  # annotate("text", x = 1.26:2.26, y = 14500, # Add in mean difference scores, EFs, and their confidence intervals
  #          label = c("Mean difference between periods = $-3927.3
  #                     [95% CI: -2432.1, -5422.6], dz = 0.46 [0.27, 0.64]                      ",
  #                    "Mean difference between periods = $-26.0
  #                     [95% CI: -311.5, 363.4], dz = 0.01 [-0.15, 0.1.7]                      "),
  #          size = 2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
  theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1, family = "Poppins"))+
  theme(legend.position = c(0.85, 0.9), 
        legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
        legend.title.align = .5, 
        legend.title=element_text(size=10)) +
  # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  theme(plot.margin = unit(c(.1,.2,.45,-2.2), "cm"))+ 
  scale_x_discrete(expand = c(0.3, 0))+
  theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
  scale_y_continuous(name = "Net loss ($)") +
  xlab('')+
  coord_flip()

# View new plot:
Figure4.c
```
Save Plot:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
ggsave("Figures/Figure4.c.jpeg",
       width = 170,
       height = 130,
       units = c("mm"),
       dpi = 600
)
```
Create a truncated version:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
Figure4truncated.c <- ggplot(net.loss.comparison.sansoutliers, aes(x = Group, y = net_loss, fill = Period)) +
  geom_flat_violin(aes(fill = Period),
                   position = position_nudge(x = 0.1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
  geom_point(aes(x = as.numeric(Group)-.17, y = net_loss, colour = Period),
             position = position_jitter(width = .07), size = .4, shape = 20)+
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
  scale_color_manual(values=c("#E69F00", "#56B4E9")) +
  geom_boxplot(aes(x = Group, y = net_loss, fill = Period),  
               position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
  # OPTIONAL ADD INS:
  # geom_line(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = net_loss, group = Period, colour = Period), linetype = 3)+
  # geom_point(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = net_loss, group = Period, colour = Period), shape = 18) +
  # # geom_errorbar(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = net_loss, group = Period, colour = Period,
  # # ymin = net_loss-se, ymax = net_loss+se), width = .05)+
  # annotate("text", x = 1.26:2.26, y = 14500, # Add in mean difference scores, EFs, and their confidence intervals
  #          label = c("Mean difference between periods = $-3927.3
  #                     [95% CI: -2432.1, -5422.6], dz = 0.46 [0.27, 0.64]                      ",
  #                    "Mean difference between periods = $-26.0
  #                     [95% CI: -311.5, 363.4], dz = 0.01 [-0.15, 0.1.7]                      "),
  #          size = 2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
  theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1, family = "Poppins"))+
  theme(legend.position = c(0.85, 0.9), 
        legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
        legend.title.align = .5, 
        legend.title=element_text(size=10)) +
  # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  theme(plot.margin = unit(c(.1,.2,.45,-2.2), "cm"))+ 
  scale_x_discrete(expand = c(0.3, 0))+
  theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
  scale_y_continuous(name = "Net loss ($)", 
                     limits = c(-1000, 5000),
                     breaks = c(-1000,  0, 1000, 2000, 3000, 4000, 5000)) +
  xlab('')+
  coord_flip()

# View new plot:
Figure4truncated.c
#  NOTE: This plot has been capped at $-1,00 and +$5,000 to enable proper visualisation**
```
Save plot:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
ggsave("Figures/Figure4truncated.c.jpeg",
       width = 170,
       height = 130,
       units = c("mm"),
       dpi = 600
)
```
<br><br>

### Join Figure 4 plots together
##### Non-truncated plots

```{r warnings = FALSE, message = FALSE, fig.align = 'center', fig.height = 9}
Figure4 <- Figure4.a/
  Figure4.b/
  # (Figure4.d | Figure4.e)/
  Figure4.c +
  plot_annotation(tag_levels = 'A') +
  plot_layout(guides = 'collect') &           
# annotate("text", x = 1.26:2.26, y = 730,# Annotations for plot 4.a
#          label = c("Mean difference between periods = $-211.5
#                    [95% CI: -157.1, -265.8], dz = 0.64 [0.46, 0.81]                      ",
#                    "Mean difference between periods = $-14.1
#                    [95% CI: -32.8, -4.5], dz = 0.12 [-0.04, 0.28]                      "),
#          size = 2.5) +
# annotate("text", x = 1.42:2.42, y = 36, # Annotations for plot 4.b
#          label = c("Mean difference between periods = $-250.3663
#                    [95% CI: -334.4 -166.3], dz = 0.48 [0.31, 0.65]                      ",
#                    "Mean difference between periods = $-19.8
#                    [95% CI: -43.9, 4.3], dz = 0.13 [-0.03, 0.29]                      "),
#          size = 2.5) +
# annotate("text", x = 1.42:2.42, y = 36, # Annotations for plot 4.c
#          label = c("Mean difference between periods = -14.9 days
#                    [95% CI: -12.2, -17.7], dz = 0.96 [0.74, 1.16]                      ",
#                    "Mean difference between periods = -7.8 days
#                    [95% CI: -5.9, -9.8], dz = 0.64 [0.47, 0.82]                      "),
#          size = 2.5) +
# plot_annotation(title = '') &
  # theme(text = element_text(face = "bold")) +
  theme(plot.margin = unit(c(-.5,.1,.2,-2), "cm"))&
  # theme(plot.title = element_text(hjust = .85, vjust = -1)) &
  theme(legend.position = "top",
        legend.text = element_text(color="black", size=7, face="plain", family = "Poppins"),
        legend.title=element_text(size=9))

# View new plot:
Figure4
```
Save plot:
```{r warnings = FALSE, message = FALSE}
ggsave("Figures/Figure4.jpeg",
  width = 150,
  height = 180,
  units = c("mm"),
  dpi = 600
  )
```

##### Truncated plots
```{r warnings = FALSE, message = FALSE, fig.align = 'center', fig.height = 9}
Figure4truncated <- Figure4truncated.a/
  Figure4truncated.b/
  # (Figure4.d | Figure4.e)/
  Figure4truncated.c +
  # plot_annotation(tag_levels = 'a') +
  plot_layout(guides = 'collect') &
# annotate("text", x = 1.26:2.26, y = 730,# Annotations for plot 3.a
#          label = c("Mean difference between periods = $-211.5
#                    [95% CI: -157.1, -265.8], dz = 0.64 [0.46, 0.81]                      ",
#                    "Mean difference between periods = $-14.1
#                    [95% CI: -32.8, -4.5], dz = 0.12 [-0.04, 0.28]                      "),
#          size = 2.5) +
# annotate("text", x = 1.62:2.42, y = 36, # Annotations for plot 3.b
#          label = c("Mean difference between periods = $-250.3663
#                    [95% CI: -334.4 -166.3], dz = 0.48 [0.31, 0.65]                      ",
#                    "Mean difference between periods = $-19.8
#                    [95% CI: -43.9, 4.3], dz = 0.13 [-0.03, 0.29]                      "),
#          size = 2.5) +
# annotate("text", x = 4.02:2.42, y = 36, # Annotations for plot 3.c
#          label = c("Mean difference between periods = -14.9 days
#                    [95% CI: -12.2, -17.7], dz = 0.96 [0.74, 1.16]                      ",
#                    "Mean difference between periods = -7.8 days
#                    [95% CI: -5.9, -9.8], dz = 0.64 [0.47, 0.82]                      "),
#          size = 2.5) +
plot_annotation(title = '') &
  # theme(text = element_text(face = "bold")) +
  theme(plot.margin = unit(c(-.5,.1,.2,-2), "cm"))&
  # theme(plot.title = element_text(hjust = .85, vjust = -1)) &
  theme(legend.position = "top",
        legend.text = element_text(color="black", size=7, face="plain", family = "Poppins"),
        legend.title=element_text(size=9))

# View new plot:
Figure4truncated
```
Save plot:
```{r warnings = FALSE, message = FALSE}
ggsave("Figures/Figure4truncated.pdf",
       width = 150,
       height = 180,
       units = c("mm"),
       dpi = 600
)

ggsave("Figures/Figure4truncated.jpeg",
       width = 150,
       height = 180,
       units = c("mm"),
       dpi = 600
)
ggsave("Figures/Figure4preprint.jpeg",
       width = 90,
       height = 180,
       units = c("mm"),
       dpi = 600
)
```
<br><br>

## Comparisons of pre & post gambling frequency
First create a workable dataset for this comparison, including the creation of z scores to identify and remove outliers: 
```{r warnings = FALSE, message = FALSE}
betting.frequency.comparison<- wager.comaprison.data %>%
  mutate(betting_frequency_differencescore = betting_days_frequency_pre - betting_days_frequency_post) %>%
  pivot_longer(c("betting_days_frequency_pre",
                 "betting_days_frequency_post"), 
               names_to = "Period",
               values_to = "betting_frequency") %>%
 dplyr::select(customerid, 
         window_limit_setter, 
         Period, 
         betting_frequency,
         self_exclusion,
         self_exclusion_start_date,
         betting_frequency_differencescore,
         timeout_start_date_pre,
         timeout_finish_date_pre,
         timeout_start_date_post,
         timeout_start_date_post,
         timeout_pre,
         timeout_duration_pre,
         timeout_duration_post,
         timeout_post) %>%
  group_by(window_limit_setter,
           Period) %>%
  mutate(betting_frequency_zscore = (betting_frequency - mean(betting_frequency))/ sd(betting_frequency))
```

This outcome will be affected by people using timeouts and self-exclusion and so we need to remove these from sample. Let's remove anyone who went on a time out of more than 2 weeks either side of messages:
```{r warnings = FALSE, message = FALSE}
# as.Date("2020-10-14") + 90
# as.Date("2021-01-12") - 14 
# 
# # First, identify this cohort:
# betting.frequency.comparison.ineligible <- betting.frequency.comparison  %>%
#   ungroup() %>%
#   # filter(timeout_pre != "None" & 
#   #          timeout_duration_pre >14 &
#   #          timeout_start_date_pre >= as.Date("2019-07-16") & 
#   #          timeout_start_date_pre <= as.Date("2020-12-29") |
#   #          self_exclusion != "None" &
#   #          self_exclusion_start_date >= as.Date("2019-07-16") & 
#   #          self_exclusion_start_date <= as.Date("2020-12-29") | # This is 14 days prior to the 90 day post message period....
#   #          timeout_post  != "None" & #  # (If anyone excluded after this date then it was for less than 2 weeks of the period)
#   #          timeout_duration_post >=14 &
#   #          timeout_start_date_post >= as.Date("2019-07-16") & 
#   #          timeout_start_date_post <= as.Date("2020-12-29")) %>% 
#  dplyr::select(customerid, 
#          window_limit_setter, 
#          self_exclusion_start_date,
#          timeout_start_date_pre,
#          timeout_finish_date_pre,
#          timeout_duration_pre,
#          timeout_duration_post,
#          timeout_start_date_post,
#          timeout_start_date_post,
#          timeout_post) %>%
#   distinct(customerid, .keep_all = TRUE) 
# 
# nrow(betting.frequency.comparison.ineligible)
```
Interestingly, this will exclude 21 people:

- One had an extended timeout prior to messages and self excluded following
- Two had an extended timeout prior to messages
- One self excluded following messages
- The other 17 all had extended timeouts following messages.

Identify outliers using pre-registered method and see how many cases this would remove: 
```{r warnings = FALSE, message = FALSE}
betting.frequency.comparison.outliers<-  betting.frequency.comparison %>%
  filter(betting_frequency_zscore >= 3.29 |
           betting_frequency_zscore <= -3.29) %>%
 dplyr::select(customerid, 
         Period,
         betting_frequency_zscore,
         betting_frequency)

nrow(betting.frequency.comparison.outliers)
```
4 participants in total, 2 limit setters and 2 non-limit setters.
<br>

Create a dataset that excludes participants who are in eligible for going on timeouts or self excluding and these outliers and then make all of the common column names and value names tidy for future plots:
```{r warnings = FALSE, message = FALSE}
betting.frequency.comparison.sansoutliers<- betting.frequency.comparison %>%
  # anti_join(betting.frequency.comparison.ineligible, by = "customerid") %>% 
  anti_join(betting.frequency.comparison.outliers, by = "customerid") %>% 
  ungroup() %>%
  dplyr::rename(Period1 = Period) %>%
  mutate(Period = fct_recode(Period1,
                             "Pre-message" = "betting_days_frequency_pre",
                             "Post-message" = "betting_days_frequency_post")) %>%
  mutate(Group = fct_recode(window_limit_setter,
                            "Limit 
                             setters" = "LimitSetter",
                            "No limit" = "None")) 
```
Create some summary data for this comparison.
<br>

Difference scores with CIs:
```{r warnings = FALSE, message = FALSE}
sumdat.av.bet.frequency.differencescore <- betting.frequency.comparison.sansoutliers %>%
  distinct(customerid, .keep_all = TRUE) %>%
  summarySE(measurevar = "betting_frequency_differencescore",
            groupvars=c("Group")) %>%
  mutate(lowerCI = betting_frequency_differencescore - ci,
         upperrCI = betting_frequency_differencescore + ci)  # calculate confidence intervals for the "betting_frequency_differencescore":
 
kable(sumdat.av.bet.frequency.differencescore, caption = "Pre-post difference score with 95% CIs: Betting frequency",
      digits = 2,
      col.names = c("Group", "n", "Difference sore", "SD", "SE", "95% CI", "Lower CI: 2.5%", "Upper CI: 97.5%")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 

```
<br>

Group means, SDs, and medians pre and post-message:
```{r warnings = FALSE, message = FALSE}
kable(betting.frequency.comparison.sansoutliers %>%
  group_by(Period,
           window_limit_setter) %>%
  dplyr::summarise(
    n(),
    mean = mean(betting_frequency),
    sd = sd(betting_frequency),
    median = median(betting_frequency)),
    caption = "Pre-post summary scores: Betting frequency",
      digits = 2,
      col.names = c("Period", "Group", "n", "Mean", "SD", "Median")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Next calculate Effect sizes (dz) for the within comparison (pre-post) of scores:

- We need a t value first to include in the calculation from the MOTE Package and this needs to be done separately for each group.

Create a dataset just to compare **limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}
betting.frequency.comparison.sansoutliers.limitsetters<- betting.frequency.comparison.sansoutliers %>%
  filter(window_limit_setter == "LimitSetter")

t.test(formula = betting_frequency ~ Period,
       data = betting.frequency.comparison.sansoutliers.limitsetters,
       paired = TRUE,
       alternative = "two.sided")

# Now calculate the effect Size:
d.dep.t.diff.t(t = -10.86, 130, a = 0.05)
```

Create a dataset just to compare **non-limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}
betting.frequency.comparison.sansoutliers.nonlimitsetters<- betting.frequency.comparison.sansoutliers %>%
  filter(window_limit_setter == "None") %>%
  print() 

t.test(formula = betting_frequency ~ Period,
       data = betting.frequency.comparison.sansoutliers.nonlimitsetters,
       paired = TRUE,
       alternative = "two.sided")

# Now calculate the effect Size:
d.dep.t.diff.t(t = -7.8968, 151, a = 0.05)
```  

#### ANCOVA: Betting frequency
Now run an ANCOVA to see the effect of limit setting on scores, with the difference score as the outcome and baseline scores and age as the covariates:
<br>

First filter out the "post-message" scores as we don't need these for the analysis and including these rows would result in a duplicated "average_daily_wager_differencescore" for each consumer due to the current setup of the data:
```{r warnings = FALSE, message = FALSE}
betting.frequency.comparison.sansoutliers.ANCOVA<- betting.frequency.comparison.sansoutliers %>%
  filter(Period == "Pre-message")
``` 

Next check the statical assumptions are met.
<br>
Normally distributed outcome variables across groups is not required but check anyway:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
# Plot distribution of variable for both groups to see whether this is normally distributed across groups:
hist_betting_freq_pre<-  ggplot(betting.frequency.comparison.sansoutliers.ANCOVA, 
                             aes(betting_frequency_differencescore, fill = window_limit_setter)) +
  geom_histogram(bins = 60) 

hist_betting_freq_pre 
```
This variable is much more normally distrubted distributed

##### Asumption 1: No influential outliers:
Outliers have already been removed: 3 participants in total, 2 limit setters and 1 non-limit setters

##### Asumption 2: The covariate should be linearly related to the dependent variable at each level of the independent variable:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
ggscatter(
  betting.frequency.comparison.sansoutliers.ANCOVA, x = "betting_frequency", y = "betting_frequency_differencescore",
  color = "window_limit_setter", add = "reg.line"
)+
  stat_regline_equation(
    aes(label =  paste(..eq.label.., ..rr.label.., sep = "~~~~"), color = window_limit_setter)
  )
```
ASSUMPTION 2 NOT MET: the covariate is not linearly related to the dependent variable at each level of the independent variable (regression lines cross)

##### Assumption 3: homogeneity of regression slope (No sig. interaction between covariate and grouping variable):
```{r warnings = FALSE, message = FALSE}
betting.frequency.comparison.sansoutliers.ANCOVA %>% anova_test(betting_frequency_differencescore ~ window_limit_setter*betting_frequency)
```
ASSUMPTION 3 NOT MET: Interaction term significant

##### Assumption 4: normality of within-group residuals:
```{r warnings = FALSE, message = FALSE}
# Compute model to calculate residuals:
norm.model4<- lm(betting_frequency_differencescore ~ betting_frequency + window_limit_setter, data = betting.frequency.comparison.sansoutliers.ANCOVA)

# Make residuals available:
norm.model4.metrics <- augment(norm.model4) 

# Run Shapiro Wilk's test on residuals:
shapiro_test(norm.model4.metrics$.resid)
```
ASSUMPTION 4 NOT MET: non-normality of residuals

##### Assumption 5: homogeneity of variance:
```{r warnings = FALSE, message = FALSE}

leveneTest(.resid~window_limit_setter, center = mean, data = norm.model4.metrics)
```
ASSUMPTION 5 MET: homogenity of residuals, non-sig. Levene's test

#### ROBUST ANCOVA: Betting frequency
No need to remove outliers here so lets make the original dataset suitable for this analysis:
```{r warnings = FALSE, message = FALSE}
betting.frequency.comparison.data.ANCOVA<- betting.frequency.comparison %>%
  # anti_join(betting.frequency.comparison.ineligible, by = "customerid") %>% # Remove ineligible consumers
  filter(Period == "betting_days_frequency_pre")
```

Run ROBUST ANCOVA:
```{r warnings = FALSE, message = FALSE}
set.seed(103)
Robust.ANCOVA.betting.frequency <- ancova(betting_frequency_differencescore ~ betting_frequency + window_limit_setter,
                                     data = betting.frequency.comparison.data.ANCOVA)

Robust.ANCOVA.betting.frequency

# How to select parts out this output for R Markdown manuscript:
betting.frequency.evalupts <- as.matrix(Robust.ANCOVA.betting.frequency$evalpts) %>% as.data.frame()
# then:
betting.frequency.evalupts[1,]
betting.frequency.evalupts[2,]

# Make all parts of the output accessible for manuscript:
betting.frequency.n1 <- as.matrix(Robust.ANCOVA.betting.frequency$n1) %>% as.data.frame()

betting.frequency.n2 <- as.matrix(Robust.ANCOVA.betting.frequency$n2) %>% as.data.frame()

betting.frequency.diff <- as.matrix(Robust.ANCOVA.betting.frequency$trDiff) %>% as.data.frame()

betting.frequency.se <- as.matrix(Robust.ANCOVA.betting.frequency$se) %>% as.data.frame()

betting.frequency.lowerci <- as.matrix(Robust.ANCOVA.betting.frequency$ci.low) %>% as.data.frame()

betting.frequency.upperci <- as.matrix(Robust.ANCOVA.betting.frequency$ci.hi) %>% as.data.frame()

betting.frequency.stat <- as.matrix(Robust.ANCOVA.betting.frequency$test) %>% as.data.frame()

betting.frequency.pvalue <- as.matrix(Robust.ANCOVA.betting.frequency$p.vals) %>% as.data.frame()

betting.frequency.pvalue5 <-betting.frequency.pvalue[5,]
```
Again, n1 in this output is non-setters, given the lower number of ps in the upper design points (see mean/median (above), and distribution of scores in figures below) and n2 is the limit setting group. This could be due the removal of more limit setters before starting these analyses, but the distribution of scores is different for this variable, with non-limit setters have some of the lowest scores of all. Check this assumption:
``` {r}
Robust.ANCOVA.betting.frequency$faclevels
```
Correct, non-setters are n1 here.

#### Plot gambling frequency comparison
Create plot (Figure5a):
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
# Recode factor order:
betting.frequency.comparison.sansoutliers$Period <- factor(betting.frequency.comparison.sansoutliers$Period,
                                                           c("Pre-message", "Post-message"))

Figure5.a <- ggplot(betting.frequency.comparison.sansoutliers, aes(x = Group, y = betting_frequency, fill = Period)) +
  geom_flat_violin(aes(fill = Period),
                   position = position_nudge(x = .1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
  geom_point(aes(x = as.numeric(Group)-.17, y = betting_frequency, colour = Period),
             position = position_jitter(width = .07), size = .4, shape = 20)+
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
  scale_color_manual(values=c("#E69F00", "#56B4E9")) +
  geom_boxplot(aes(x = Group, y = betting_frequency, fill = Period),  
               position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
  # OPTIONAL ADD INS:
  # geom_line(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = betting_frequency, group = Period, colour = Period), linetype = 3)+
  # geom_point(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = betting_frequency, group = Period, colour = Period), shape = 18) +
  # geom_point(data =sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.06, y=betting_frequency_differencescore)) +
  # geom_errorbar(data = sumdat.av.bet.frequency.differencescore,
  #               aes(x = as.numeric(Group)+.06, y = betting_frequency_differencescore, group = Period, colour = Period,
  #                  ymin = betting_frequency_differencescore - ci, ymax = betting_frequency_differencescore + ci), width = .05)+
  # annotate("text", x = 1.42:2.42, y = 36, # Add in mean difference scores and their confidence intervals
  #          label = c("Mean difference between periods = -14.9 days 
  #                    [95% CI: -12.2, -17.7], dz = 0.96 [0.74, 1.16]                      ", 
  #                    "Mean difference between periods = -7.8 days
#                    [95% CI: -5.9, -9.8], dz = 0.64 [0.47, 0.82]                      "),
#          size = 2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
  theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1, family = "Poppins"))+
  theme(legend.position = c(0.85, 0.9), 
        legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
        legend.title.align = .5, 
        legend.title=element_text(size=10)) +
  # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  theme(plot.margin = unit(c(.1,.2,.5,-2.2), "cm"))+ 
  scale_x_discrete(expand = c(0.3, 0))+
  scale_y_continuous(name = "Betting frequency",
                     breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80)) +
  xlab('')+
  theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
  coord_flip()

# View new plot:
Figure5.a
```
Save plot:
```{r warnings = FALSE, message = FALSE}
ggsave("Figures/Figure5.a.jpeg",
       width = 170,
       height = 130,
       units = c("mm"),
       dpi = 600
)
```
<br><br>


## Comparison of pre & post gambling intensity
 First create a workable dataset for this comparison, including the creation of z scores to identify and remove outliers: 
```{r warnings = FALSE, message = FALSE}
betting.intensity.comparison<- wager.comaprison.data %>%
  mutate(betting_intensity_differencescore = betting_intensity_pre - betting_intensity_post) %>%
  pivot_longer(c("betting_intensity_pre",
                 "betting_intensity_post"), 
               names_to = "Period",
               values_to = "betting_intensity") %>%
 dplyr::select(customerid, 
         window_limit_setter, 
         Period, 
         betting_intensity,
         self_exclusion,
         self_exclusion_start_date,
         betting_intensity_differencescore,
         timeout_start_date_pre,
         timeout_finish_date_pre,
         timeout_start_date_post,
         timeout_start_date_post,
         timeout_pre,
         timeout_duration_pre,
         timeout_duration_post,
         timeout_post) %>%
  group_by(window_limit_setter,
           Period) %>%
  mutate(betting_intensity_zscore = (betting_intensity - mean(betting_intensity))/ sd(betting_intensity))
```

This outcome will be affected by people using timeouts and self-exclusion and so we need to remove these from sample.Let's remove anyone who went on a time out of more than 2 weeks either side of messages.
<br>

We can use the dataset created earlier:

- "betting.frequency.comparison.ineligible"

Again, this will exclude 21 people:

- One had an extended timeout prior to messages and self excluded following.
- Two had an extended timeout prior to messages
- One self excluded following messages
- The other 17 all had extended timeouts following messages


Identify outliers using pre-registered method and see how many cases this would remove: 
```{r warnings = FALSE, message = FALSE}
betting.intensity.comparison.outliers<-  betting.intensity.comparison %>%
  filter(betting_intensity_zscore >= 3.29 |
           betting_intensity_zscore <= -3.29) %>%
 dplyr::select(customerid, 
         Period,
         betting_intensity_zscore,
         betting_intensity) %>%
  ungroup() %>%
  distinct(customerid, .keep_all = TRUE) 

nrow(betting.intensity.comparison.outliers)
```
9  participants in total, 4 limit setters and 5 non-limit setters
<br>

Create a dataset that excludes participants who are in eligible for going on timeouts or self excluding and these outliers and then make all of the common column names and value names tidy for future plots:
```{r warnings = FALSE, message = FALSE}
betting.intensity.comparison$Period<- as.factor(betting.intensity.comparison$Period) # Make variable a factor to change the level names

betting.intensity.comparison.sansoutliers<- betting.intensity.comparison %>%
  # anti_join(betting.frequency.comparison.ineligible, by = "customerid") %>% 
  anti_join(betting.intensity.comparison.outliers, by = "customerid") %>% 
  ungroup() %>%
  dplyr::rename(Period1 = Period) %>%
  mutate(Period = fct_recode(Period1,
                             "Pre-message" = "betting_intensity_pre",
                             "Post-message" = "betting_intensity_post")) %>%
  mutate(Group = fct_recode(window_limit_setter,
                            "Limit 
                             setters" = "LimitSetter",
                            "No limit" = "None")) 
```

Note: One of the outliers for comparison is already excluded for being on timeout/closing account/Self exclusion. This is calculated using the following code:
```{r warnings = FALSE, message = FALSE, results = FALSE}
# betting.intensity.comparison.outliers %>%
#   anti_join(betting.frequency.comparison.ineligible, by = "customerid")
```
Create some summary data for this comparison.
<br>

Difference scores with CIs:
```{r warnings = FALSE, message = FALSE}
sumdat.betting.intensity.differencescore <- betting.intensity.comparison.sansoutliers %>%
  distinct(customerid, .keep_all = TRUE) %>%
  summarySE(measurevar = "betting_intensity_differencescore",
            groupvars=c("Group")) %>%
  mutate(lowerCI = betting_intensity_differencescore - ci,
         upperrCI = betting_intensity_differencescore + ci) # calculate confidence intervals for "betting_intensity_differencescore":

kable(sumdat.betting.intensity.differencescore, caption = "Pre-post difference score with 95% CIs: Betting intensity ",
      digits = 2,
      col.names = c("Group", "n", "Difference sore", "SD", "SE", "95% CI", "Lower CI: 2.5%", "Upper CI: 97.5%")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 

```
<br>

Group means, SDs, and medians pre and post-message:
```{r warnings = FALSE, message = FALSE}
kable(betting.intensity.comparison.sansoutliers %>%
  group_by(Period,
           window_limit_setter) %>%
  dplyr::summarise(
    n = n(),
    mean = mean(betting_intensity),
    sd = sd(betting_intensity),
    median = median(betting_intensity)),
    caption = "Pre-post summary scores: Betting intensity",
      digits = 2,
      col.names = c("Period", "Group", "n", "Mean", "SD", "Median")) %>%
   kable_classic(full_width = F, html_font = "Cambria") 
```
<br>

Next calculate Effect sizes (dz) for the within comparison (pre-post) of scores:

- We need a t value first to include in the calculation from the MOTE Package and this needs to be done separately for each group

Create a dataset just to compare **limit setters** pre-and post:
```{r warnings = FALSE, message = FALSE}
betting.intensity.comparison.sansoutliers.limitsetters<- betting.intensity.comparison.sansoutliers %>%
  filter(window_limit_setter == "LimitSetter") 
t.test(formula = betting_intensity ~ Period,
       data = betting.intensity.comparison.sansoutliers.limitsetters,
       paired = TRUE,
       alternative = "two.sided")

# Now calculate the effect Size:
d.dep.t.diff.t(t = -5.6019, 129, a = 0.05)
```

Create a dataset just to compare **non-limit setters*8 pre-and post:
```{r warnings = FALSE, message = FALSE}
betting.intensity.comparison.sansoutliers.nonlimitsetters<- betting.intensity.comparison.sansoutliers %>%
  filter(window_limit_setter == "None") %>%
  print() 

t.test(formula = betting_intensity ~ Period,
       data = betting.intensity.comparison.sansoutliers.nonlimitsetters,
       paired = TRUE,
       alternative = "two.sided")

# Now calculate the effect Size:
d.dep.t.diff.t(t = -4.8486, 145, a = 0.05)
```

### ANCOVA: Betting intensity
Now run an ANCOVA to see the effect of limit setting on scores, with the difference score as the outcome and baseline scores and age as the covariates:
<br>

First filter out the "post-message" scores as we don't need these for the analysis and including these rows would result in a duplicated "average_daily_wager_differencescore" for each consumer due to the current setup of the data:
```{r warnings = FALSE, message = FALSE}
betting.intensity.comparison.sansoutliers.ANCOVA<- betting.intensity.comparison.sansoutliers %>%
  filter(Period == "Pre-message")
```
Next check the statical assumptions are met:
<br>

Normally distributed outcome variables across groups is not required but check anyway:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
# Plot distribution of variable for both groups to see whether this is normally distributed across groups:
hist_betting_intensity_pre<-  ggplot(betting.intensity.comparison.sansoutliers.ANCOVA, 
                                aes(betting_intensity_differencescore, fill = window_limit_setter)) +
  geom_histogram(bins = 60) 

hist_betting_intensity_pre # Again, this variable is much more normally distrubted distributed, although more kurtosis here
```
<br>

##### Asumption 1: No influential outliers:
Outliers have already been removed: 10 participants in total, 4 limit setters and 6 non-limit setters

##### Asumption 2: The covariate should be linearly related to the dependent variable at each level of the independent variable:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
ggscatter(
  betting.intensity.comparison.sansoutliers.ANCOVA, x = "betting_intensity", y = "betting_intensity_differencescore",
  color = "window_limit_setter", add = "reg.line"
)+
  stat_regline_equation(
    aes(label =  paste(..eq.label.., ..rr.label.., sep = "~~~~"), color = window_limit_setter)
  )
```
<br>

ASSUMPTION 2 NOT MET: the covariate is not linearly related to the dependent variable at each level of the independent variable (regression lines cross)

##### Assumption 3: homogeneity of regression slope (No sig. interaction between covariate and grouping variable):
```{r warnings = FALSE, message = FALSE}
betting.intensity.comparison.sansoutliers.ANCOVA %>% anova_test(betting_intensity_differencescore ~ window_limit_setter*betting_intensity)
```
ASSUMPTION 3 NOT MET: Interaction term significant

##### Assumption 4: normality of within-group residuals:
```{r warnings = FALSE, message = FALSE}
# Compute model to calculate residuals:
norm.model5<- lm(betting_intensity_differencescore ~ betting_intensity + window_limit_setter, data = betting.intensity.comparison.sansoutliers.ANCOVA)
# Make residuals available:
norm.model5.metrics <- augment(norm.model5) 
# Run Shaprio wilks test on residuals:
shapiro_test(norm.model5.metrics$.resid)
```
ASSUMPTION 4 NOT MET: non-normality of residuals

##### Assumption 5: homogeneity of variance:
```{r warnings = FALSE, message = FALSE}
leveneTest(.resid~window_limit_setter, center = mean, data = norm.model5.metrics)
```
ASSUMPTION 5 NOT MET: non-homogeneity of residuals, sig. Levene's test

Hi#### ROBUST ANCOVA: Betting intensity
No need to remove outliers here so lets make the original dataset suitable for this analysis:
```{r warnings = FALSE, message = FALSE}
betting.intensity.comparison.data.ANCOVA<- betting.intensity.comparison %>%
  # anti_join(betting.frequency.comparison.ineligible, by = "customerid") %>% # Remove ineligible consumers
  filter(Period == "betting_intensity_pre")
```

Run ROBUST ANCOVA:
```{r warnings = FALSE, message = FALSE}
set.seed(104)
Robust.ANCOVA.betting.intensity <- ancova(betting_intensity_differencescore ~ betting_intensity + window_limit_setter,
                                              data = betting.intensity.comparison.data.ANCOVA)

Robust.ANCOVA.betting.intensity 

# How to select parts out this output for R Markdown manuscript:
betting.intensity.evalupts <- as.matrix(Robust.ANCOVA.betting.intensity$evalpts) %>% as.data.frame()
# then:
betting.intensity.evalupts[1,]
betting.intensity.evalupts[2,]

# Make all parts of the output accessible for manuscript:
betting.intensity.n1 <- as.matrix(Robust.ANCOVA.betting.intensity$n1) %>% as.data.frame()

betting.intensity.n2 <- as.matrix(Robust.ANCOVA.betting.intensity$n2) %>% as.data.frame()

betting.intensity.diff <- as.matrix(Robust.ANCOVA.betting.intensity$trDiff) %>% as.data.frame()

betting.intensity.se <- as.matrix(Robust.ANCOVA.betting.intensity$se) %>% as.data.frame()

betting.intensity.lowerci <- as.matrix(Robust.ANCOVA.betting.intensity$ci.low) %>% as.data.frame()

betting.intensity.upperci <- as.matrix(Robust.ANCOVA.betting.intensity$ci.hi) %>% as.data.frame()

betting.intensity.stat <- as.matrix(Robust.ANCOVA.betting.intensity$test) %>% as.data.frame()

betting.intensity.pvalue <- as.matrix(Robust.ANCOVA.betting.intensity$p.vals) %>% as.data.frame()

# As the first 3 p-values here are very small these will need to be put into the manuscript as conditional statements that print "p<0.001" if that statement is true. Otherwise, simply printing these values will result in "p = 0"
betting.intensity.pvalue1 <- betting.intensity.pvalue[1,]
betting.intensity.pvalue2 <- betting.intensity.pvalue[2,]
betting.intensity.pvalue3 <- betting.intensity.pvalue[3,]

```
Again, n1 in this output is non-setters, given the lower number of ps in the upper design points (see mean/median (above), and distribution of scores in figures below) and n2 is the limit setting group. This could be due the removal of more limit setters before starting these analyses, but the distribution of scores is different for this variable, with non-limit setters have some of the lowest scores of all. Check this assumption:
``` {r}
Robust.ANCOVA.betting.intensity$faclevels
```
Correct, non-setters are n1 here.

#### Plot betting intensity comparison
Create plot (Figure5b):
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
# Recode factor order:
betting.intensity.comparison.sansoutliers$Period <- factor(betting.intensity.comparison.sansoutliers$Period,
                                                              c("Pre-message", "Post-message"))

Figure5.b <- ggplot(betting.intensity.comparison.sansoutliers, aes(x = Group, y = betting_intensity, fill = Period)) +
  geom_flat_violin(aes(fill = Period),
                   position = position_nudge(x = .1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
  geom_point(aes(x = as.numeric(Group)-.17, y = betting_intensity, colour = Period),
             position = position_jitter(width = .07), size = .4, shape = 20)+
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
  scale_color_manual(values=c("#E69F00", "#56B4E9")) +
  geom_boxplot(aes(x = Group, y = betting_intensity, fill = Period),  
               position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
  # OPTIONAL ADD INS:
  # geom_line(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = betting_intensity, group = Period, colour = Period), linetype = 3)+
  # geom_point(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = betting_intensity, group = Period, colour = Period), shape = 18) +
  # geom_point(data =sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.06, y=betting_intensity_differencescore)) +
  # geom_errorbar(data = sumdat.av.bet.frequency.differencescore,
  #               aes(x = as.numeric(Group)+.06, y = betting_intensity_differencescore, group = Period, colour = Period,
  #                  ymin = betting_intensity_differencescore - ci, ymax = betting_intensity_differencescore + ci), width = .05)+
  # annotate("text", x = 1.42:2.42, y = 36, # Add in mean difference scores and their confidence intervals
  #          label = c("Mean difference between periods = -14.9 days 
  #                    [95% CI: -12.2, -17.7], dz = 0.96 [0.74, 1.16]                      ", 
  #                    "Mean difference between periods = -7.8 days
#                    [95% CI: -5.9, -9.8], dz = 0.64 [0.47, 0.82]                      "),
#          size = 2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
  theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1.8, family = "Poppins"))+
  theme(legend.position = c(0.85, 0.9), 
        legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
        legend.title.align = .5, 
        legend.title=element_text(size=10)) +
  # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  theme(plot.margin = unit(c(.1,.2,.45,-2.2), "cm"))+ 
  scale_x_discrete(expand = c(0.3, 0))+
  scale_y_continuous(name = "Betting intensity") +
  xlab('')+
  theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
  coord_flip()

# View new plot:
Figure5.b
```
Save plot:
```{r warnings = FALSE, message = FALSE}
jpeg("Figure5.b.jpeg")
ggsave("Figures/Figure5.b.jpeg",
       width = 170,
       height = 130,
       units = c("mm"),
       dpi = 600
)
```

Plot truncated version:
```{r warnings = FALSE, message = FALSE, fig.align = 'center'}
Figure5truncated.b <- ggplot(betting.intensity.comparison.sansoutliers, aes(x = Group, y = betting_intensity, fill = Period)) +
  geom_flat_violin(aes(fill = Period),
                   position = position_nudge(x = .1, y = 0), adjust = .8, trim = TRUE, alpha = .75, colour = "black")+
  geom_point(aes(x = as.numeric(Group)-.17, y = betting_intensity, colour = Period),
             position = position_jitter(width = .07), size = .4, shape = 20)+
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
  scale_color_manual(values=c("#E69F00", "#56B4E9")) +
  geom_boxplot(aes(x = Group, y = betting_intensity, fill = Period),  
               position = position_dodge(.17), outlier.shape = NA, alpha = 1, width = .1, colour = "black")+
  # OPTIONAL ADD INS:
  # geom_line(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = betting_intensity, group = Period, colour = Period), linetype = 3)+
  # geom_point(data = sumdat.av.day.wager, aes(x = as.numeric(Group)+.1, y = betting_intensity, group = Period, colour = Period), shape = 18) +
  # geom_point(data =sumdat.av.bet.frequency.differencescore, aes(x = as.numeric(Group)+.06, y=betting_intensity_differencescore)) +
  # geom_errorbar(data = sumdat.av.bet.frequency.differencescore,
  #               aes(x = as.numeric(Group)+.06, y = betting_intensity_differencescore, group = Period, colour = Period,
  #                  ymin = betting_intensity_differencescore - ci, ymax = betting_intensity_differencescore + ci), width = .05)+
  # annotate("text", x = 1.42:2.42, y = 36, # Add in mean difference scores and their confidence intervals
  #          label = c("Mean difference between periods = -14.9 days 
  #                    [95% CI: -12.2, -17.7], dz = 0.96 [0.74, 1.16]                      ", 
  #                    "Mean difference between periods = -7.8 days
#                    [95% CI: -5.9, -9.8], dz = 0.64 [0.47, 0.82]                      "),
#          size = 2.5) + # Better to add annotations later when joining the plots together to avoid aspect issues
theme(axis.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"))+
  theme(axis.title.x = element_text(color="black", size=9, face="plain", vjust=-1.8, family = "Poppins"))+
  theme(legend.position = c(0.85, 0.9), 
        legend.text = element_text(color = "black", size = 8, face = "plain", family = "Poppins"),
        legend.title.align = .5, 
        legend.title=element_text(size=10)) +
  # theme(legend.position = "none") + # For some reason the legend is duplicating when joining this plot and the previous one together, So remove it here
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  theme(plot.margin = unit(c(.1,.2,.45,-2.2), "cm"))+ 
  scale_x_discrete(expand = c(0.3, 0))+
  scale_y_continuous(name = "Betting intensity", 
                     limits = c(0, 60), 
                     breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80)) +
  xlab('')+
  theme(axis.title.y = element_text( face="plain", family = "Poppins", size = 9))+
  coord_flip()

# View new plot:
Figure5truncated.b
```
This plot has been capped at 60 to enable proper visualisation.
<br>

Save plot:
```{r warnings = FALSE, message = FALSE}
ggsave("Figures/Figure5truncated.b.jpeg",
       width = 170,
       height = 130,
       units = c("mm"),
       dpi = 600
)
```
<br><br>

### Join Figure 5 plots together
##### Truncated plots
```{r warnings = FALSE, message = FALSE, fig.align = 'center', fig.height = 6}
Figure5 <- Figure5.a/
  Figure5truncated.b +
  plot_annotation(tag_levels = 'A') +
  plot_layout(guides = 'collect')&
  plot_annotation(title = '') &
  theme(plot.margin = unit(c(-.5,.1,.2,-2), "cm")) &
  theme(legend.position = "top",
        legend.text = element_text( color="black", size=7, face="plain", family = "Poppins"),
        legend.title=element_text(size=9)) 
  # annotate("text", x = 1.26:2.26, y = 730,# Annotations for plot 3.a
  #          label = c("Mean difference between periods = $-211.5 
  #                    [95% CI: -157.1, -265.8], dz = 0.64 [0.46, 0.81]                      ", 
  #                    "Mean difference between periods = $-14.1 
  #                    [95% CI: -32.8, -4.5], dz = 0.12 [-0.04, 0.28]                      "),
  #          size = 2.5) + 
  # annotate("text", x = 1.42:2.42, y = 36, # Annotations for plot 3.b
  #          label = c("Mean difference between periods = $-250.3663
  #                    [95% CI: -334.4 -166.3], dz = 0.48 [0.31, 0.65]                      ",
  #                    "Mean difference between periods = $-19.8
  #                    [95% CI: -43.9, 4.3], dz = 0.13 [-0.03, 0.29]                      "),
#          size = 2.5) +
# annotate("text", x = 1.42:2.42, y = 36, # Annotations for plot 3.c
#          label = c("Mean difference between periods = -14.9 days 
#                    [95% CI: -12.2, -17.7], dz = 0.96 [0.74, 1.16]                      ", 
#                    "Mean difference between periods = -7.8 days
#                    [95% CI: -5.9, -9.8], dz = 0.64 [0.47, 0.82]                      "),
#          size = 2.5) +


# View new plot:
Figure5
```
Save plot:
```{r warnings = FALSE, message = FALSE}
ggsave("Figures/Figure5.pdf",
              width = 150,
              height = 120,
              units = c("mm"),
              dpi = 600
       )

ggsave("Figures/Figure5preprint.jpeg",
       width = 90,
       height = 120,
       units = c("mm"),
       dpi = 600
)
```

# --------------------------------------------------------------------------------

<center>
# Post-peer review additions to analyses & manuscript
</center>

After submitting our manuscript to the journal *Addiction* we were asked to make multiple changes to the manuscript. Each new analysis and its outcome are documented here. All the code above this section remains exactly as it was pre-submission other than our exclusions of customers: based on reviewer suggestions we retained anyone who used a timeout or self-exclusion in the messaging window, but removed anyone who was not active for the entire messaging window because they were on a timeout or self- excluded, or because they closed their account prior to receiving the first message. 
<br>

## Power analyses

We were asked to change our confirmatory hypothesis tests from chi-squared analyses (reported abvoe) to logistic regressions and adjust our power calculations accordingly, as suggested by the statistical editor. We performed our power analysis using G*Power software, but decided to reported our revised input parameters for the power analysis in full here for increased transparency and reproducibility.

### Hypothesis 1
H$^1$:Online wagerers in the messaging conditions will be more likely than controls (i.e., those who do not receive a message) to set a deposit limit within five days of messaging (the same time period used by BIT, 2018).
 
We explain all of the input parameters for this first power analysis below before presenting the G*Power protocol of power analysis (i.e., the output from the calculation provided by the software) but do not do this hereafter. 

- Tail(s): Two
- Pr(Y=1|X=1) H1: 0.1 (probability of limit setting limits with X = 1 (x = predictor, or messages in this case [1 = limit, 0 = no limit]) under H1 is p2 = 0.025[2.5%])
- Pr(Y=1|X=1) H0: 0.05 (Probability of limit setting limits with X = 1 under H0 is p2 = 0.005[0.05% to account for random limits set not prompted by messages])
- The above two values can be used to calculate a proposed **odds ratio**, which here would be [i.e., (0.025/0.975)/(0.005/0.995) **= 5.10**)
- Assuming the above proportions, our anticipated Odds ratio is
- $\alpha$ err prob: 0.05
- Power (1-$\beta$ err prob): 0.95 
- R2 other X: 0
- X distribution: Binomial
- X parm $\pi$: proportion in the intervention group (X = 1). For this we need to compute the relative proportion of the sample that are in the messaging groups so let's do that below. 

Compute proportions for X parm $\pi$ value:
```{r}
# Messages versus controls:
hypothesis.test.data %>% 
  group_by(condition) %>% 
  dplyr::summarise(n= n()) %>% 
  mutate(group = case_when(condition >1 ~ "Messages", 
                           condition == 1  ~ "Control")) %>% 
  group_by(group) %>% 
  dplyr::summarise(sum = sum(n)) %>% 
  mutate(Proportion = sum/nrow(hypothesis.test.data)*100) %>% 
  print()

```

**G Power protocol of power analysis:**

- **Options:** Large sample z-Test, Demidenko (2007) with var corr 
- **Analysis:**	A priori: Compute required sample size 
- Input: Tail(s) =	Two
-	Pr(Y=1|X=1) H1 = 0.025
-	Pr(Y=1|X=1) H0 = 0.005
-	$\alpha$ err prob	=	0.05
-	Power (1--$\beta$ err prob) =	0.95
-	R$^2$ other X =	0
-	X distribution =	Binomial
-	X parm $\pi$ =	0.856
- **Output:**	Critical z = 1.9599640
- Total sample size	=	4768
- Actual power =	0.9500135
			
### Hypothesis 2

H$^2$: Online wagerers who receive positive social perception messages will be most likely to set a deposit limit within five days of messaging[^1], followed by those who receive positive personal perception messages, and then those who receive informative messages.

2.1: Social messages (i.e., conditions4 & 5) vs. Informative messages (i.e, conditions 2 & 3):

- Odds ratio: (0.035/0.965)/(0.015/0.985) = 2.38

Compute proportions for X parm $\pi$ value:

```{r}
# Social versus informative:
hypothesis.test.data %>% 
  group_by(condition) %>% 
  dplyr::summarise(n= n()) %>% 
  mutate(group = case_when(condition == 4 ~ "Social", 
                           condition == 5 ~ "Social", 
                           condition == 2  ~ "Informative",
                           condition == 3  ~ "Informative")) %>% 
  group_by(group) %>% 
  dplyr::summarise(sum = sum(n)) %>% 
  pivot_wider(names_from = group,
              values_from = sum) %>% 
  mutate(total = Informative + Social) %>% 
 mutate(Proportion.social.inform = (Social/total)*100) 
```
**G Power protocol & outcomes for power analysis:**

- **Options:** Large sample z-Test, Demidenko (2007) with var corr 
- **Analysis:**	A priori: Compute required sample size 
- Input: Tail(s) =	Two
-	Pr(Y=1|X=1) H1 = 0.035
-	Pr(Y=1|X=1) H0 = 0.015
-	$\alpha$ err prob	=	0.05
-	Power (1--$\beta$ err prob) =	0.95
-	R$^2$ other X =	0
-	X distribution =	Binomial
-	X parm $\pi$ =	0.52
- **Output:**	Critical z = 1.9599640
-	Total sample size	=	3169
-	Actual power =	0.9500379
	
2.2: Personal messages (i.e., conditions  6 & 7) versus Informative messages (i.e, conditions 2 & 3):

- Odds ratio: (0.025/0.975)/(0.015/0.985) = 1.68

Compute proportions for X parm $\pi$ value:

```{r}
# Personal versus informative:
hypothesis.test.data %>% 
  group_by(condition) %>% 
  dplyr::summarise(n= n()) %>% 
  mutate(group = case_when(condition == 6 ~ "Personal", 
                           condition == 7 ~ "Personal", 
                           condition == 2  ~ "Informative",
                           condition == 3  ~ "Informative")) %>% 
  group_by(group) %>% 
  dplyr::summarise(sum = sum(n)) %>% 
  pivot_wider(names_from = group,
              values_from = sum) %>% 
  mutate(total = Informative + Personal) %>% 
 mutate(Proportion.personal.inform = (Personal/total)*100) 
```
**G Power protocol & outcomes for power analysis:**

- **Options:** Large sample z-Test, Demidenko (2007) with var corr 
- **Analysis:**	A priori: Compute required sample size 
- Input: Tail(s) = Two
-	Pr(Y=1|X=1) H1 = 0.025
-	Pr(Y=1|X=1) H0 = 0.015
-	$\alpha$ err prob	=	0.05
-	Power (1--$\beta$ err prob) =	0.95
-	R$^2$ other X =	0
-	X distribution =	Binomial
-	X parm $\pi$ =	0.498
- **Output:**	Critical z = 1.9599640
- Total sample size =	10156
- Actual power =	0.9500087

2.3: Social messages (i.e., conditions  4 & 5) versus Personal messages (i.e., conditions  6 & 7):

- Odds ratio: (0.035/0.965)/(0.025/0.975) = 1.41

Compute proportions for X parm $\pi$ value:

```{r}
# Social versus personal:
hypothesis.test.data %>% 
  group_by(condition) %>% 
  dplyr::summarise(n= n()) %>% 
  mutate(group = case_when(condition == 6 ~ "Personal", 
                           condition == 7 ~ "Personal", 
                           condition == 4  ~ "Social",
                           condition == 5  ~ "Social")) %>% 
  group_by(group) %>% 
  dplyr::summarise(sum = sum(n)) %>% 
  pivot_wider(names_from = group,
              values_from = sum) %>% 
  mutate(total = Social + Personal) %>% 
 mutate(Proportion.Social.personal = (Social/total)*100) 
```
**G Power protocol & outcomes for power analysis:**

- **Options:** Large sample z-Test, Demidenko (2007) with var corr 
- **Analysis:**	A priori: Compute required sample size 
- Input: Tail(s) = Two
-	Pr(Y=1|X=1) H1 = 0.035
-	Pr(Y=1|X=1) H0 = 0.025
-	$\alpha$ err prob	=	0.05
-	Power (1--$\beta$ err prob) =	0.95
-	R$^2$ other X =	0
-	X distribution =	Binomial
-	X parm $\pi$ =	0.504
- **Output:**	Critical z =	1.9599640
- Total sample size =	15111
- Actual power =	0.9500091

### Hypothesis 3
H$^3$: Messages delivered via in-account notification will be more effective at increasing deposit limit uptake than those delivered via email (due to reduced friction).
			
- Odds ratio: (0.035/0.965)/(0.015/0.985) = 2.38
Compute proportions for X parm $\pi$ value:

```{r}
# In-Account versus email delivery:
hypothesis.test.data %>% 
  group_by(condition) %>% 
  dplyr::summarise(n= n()) %>% 
  mutate(group = case_when(condition == 2 ~ "Email", 
                           condition == 4 ~ "Email", 
                           condition == 6  ~ "Email",
                           condition == 3  ~ "Account",
                           condition == 5  ~ "Account",
                           condition == 7  ~ "Account")) %>% 
  group_by(group) %>% 
  dplyr::summarise(sum = sum(n)) %>% 
  pivot_wider(names_from = group,
              values_from = sum) %>% 
  mutate(total = Email + Account) %>% 
 mutate(Proportion.Account.Email = (Account/total)*100) 
```			
**G Power protocol of power analysis:**
	
- **Options:** Large sample z-Test, Demidenko (2007) with var corr 
- **Analysis:**	A priori: Compute required sample size 
- Input: Tail(s) =	Two
-	Pr(Y=1|X=1) H1 = 0.03
-	Pr(Y=1|X=1) H0 = 0.02
-	$\alpha$ err prob	=	0.05
-	Power (1--$\beta$ err prob) =	0.95
-	R$^2$ other X =	0
-	X distribution =	Binomial
-	X parm $\pi$ =	0.481
- **Output:**	Critical z = 1.9599640
- Total sample size	=	12642
- Actual power =	0.9500131

## New participant sample description table

Reviewers and editors requested a more detailed participant characteristics table which will certainly be informative. Let's create a html using the gtsummary package and we will tidy this version up in the ms. 
```{r}
# Wrangle data into a usable format for Table:
table1.data<- hypothesis.test.data %>% 
    mutate(condition = as.character(condition)
         ) %>%
  dplyr::select(condition,
                                Age = age, 
                                Gender = gender,
                                limit_setter_pre,
                                "Average daily wager" = average_daily_wager_pre,
                                "SD of daily wager" = daily_wager_SD_pre,
                                "Net loss" = net_loss_pre,
                                "Betting frequency" = betting_days_frequency_pre,
                                "Betting intensity" =  betting_intensity_pre) %>%
  mutate(Gender = fct_recode(Gender,
                         "Female" = "F",
                         "Male" = "M",
                         "Unknown" = "U"
                         )) %>%
  mutate(limit_setter_pre = fct_recode(limit_setter_pre,
                         "No" = "None",
                         "Yes" = "PreLimitSetter")) %>%
  dplyr::rename("Previous limit set" = limit_setter_pre) %>%
   mutate(condition = fct_recode(condition,
                         "Controls" = "1",
                         "Informative (e)"= "2",
                         "Informative (i-a)" = "3",
                         "Social (e)"  = "4",
                         "Social (i-a)" = "5",
                         "Personal (e)" = "6",
                         "Personal (i-a)" = "7"))

# Create table:
tbl_summary(table1.data, # Dataset with select columns to summarise
    by = condition, # split table by group
  statistic = list(all_continuous() ~ "{mean} ({sd})", # what stats to present and how
                     all_categorical() ~ "{n} ({p}%)"),# what stats to present and how
    digits = all_continuous() ~ 1)  %>%
   add_overall() %>% # add an overall column
  modify_header(label ~ "**Variable**") %>% # update the first column header%>%
  as_kable_extra(booktabs = T,
                 caption = "Sample characteristics") %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br><br>

## Amend Figure 1: CONSORT Flowchart
Thankfully, the editor picked up that there were some errors in the figures within our flowchart (Fig 1) outlining our selection and recruitment process. Let's recreate this figure entirely from the data using R code (rather than doing it in Microsoft Word and copy-pasting, as previously done) which should avoid future calculation errors.


```{r message=FALSE, warning=FALSE, fig.align = 'center', results = FALSE, fig.height = 8.47, fig.width = 5.61}

TxtGp <- getOption("Poppins", default = gpar(fontfamily = "Poppins", fontsize = 8))

TxtGp2 <- getOption("Poppins", default = gpar(fontfamily = "Poppins", fontsize = 10))

grid.newpage()

# box1
box1 <-boxGrob(y = 0.91,
               x = 0.63,
        txt_gp = TxtGp,
                      glue("All customers meeting eligibility criteria identified",
                           "by online wagering operators",
                           .sep = "\n"))

# Figures for box 2:
# No. customers overall & by Operator:
starting_sample<- nrow(all.operators.data) # Starting sample
Operator_1_Starting_Sample <- all.operators.data %>% group_by(operator) %>% dplyr::summarise(n = n()) %>% filter(operator == "1") %>%dplyr::select(n) # Operator 1 starting sample
Operator_2_Starting_Sample <- all.operators.data %>% group_by(operator) %>% dplyr::summarise(n = n()) %>% filter(operator == "2") %>%dplyr::select(n) # Operator 2 starting sample
Operator_3_Starting_Sample <- all.operators.data %>% group_by(operator) %>% dplyr::summarise(n = n()) %>% filter(operator == "3") %>%dplyr::select(n) # Operator 3 starting sample
Operator_4_Starting_Sample <- all.operators.data %>% group_by(operator) %>% dplyr::summarise(n = n()) %>% filter(operator == "4") %>%dplyr::select(n) # Operator 4 starting sample

# Box 2
box2 <-boxGrob(y = 0.76,
               x = 0.63,
        txt_gp = TxtGp,
                      glue("Random samples of these customers selected by",
                      "each operator:",
                           "- Operator 1: n = {no1}",
                           "- Operator 2: n = {no2}",
                           "- Operator 3: n = {no3}",
                           "- Operator 4: n = {no4}",
                           "- Total: n = {ntotal}",
                           no1 = Operator_1_Starting_Sample,
                           no2 = Operator_2_Starting_Sample,
                           no3 = Operator_3_Starting_Sample,
                           no4 = Operator_4_Starting_Sample,
                           ntotal = starting_sample,
                           .sep = "\n"))

box1
box2
connectGrob(box1, box2, "vertical"
            # , lty_gp = gpar(lwd = .5)
            )

# Box 3
box3 <-boxGrob(y = 0.85,
               x = 0.17,
        txt_gp = TxtGp2,
        box_gp = gpar(fill = "#add8e6"), 
                      glue("Identification &",
                           "sampling",
                           .sep = "\n"))
box3

# Figures for box 4:
# No. customers by condition:
Condition_1_Starting_Sample <- all.operators.data %>% group_by(condition) %>% dplyr::summarise(n = n()) %>% filter(condition == "1") %>%dplyr::select(n) # Condition 1 starting sample
Condition_2_Starting_Sample <- all.operators.data %>% group_by(condition) %>% dplyr::summarise(n = n()) %>% filter(condition == "2") %>%dplyr::select(n) # Condition 2 starting sample
Condition_3_Starting_Sample <- all.operators.data %>% group_by(condition) %>% dplyr::summarise(n = n()) %>% filter(condition == "3") %>%dplyr::select(n) # Condition 3 starting sample
Condition_4_Starting_Sample <- all.operators.data %>% group_by(condition) %>% dplyr::summarise(n = n()) %>% filter(condition == "4") %>%dplyr::select(n) # Condition 4 starting sample
Condition_5_Starting_Sample <- all.operators.data %>% group_by(condition) %>% dplyr::summarise(n = n()) %>% filter(condition == "5") %>%dplyr::select(n) # Condition 5 starting sample
Condition_6_Starting_Sample <- all.operators.data %>% group_by(condition) %>% dplyr::summarise(n = n()) %>% filter(condition == "6") %>%dplyr::select(n) # Condition 6 starting sample
Condition_7_Starting_Sample <- all.operators.data %>% group_by(condition) %>% dplyr::summarise(n = n()) %>% filter(condition == "7") %>%dplyr::select(n) # Condition 7 starting sample

# Box 4
box4 <-boxGrob(y = 0.54,
               x = 0.63,
        txt_gp = TxtGp,
                      glue("Entire sample randomly allocated by operators to", 
                           "conditions:",
                           "- Controls: n = {no1}",
                           "- Informative [email]: n = {no2}",
                           "- Informative [in-account]: n = {no3}",
                           "- Personal [email]: n = {no4}",
                           "- Personal [in-account]: n = {no5}",
                           "- Social [email]: n = {no6}",
                           "- Social [in-account]: n = {no7}",
                           no1 = Condition_1_Starting_Sample,
                           no2 = Condition_2_Starting_Sample,
                           no3 = Condition_3_Starting_Sample,
                           no4 = Condition_4_Starting_Sample,
                           no5 = Condition_5_Starting_Sample,
                           no6 = Condition_6_Starting_Sample,
                           no7 = Condition_7_Starting_Sample,
                           .sep = "\n"))
# Box 5
box5 <-boxGrob(y = 0.54,
               x = 0.17,
        txt_gp = TxtGp2,
        box_gp = gpar(fill = "#add8e6"), 
                      glue("Randomisation",
                           "& allocation",
                           .sep = "\n"))
box4
box5
connectGrob(box2, box4, "vertical")

# Figures for box 6:
# No. customers excluded for each reason:

less_5_betting_days<- nrow(too.few.betting.days) # created the object in this function during the original filtering process

less_90_account_days<- nrow(late.registration.date) # created the object in this function during the original filtering process

closed_account_prior_to_window <- nrow(account.closers) # Newly created in filtering process above

on_timeout_entire_window <- nrow(timeout_for_entire_window) # Newly created in filtering process above

self_excluded_entire_window <- nrow(self.excluders.all) #  Newly created in filtering process above

# Box 6
box6 <-boxGrob(y = 0.32,
               x = 0.63,
        txt_gp = TxtGp,
                      glue("Removal of customers not meeting pre-specified",
                      "eligibility criteria:",
                           "- <5 betting days in the last 30 : n = {no1}",
                           "- <90 days since registering account: n = {no2}",
                           "- Closed account prior to messaging window*: n = {no3}",
                           "- On timeout for all of messaging window*: n = {no4}",
                           "- Self-excluded for all of messaging window*: n = {no5}",
                           no1 = less_5_betting_days,
                           no2 = less_90_account_days,
                           no3 = closed_account_prior_to_window,
                           no4 = on_timeout_entire_window,
                           no5 = self_excluded_entire_window,
                           .sep = "\n"))


box6
connectGrob(box4, box6, "vertical")

# Box 7
box7 <-boxGrob(y = 0.32,
               x = 0.17,
        txt_gp = TxtGp2,
        box_gp = gpar(fill = "#add8e6"), 
                      glue("Research team",
                           "elgibility checks",
                           .sep = "\n"))
box7

# Figures for box 8:
# No. customers overall & by Operator:
hypothesis_testing_sample<- nrow(hypothesis.test.data) 
Operator_1_hypothesis_testing_Sample <- hypothesis.test.data %>% group_by(operator) %>% dplyr::summarise(n = n()) %>% filter(operator == "1") %>%dplyr::select(n) # Operator 1 starting sample
Operator_2_hypothesis_testing_Sample <- hypothesis.test.data %>% group_by(operator) %>% dplyr::summarise(n = n()) %>% filter(operator == "2") %>%dplyr::select(n) # Operator 2 starting sample
Operator_3_hypothesis_testing_Sample <- hypothesis.test.data %>% group_by(operator) %>% dplyr::summarise(n = n()) %>% filter(operator == "3") %>%dplyr::select(n) # Operator 3 starting sample
Operator_4_hypothesis_testing_Sample <- hypothesis.test.data %>% group_by(operator) %>% dplyr::summarise(n = n()) %>% filter(operator == "4") %>%dplyr::select(n) # Operator 4 starting sample

# Box 8
box8 <-boxGrob(y = 0.13,
               x = 0.63,
        txt_gp = TxtGp,
                      glue("Remaining sample included in tests of hypotheses:",
                           "- Operator 1: n = {no1}",
                           "- Operator 2: n = {no2}",
                           "- Operator 3: n = {no3}",
                           "- Operator 4: n = {no4}",
                           "- Total: n = {ntotal}",
                           no1 = Operator_1_hypothesis_testing_Sample,
                           no2 = Operator_2_hypothesis_testing_Sample,
                           no3 = Operator_3_hypothesis_testing_Sample,
                           no4 = Operator_4_hypothesis_testing_Sample,
                           ntotal = hypothesis_testing_sample,
                           .sep = "\n"))

box8
connectGrob(box6, box8, "vertical")

# Box 9
box9 <-boxGrob(y = 0.13,
               x = 0.17,
        txt_gp = TxtGp2,
        box_gp = gpar(fill = "#add8e6"), 
                      glue("Hypothesis test",
                           "sample",
                           .sep = "\n"))
box9

# Save in/as: Figures/Figure1updated.pdf

```
<br><br>

## Table exploratory ANCOVAs
There was some suggestion that the exploratory results section was difficult to follow. Let's put all outcomes from robust ANCOVAs into tables.

Start with analyses relating to gambling expenditure:
```{r}
# Average daily wager
# Robust.ANCOVA.averwager

averwager <- avwager.evalupts %>% bind_cols(avwager.n1,
                  avwager.n2,
                  avwager.diff,
                  avwager.se,
                  avwager.lowerci,
                  avwager.upperci,
                  avwager.stat,
                  avwager.pvalue) %>%
  dplyr::rename(Evaluation_points = 1,
                n1 = 2,
                n2 = 3,
                Mean_difference = 4,
                SE = 5,
                lowerci = 6,
                upperci = 7,
                Statistic = 8,
                pvalue = 9)

# Standard deviation of wager
# Robust.ANCOVA.sd.averwager

sd.averwager <-   sd.avwager.evalupts %>% bind_cols(avwager.n1,
                  sd.avwager.n2,
                  sd.avwager.diff,
                  sd.avwager.se,
                  sd.avwager.lowerci,
                  sd.avwager.upperci,
                  sd.avwager.stat,
                  sd.avwager.pvalue) %>%
  dplyr::rename(Evaluation_points = 1,
                n1 = 2,
                n2 = 3,
                Mean_difference = 4,
                SE = 5,
                lowerci = 6,
                upperci = 7,
                Statistic = 8,
                pvalue = 9)

# Net loss
# Robust.ANCOVA.net.loss

net.loss<-netloss.evalupts %>% bind_cols(avwager.n1,
          netloss.n2,
          netloss.diff,
          netloss.se,
          netloss.lowerci,
          netloss.upperci,
          netloss.stat,
          netloss.pvalue) %>%
  dplyr::rename(Evaluation_points = 1,
                n1 = 2,
                n2 = 3,
                Mean_difference = 4,
                SE = 5,
                lowerci = 6,
                upperci = 7,
                Statistic = 8,
                pvalue = 9)


Expenditure.ancova.comparisons.data<- averwager %>% bind_rows(sd.averwager,
                       net.loss) %>%
  mutate(across(1:8, round, 2))

kbl(Expenditure.ancova.comparisons.data,
    digits = 4,
    caption = "Comparisons between limit setters and non-limit setters on expenditure variables: Robust ANCOVA outcomes",
     escape = F
   ) %>%
    pack_rows("Average daily wager", 1, 5) %>%
    pack_rows("SD of average daily wager", 6, 10) %>% 
    pack_rows("Net loss", 11, 15) %>%
  add_header_above(c("Point of comparison" = 3, "Difference between samples" = 4, "Robust ANCOVA outcomes" = 2)) %>% 
  footnote(general = "SE = Standard error; CI = 95% confidence interval; Bold p values are statistically significant at < 0.0083",
  footnote_as_chunk = F) %>%
    kable_classic(full_width = F, html_font = "Cambria")

```
<br><br>

Let's do the same for gambling behavioural/involvement variables:
```{r}
# Betting frequency
Robust.ANCOVA.betting.frequency

betting.frequency <-betting.frequency.evalupts %>% bind_cols(betting.frequency.n1,
                  betting.frequency.n2,
                  betting.frequency.diff,
                  betting.frequency.se,
                  betting.frequency.lowerci,
                  betting.frequency.upperci,
                  betting.frequency.stat,
                  betting.frequency.pvalue) %>%
  dplyr::rename(Evaluation_points = 1,
                n1 = 2,
                n2 = 3,
                Mean_difference = 4,
                SE = 5,
                lowerci = 6,
                upperci = 7,
                Statistic = 8,
                pvalue = 9)


# Betting intensity
Robust.ANCOVA.betting.intensity 

betting.intensity <-betting.intensity.evalupts %>% bind_cols(betting.intensity.n1,
          betting.intensity.n2,
          betting.intensity.diff,
          betting.intensity.se,
          betting.intensity.lowerci,
          betting.intensity.upperci,
          betting.intensity.stat,
          betting.intensity.pvalue) %>%
  dplyr::rename(Evaluation_points = 1,
                n1 = 2,
                n2 = 3,
                Mean_difference = 4,
                SE = 5,
                lowerci = 6,
                upperci = 7,
                Statistic = 8,
                pvalue = 9)


Involvement.ancova.comparisons.data<- betting.frequency %>% 
  bind_rows(betting.intensity) %>%
  mutate(across(1:8, round, 2))

kbl(Involvement.ancova.comparisons.data,
    digits = 4,
    caption = "Comparisons between limit setters & non-limit setters on expenditure variables: Robust ANCOVA outcomes",
     escape = F
   ) %>%
    pack_rows("Betting frequency", 1, 5) %>%
    pack_rows("Betting intensity", 6, 10) %>% 
  add_header_above(c("Point of comparison" = 3, "Difference between samples" = 4, "Robust ANCOVA outcomes" = 2)) %>% 
  footnote(general = "SE = Standard error; CI = 95% confidence interval; Bold p values are statistically significant at < 0.0083",
  footnote_as_chunk = F) %>%
    kable_classic(full_width = F, html_font = "Cambria")
```
<br><br>

## Re-test hypotheses
The statistical editors suggested we perform logistical regressions instead of our Chi-square analyses, which are likely more suitable test about hypotheses and will allow for covariate adjustment. We compute adjusted and unadjusted logistic regressions here but only report the former in our manuscript. 

Found some really useful notes on logistic Regression and Adjusted odds ratios ;

- https://rstudio-pubs-static.s3.amazonaws.com/138745_69f9cf4d1d8b41d781aa5f3ac4d84e35.html

First, we need to check whether there's an interaction between message content and message that, if present, would have necessitate separate testing of conditions at each intersection (e.g., testing the effect of delivery move at each level of message content).
``` {r warnings = FALSE, message = FALSE}

interaction.log.reg.data <- hypothesis.test.data %>%
   filter(condition != "1") %>% # Remove controls
    mutate(content = case_when(condition == 4 ~ "Social", 
                           condition == 5 ~ "Social", 
                           condition == 2  ~ "Informative",
                           condition == 3  ~ "Informative",
                           condition == 6 ~ "Personal", 
                           condition == 7 ~ "Personal")) %>% # Designate controls
    mutate(content = as.factor(content)) %>%
    mutate(window_limit_setter = fct_recode(window_limit_setter,
                                        "1" = "LimitSetter",
                                        "0" = "None")) %>%
    mutate(delivery = case_when(condition == 2 ~ "Email", # Designate delivery type
                           condition == 4 ~ "Email", 
                           condition == 6  ~ "Email",
                           condition == 3  ~ "Account",
                           condition == 5  ~ "Account",
                           condition == 7  ~ "Account")) %>% 
    mutate(delivery = as.factor(delivery))
  
#  Check all conversions appear correct
interaction.log.reg.data %>% dplyr::select(condition, window_limit_setter, content, delivery) %>% print(n=150)

interaction.log.reg <- glm(window_limit_setter ~ content +
                             delivery +
                             content*delivery,
    data = interaction.log.reg.data, 
    family = "binomial") 

# View summary of outcomes:
summary(interaction.log.reg) 

tidy.interaction.log.reg <-  tidy(interaction.log.reg)
```
Now we know there is no interaction, we can test each of our hypotheses as planned.

### Re-test Hypothesis 1
Do messages predict limit setting? 

``` {r warnings = FALSE, message = FALSE}
# Create dataset:
hyp1.data <- hypothesis.test.data %>%
    mutate(group = case_when(condition >1 ~ "Messages", # designate message conditions
                               condition == 1  ~ "Controls")) %>% # designate controls
    mutate(group = as.factor(group)) %>%
    mutate(window_limit_setter = fct_recode(window_limit_setter,
                                        "1" = "LimitSetter",
                                        "0" = "None"))

# Re-level our outcome:
hyp1.data$window_limit_setter <-  relevel(hyp1.data$window_limit_setter, ref = "0")

# Run analysis:
hyp1.log.reg <- glm(window_limit_setter ~ group,
    data = hyp1.data, 
    family = "binomial") 

# View summary of outcomes:
summary(hyp1.log.reg) 

tidy.hyp1.log.reg <-  tidy(hyp1.log.reg)

# Compute unadjusted odds ratios:
ORs1 <- exp(hyp1.log.reg$coefficients)
OR.CIs1 <- round(cbind(ORs1, exp(confint(hyp1.log.reg))),2) %>% 
  as.data.frame()  %>%
  tibble::rownames_to_column("term") %>%
   filter(term == "groupMessages")

# Now include the other predictors on the model so that we can calculate adjusted ORs:
hyp1.1.log.reg.data <-   hyp1.data %>%
    mutate(average_daily_wager_pre_cuberoot = average_daily_wager_pre^(1/3)) # Need to convert this predictor as per protocol for first LR

# Run analysis:
hyp1.1.log.reg <-  glm(window_limit_setter ~ group +
                                      operator +
                                      betting_days_frequency_pre +
                                      average_daily_wager_pre_cuberoot +
                                      age +
                                      betting_intensity_pre +
                                      gender + 
                                      limit_setter_pre,
    data = hyp1.1.log.reg.data, 
    family = "binomial") 

summary(hyp1.1.log.reg) 
tidy(hyp1.1.log.reg) 

tidy.hyp1.1.log.reg <- tidy(hyp1.1.log.reg) %>%
   filter(term == "groupMessages")

# Calculate odds ratios and their CIs:
aORs1 <- exp(hyp1.1.log.reg$coefficients)
aOR.CIs1 <- round(cbind(aORs1, exp(confint(hyp1.1.log.reg))),2)

# Extract just the grouping variable ORs:
aOR.CIs1.group.only <- aOR.CIs1 %>% as.data.frame() %>% 
  tibble::rownames_to_column("term") %>% 
  filter(term == "groupMessages")

# Bind together key results:
hyp1.log.reg.outcomes<- tidy.hyp1.1.log.reg %>%
  bind_cols(OR.CIs1) %>% 
 dplyr::select(-6) %>%
  bind_cols(aOR.CIs1.group.only) %>% 
   dplyr::select(-9) %>%
  # as.data.frame() %>% 
  dplyr::select(Term = 1,
         Beta = 2,
         SE = 3,
         Statistic = 4,
         p_value = 5,
         unajustedOR = 6,
         unajustedOR_LB = 7,
         unajustedOR_UB = 8,
         ajustedOR = 9,
         ajustedOR_LB = 10,
         ajustedOR_UB = 11) %>% 
  mutate(Term = as.factor(Term)) %>% 
  mutate(Term = fct_recode(Term,
                           Messages = "groupMessages")) %>%
  print()

# See sample size for each group:
hyp1.group.sample.size<- hyp1.data %>% group_by(group) %>% 
  dplyr::summarise(n = n(),
            ) %>%
  print()

# overall sample size:
hyp1.overall.sample.size<- hyp1.data %>%
  dplyr::summarise(n = n(),
            ) %>%
  print()
```

### Re-test Hypothesis 2
Does messages content predict limit setting? 

We can reuse the dataset we created for testing the interaction for this hyp.
``` {r warnings = FALSE, message = FALSE}
# Re-level our outcome:
interaction.log.reg.data$window_limit_setter <-  relevel(interaction.log.reg.data$window_limit_setter, ref = "0") 

# Re-level our predictor:
interaction.log.reg.data$content <-  relevel(interaction.log.reg.data$content, ref = "Informative") 

# Run analysis:
hyp2.log.reg <- glm(window_limit_setter ~ content,
    data = interaction.log.reg.data, 
    family = "binomial") 

# View summary of outcomes:
summary(hyp2.log.reg) 

tidy.hyp2.log.reg <- tidy(hyp2.log.reg) %>% print()

# Compute unadjusted odds ratios:
ORs2 <- exp(hyp2.log.reg$coefficients)
OR.CIs2 <- round(cbind(ORs2, exp(confint(hyp2.log.reg))),2) %>% 
  as.data.frame() %>% 
   tibble::rownames_to_column("term") %>%
    filter(term == "contentPersonal" |
         term == "contentSocial") %>%
  print()


# Now include the other predictors on the model so that we can calculate adjusted ORs:
hyp2.1.log.reg.data <-   interaction.log.reg.data %>%
    mutate(average_daily_wager_pre_cuberoot = average_daily_wager_pre^(1/3)) # Need to convert this predictor as per protocol for first LR

# Run analysis:
hyp2.1.log.reg <-  glm(window_limit_setter ~ content +
                                      operator +
                                      betting_days_frequency_pre +
                                      average_daily_wager_pre_cuberoot +
                                      age +
                                      betting_intensity_pre +
                                      gender + 
                                      limit_setter_pre,
    data = hyp2.1.log.reg.data, 
    family = "binomial") 

summary(hyp2.1.log.reg) 
tidy(hyp2.1.log.reg)

tidy.hyp2.1.log.reg <-  tidy(hyp2.1.log.reg) %>%filter(term == "contentPersonal" |
         term == "contentSocial") %>% 
  print()

# Calculate odds ratios and their CIs:
aORs2 <- exp(hyp2.1.log.reg$coefficients)
aOR.CIs2  <- round(cbind(aORs2, exp(confint(hyp2.1.log.reg))),2) %>% 
  print() 

# Extract just the grouping variable ORs:
aOR.CIs2.group.only <- aOR.CIs2 %>% as.data.frame() %>% 
  tibble::rownames_to_column("term") %>% 
  filter(term == "contentPersonal" |
         term == "contentSocial")


# Bind together key results:
hyp2.log.reg.outcomes<- tidy.hyp2.1.log.reg %>% 
  bind_cols(OR.CIs2) %>% 
     dplyr::select(-6) %>%
  bind_cols(aOR.CIs2.group.only) %>% 
    dplyr::select(-9) %>%
  # as.data.frame() %>% 
  dplyr::select(Term = 1,
         Beta = 2,
         SE = 3,
         Statistic = 4,
         p_value = 5,
         unajustedOR = 6,
         unajustedOR_LB = 7,
         unajustedOR_UB = 8,
         ajustedOR = 9,
         ajustedOR_LB = 10,
         ajustedOR_UB = 11) %>% 
  mutate(Term = as.factor(Term)) %>% 
  mutate(Term = fct_recode(Term,
                           "Personal message" = "contentPersonal",
                           "Social message" = "contentSocial")) %>% 
  print() 

# See sample size for each group:
hyp2.group.sample.size<- interaction.log.reg.data %>% group_by(content) %>% 
  dplyr::summarise(n = n(),
            ) %>%
  print()

# overall sample size:
hyp2.and.3.overall.sample.size<- interaction.log.reg.data %>%
  dplyr::summarise(n = n(),
            ) %>%
  print()
```

### Bayes test of Hypothesis 2

As the terms were all non-sig, we need to calculate Bayes factors for this finding:

Useful site and paper:

-https://github.com/jomulder/BFpack 
-https://arxiv.org/pdf/1911.07728.pdf

```{r}
get_estimates(hyp2.1.log.reg)

BF_hyp2.1.log.reg <- BF(hyp2.1.log.reg, hypothesis = "contentSocial  > contentPersonal >  0")

summary(BF_hyp2.1.log.reg)

Bayes.outcomes.hyp2<- BF_hyp2.1.log.reg$BFtable_confirmatory

Bayes.outcomes.hyp2[1,7]

```

### Re-test Hypothesis 3
Does messages delivery method predict limit setting? 

Again, we can reuse the dataset we created for testing the interaction for this hyp.
``` {r warnings = FALSE, message = FALSE}

# Re-level our predictor:
interaction.log.reg.data$delivery <-  relevel(interaction.log.reg.data$delivery, ref = "Email") 

hyp3.log.reg <- glm(window_limit_setter ~ delivery,
    data = interaction.log.reg.data, 
    family = "binomial") 

# View summary of outcomes:
summary(hyp3.log.reg) 

tidy.hyp3.log.reg <- tidy(hyp3.log.reg) %>% 
  print() 

# Compute unadjusted odds ratios:
ORs3 <- exp(hyp3.log.reg$coefficients)
OR.CIs3 <- round(cbind(ORs3, exp(confint(hyp3.log.reg))),2) %>%
as.data.frame() %>% 
  tibble::rownames_to_column("term") %>% 
  filter(term == "deliveryAccount")



# Now include the other predictors on the model so that we can calculate adjusted ORs:
hyp3.1.log.reg.data <-   interaction.log.reg.data %>%
    mutate(average_daily_wager_pre_cuberoot = average_daily_wager_pre^(1/3)) # Need to convert this predictor as per protocol for first LR

# Run analysis:
hyp3.1.log.reg <-  glm(window_limit_setter ~ delivery +
                                      operator +
                                      betting_days_frequency_pre +
                                      average_daily_wager_pre_cuberoot +
                                      age +
                                      betting_intensity_pre +
                                      gender,
                                      # limit_setter_pre,
    data = hyp3.1.log.reg.data, 
    family = "binomial") 

summary(hyp3.1.log.reg) 

tidy(hyp3.1.log.reg)

tidy.hyp3.1.log.reg <-  tidy(hyp3.1.log.reg) %>% 
  filter(term == "deliveryAccount") %>% 
  print()

# Calculate odds ratios and their CIs:
aORs3 <- exp(hyp3.1.log.reg$coefficients)
aOR.CIs3  <-round(cbind(aORs3, exp(confint(hyp3.1.log.reg))),2) %>% 
  print() 

# Extract just the grouping variable ORs:
aOR.CIs3.group.only <- aOR.CIs3 %>% as.data.frame() %>% 
  tibble::rownames_to_column("term") %>% 
  filter(term == "deliveryAccount")

# Bind together key results:
hyp3.log.reg.outcomes<- tidy.hyp3.1.log.reg %>%
  bind_cols(OR.CIs3) %>% 
       dplyr::select(-6) %>%
  bind_cols(aOR.CIs3.group.only) %>% 
       dplyr::select(-9) %>%
  # as.data.frame() %>% 
  dplyr::select(Term = 1,
         Beta = 2,
         SE = 3,
         Statistic = 4,
         p_value = 5,
         unajustedOR = 6,
         unajustedOR_LB = 7,
         unajustedOR_UB = 8,
         ajustedOR = 9,
         ajustedOR_LB = 10,
         ajustedOR_UB = 11) %>% 
  mutate(Term = as.factor(Term)) %>% 
  mutate(Term = fct_recode(Term,
                           "In-account" = "deliveryAccount")) %>% 
  print() 

# See sample size for each group:
hyp3.group.sample.size<- interaction.log.reg.data %>% group_by(delivery) %>% 
  dplyr::summarise(n = n(),
            ) %>%
  print()

```

### Bayes test of Hypothesis 3

As the terms were all non-sig, we need to calculate Bayes factors for this finding too:

```{r}
get_estimates(hyp3.1.log.reg)

BF_hyp3.1.log.reg <- BF(hyp3.1.log.reg, hypothesis = "deliveryAccount  >  0")

summary(BF_hyp3.1.log.reg)

Bayes.outcomes.hyp3<- BF_hyp3.1.log.reg$BFtable_confirmatory

Bayes.outcomes.hyp3[1,7]
```

### Intention to treat analysis (Hyp1)

```{r}
Intention.to.treat.test.data<- all.operators.data %>%
  anti_join(account.closers) %>% # Remove those who closed their account before messages could be sent 
    mutate(group = case_when(condition >1 ~ "Messages", # designate message conditions
                               condition == 1  ~ "Controls")) %>% # designate controls
    mutate(group = as.factor(group)) %>%
    mutate(window_limit_setter = fct_recode(window_limit_setter,
                                        "1" = "LimitSetter",
                                        "0" = "None"))

# Re-level our outcome:
Intention.to.treat.test.data$window_limit_setter <-  relevel(Intention.to.treat.test.data$window_limit_setter, ref = "0")

# Run analysis:
ITT.log.reg <- glm(window_limit_setter ~ group,
    data = Intention.to.treat.test.data, 
    family = "binomial") 

# View summary of outcomes:
summary(ITT.log.reg) 

tidy.ITT.log.reg <-  tidy(ITT.log.reg)

# Compute unadjusted odds ratios:
ORs4 <- exp(ITT.log.reg$coefficients)
OR.CIs4 <- round(cbind(ORs4, exp(confint(ITT.log.reg))),2) %>%
  as.data.frame() %>% 
  tibble::rownames_to_column("term") %>% 
  filter(term == "groupMessages")

# Now include the other predictors on the model so that we can calculate adjusted ORs:
ITT.adjusted.log.reg.data <-   Intention.to.treat.test.data %>%
    mutate(average_daily_wager_pre_cuberoot = average_daily_wager_pre^(1/3)) # Need to convert this predictor as per protocol for first LR

# Run analysis:
ITT.adjusted.log.reg <-  glm(window_limit_setter ~ group +
                                      operator +
                                      betting_days_frequency_pre +
                                      average_daily_wager_pre_cuberoot +
                                      age +
                                      betting_intensity_pre +
                                      gender + 
                                      limit_setter_pre,
    data = ITT.adjusted.log.reg.data, 
    family = "binomial") 

summary(ITT.adjusted.log.reg) 
tidy.ITT.adjusted.log.reg <-  tidy(ITT.adjusted.log.reg) %>% 
  filter(term == "groupMessages") %>% 
  print()

# Calculate odds ratios and their CIs:
aORs4 <- exp(ITT.adjusted.log.reg$coefficients)
aOR.CIs4 <- round(cbind(aORs4, exp(confint(ITT.adjusted.log.reg))),2)

# Extract just the grouping variable ORs:
aOR.CIs4.group.only <- aOR.CIs4 %>% as.data.frame() %>% 
  tibble::rownames_to_column("term") %>% 
  filter(term == "groupMessages")

# Bind together key results:
ITT.log.reg.outcomes<- tidy.ITT.adjusted.log.reg %>% 
  bind_cols(OR.CIs4) %>% 
         dplyr::select(-6) %>%
  bind_cols(aOR.CIs4.group.only) %>% 
         dplyr::select(-9) %>%
  # as.data.frame() %>% 
  dplyr::select(Term = 1,
         Beta = 2,
         SE = 3,
         Statistic = 4,
         p_value = 5,
         unajustedOR = 6,
         unajustedOR_LB = 7,
         unajustedOR_UB = 8,
         ajustedOR = 9,
         ajustedOR_LB = 10,
         ajustedOR_UB = 11) %>% 
  mutate(Term = as.factor(Term)) %>% 
  mutate(Term = fct_recode(Term,
                           Messages = "groupMessages")) %>% 
  print() 

# See sample size for each group:
ITT.group.sample.size<- Intention.to.treat.test.data %>% group_by(group) %>% 
  dplyr::summarise(n = n(),
            ) %>%
  print()

# overall sample size:
ITT.overall.sample.size<- Intention.to.treat.test.data %>%
  dplyr::summarise(n = n(),
            ) %>%
  print()

```

Now let's develop the table, as per reviewer requests (with which we agree), that summarises all of the logistic regression outcomes.
```{r}
all.hyp.log.regression.outcomes<- hyp1.log.reg.outcomes %>% 
  bind_rows(ITT.log.reg.outcomes,
            hyp2.log.reg.outcomes,
            hyp3.log.reg.outcomes)

kbl(all.hyp.log.regression.outcomes,
    digits = 4,
    caption = "Logistic regressions",
     escape = F
   ) %>%
    pack_rows("Hypothesis 1: Overall impact of messages", 1, 1) %>%
    pack_rows("ITT analysis*:  Overall impact of messages", 2, 2) %>% 
    pack_rows("Hypothesis 2: Impact of message content", 3, 4) %>%
   pack_rows("Hypothesis 3: Impact of delivery mode", 5, 5) %>%
  add_header_above(c("", "Logistic regression" = 4, "Unadjusted ORs" = 3, "Covariate adjusted ORs" = 3)) %>%
  footnote(general = c("Hypothesis 1: reference = No message",
                       "Hypothesis 2: reference = Informative message",
                       "Hypothesis 3: reference = Email delivery",
                       "*Intention to treat (ITT) anlaysis involving all randomised participants (excl. 3 who closed their accounts before messages",
                       "were sent) reference = No message"),
  footnote_as_chunk = F) %>%
    kable_classic(full_width = F, html_font = "Cambria")

```
<br><br>

## Table of Primary outcomes
The statistical editor requested a table summarising the primary outcome from the trial: limit setting rates by condition. 


```{r}
# Make a tidy dataset to table. Need to make several tables and combine:
Group2I <- c("Intervention","Intervention")
Group3I <- c("Intervention","Intervention","Intervention")
Group6I <- c("Intervention","Intervention","Intervention","Intervention","Intervention","Intervention")
Content2 <- c("","")
Delivery3<- c("","","")
Delivery2 <- c("","")

# Total:
  
# Messages vs. controls:
message.control.summary<- limit.summary  %>%
    mutate(Group = case_when(condition >1 ~ "Intervention", # designate message conditions
                               condition == 1  ~ "Control")) %>% # designate controls
   group_by(Group) %>% 
  dplyr::summarise(
    n = sum(Total),
    LimitSetter = sum(LimitSetter),
  ) %>% 
   bind_cols(Delivery2,
             Content2) %>%
  mutate(Percentage = (LimitSetter/n)*100) %>% 
   dplyr::select(Group,
                   Content = ...5,
          "Delivery mode" = ...4,
         n,
         LimitSetter,
         Percentage
         ) 
  
# Combined delivery mode conditions:
deliv.mode.summary<- limit.summary %>%
  filter(Delivery != "Controls") %>% 
  group_by(Delivery) %>% 
  dplyr::summarise(
    n = sum(Total),
    LimitSetter = sum(LimitSetter),
  ) %>% 
  mutate(Percentage = (LimitSetter/n)*100) %>% 
  bind_cols(Group2I,
            Content2) %>%
   dplyr::select(Group = ...5,
                   Content = ...6,
          "Delivery mode" = Delivery,
         n,
         LimitSetter,
         Percentage
         ) 

# Combined message content conditions:


content.summary<- limit.summary %>%
  filter(Delivery != "Controls") %>% 
  group_by(Message) %>% 
  dplyr::summarise(
    n = sum(Total),
    LimitSetter = sum(LimitSetter),
  ) %>% 
  mutate(Percentage = (LimitSetter/n)*100) %>% 
  bind_cols(Group3I,
            Delivery3) %>%
   dplyr::select(Group =...5,
          "Content" = Message,
         "Delivery mode" = ...6,
         n,
         LimitSetter,
         Percentage
         ) 

# Single condition salaries and finalise:
Conditions.summary <- limit.summary %>% 
   filter(Delivery != "Controls") %>% 
  bind_cols(Group6I) %>%
  dplyr::select(Group = ...8,
         Content = Message,
         "Delivery mode" = Delivery,
         n = Total,
         LimitSetter,
         Percentage
         )  

table2data<- message.control.summary %>%  bind_rows(Conditions.summary,
            content.summary,
            deliv.mode.summary)
  
kbl(table2data,
    digits = 4,
    caption = "Primary outcome summary: Number of limit setters per experimental conditions",
     escape = F
   ) %>%
    pack_rows("Overall", 1, 2) %>%
    pack_rows("All conditions", 3, 8) %>% 
    pack_rows("Message content aggregates", 9, 11) %>%
   pack_rows("Message delivery mode aggregates", 12, 13) %>%
  # add_header_above(c("", "Logistic regression" = 4, "Unadjusted ORs" = 3, "Covariate adjusted ORs" = 3)) %>%
    kable_classic(full_width = F, html_font = "Cambria")


```

## Unintended consequences of messages
One reviewer referred to the number of people who may have self excluded or gone on a timeout in the window following messages. Let's look at these as potential unintended consequences of our messages.

```{r}

# Identify start a timeout during the messaging period:
timeout.during <- all.operators.data %>%
  filter(timeout_start_date_pre >=  as.Date("2019-10-14") &
         timeout_start_date_post <=  as.Date("2019-10-23")) %>% 
 dplyr::select(condition,
               timeout_duration_pre, 
         timeout_start_date_pre,
         timeout_finish_date_pre,
         timeout_pre,
         operator,
         window_limit_setter)

nrow(timeout.during)
# Only one person was on timeout and they were from Operator 4, condition 4. . 

# What about in the 10 days after?
timeout.after <- all.operators.data %>%
  filter(timeout_start_date_pre >=  as.Date("2019-10-24") &
         timeout_start_date_post <=  as.Date("2019-11-02")) %>% 
 dplyr::select(condition,
               timeout_duration_pre, 
         timeout_start_date_pre,
         timeout_finish_date_pre,
         timeout_pre,
         operator,
         window_limit_setter)

nrow(timeout.after)

# See how many self-excluded during the messaging period:
self.excluders.during<- all.operators.data %>%
  filter(self_exclusion_start_date >=  as.Date("2019-10-14") &
         self_exclusion_start_date <=  as.Date("2019-10-23")) %>%
 dplyr::select(condition,
               self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         # customerid,
         operator,
         window_limit_setter) 

nrow(self.excluders.during)

# What about in the 10 days after?
self.excluders.10daysafter<- all.operators.data %>%
  filter(condition != "1") %>% 
  filter(self_exclusion_start_date >=  as.Date("2019-10-24") &
         self_exclusion_start_date <=  as.Date("2019-11-02")) %>%
 dplyr::select(condition,
               self_exclusion_start_date,
         self_exclusion_finish_date,
         self_exclusion,
         # customerid,
         operator,
         window_limit_setter) 

nrow(self.excluders.10daysafter)

# What about the 90 days after messages?
all.operators.data %>%
  filter(self_exclusion_start_date >=  as.Date("2019-10-14") &
         self_exclusion_start_date <=  as.Date("2020-01-17")) %>%
  group_by(self_exclusion_start_date) %>% 
  dplyr::summarise(n= n()) %>% print(n=50)

# There's a spike around Melbourne cup, it seems. But the messaging window does not appear to be unique in the terms of the number of people who self-excluded
  
```

# -------------------------------------------------------------------------------

#### Save final workspace environment for use in manuscript:
```{r warnings = FALSE, message = FALSE}
save.image(file='ProjectOutcomes.RData')

# Signal end of script:
beep(4)
```
END
